<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en" data-bs-theme="auto">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<title>JAX: (Bio)Image Processing with Python: All in One View</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<script src="../assets/themetoggle.js"></script><link rel="stylesheet" type="text/css" href="../assets/styles.css">
<script src="../assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="../favicons/dc/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicons/dc/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="../favicons/dc/favicon-16x16.png">
<link rel="manifest" href="../favicons/dc/site.webmanifest">
<link rel="mask-icon" href="../favicons/dc/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="white">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="black">
</head>
<body>
    <header id="top" class="navbar navbar-expand-md top-nav data"><svg xmlns="http://www.w3.org/2000/svg" class="d-none"><symbol id="check2" viewbox="0 0 16 16"><path d="M13.854 3.646a.5.5 0 0 1 0 .708l-7 7a.5.5 0 0 1-.708 0l-3.5-3.5a.5.5 0 1 1 .708-.708L6.5 10.293l6.646-6.647a.5.5 0 0 1 .708 0z"></path></symbol><symbol id="circle-half" viewbox="0 0 16 16"><path d="M8 15A7 7 0 1 0 8 1v14zm0 1A8 8 0 1 1 8 0a8 8 0 0 1 0 16z"></path></symbol><symbol id="moon-stars-fill" viewbox="0 0 16 16"><path d="M6 .278a.768.768 0 0 1 .08.858 7.208 7.208 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277.527 0 1.04-.055 1.533-.16a.787.787 0 0 1 .81.316.733.733 0 0 1-.031.893A8.349 8.349 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.752.752 0 0 1 6 .278z"></path><path d="M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.734 1.734 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.734 1.734 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.734 1.734 0 0 0 1.097-1.097l.387-1.162zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.156 1.156 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.156 1.156 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732L13.863.1z"></path></symbol><symbol id="sun-fill" viewbox="0 0 16 16"><path d="M8 12a4 4 0 1 0 0-8 4 4 0 0 0 0 8zM8 0a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 0zm0 13a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 13zm8-5a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2a.5.5 0 0 1 .5.5zM3 8a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2A.5.5 0 0 1 3 8zm10.657-5.657a.5.5 0 0 1 0 .707l-1.414 1.415a.5.5 0 1 1-.707-.708l1.414-1.414a.5.5 0 0 1 .707 0zm-9.193 9.193a.5.5 0 0 1 0 .707L3.05 13.657a.5.5 0 0 1-.707-.707l1.414-1.414a.5.5 0 0 1 .707 0zm9.193 2.121a.5.5 0 0 1-.707 0l-1.414-1.414a.5.5 0 0 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .707zM4.464 4.465a.5.5 0 0 1-.707 0L2.343 3.05a.5.5 0 1 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .708z"></path></symbol></svg><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-8">
      <div class="large-logo">
        <img id="dc-logo" alt="Data Carpentry" src="../assets/images/data-logo.svg">
</div>
    </div>
    <div class="selector-container">
      <div id="theme-selector">
        <li class="nav-item dropdown" id="theme-button-list">
          <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
            <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="bd-theme-text">
<li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                Light
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                Dark
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                Auto
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
          </ul>
</li>
      </div>

      <div class="dropdown" id="instructor-dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1">
<li><button class="dropdown-item" type="button" onclick="window.location.href='../aio.html';">Learner View</button></li>
        </ul>
</div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl bottom-nav data" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="Data Carpentry" src="../assets/images/data-logo-sm.svg">
</div>
    <div class="lesson-title-md">
      JAX: (Bio)Image Processing with Python
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="Search the All In One page" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0">
<li class="nav-item">
          <span class="lesson-title">
            JAX: (Bio)Image Processing with Python
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/instructor-notes.html">Instructor Notes</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/images.html">Extract All Images</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown">
<hr>
<li><a class="dropdown-item" href="discuss.html">Discussion</a></li>
<li><a class="dropdown-item" href="edge-detection.html">Extra Episode: Edge Detection</a></li>
<li><a class="dropdown-item" href="prereqs.html">Prerequisites</a></li>
<li><a class="dropdown-item" href="reference.html">Reference</a></li>
          </ul>
</li>
      </ul>
</div>
    <!--
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled>
      <input class="form-control me-2 searchbox" type="search" placeholder="" aria-label="">
        <button class="btn btn-outline-success tablet-search-button"  type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="Search the All In One page"></i>
        </button>
      </fieldset>
    </form>
    -->
    <a id="search-button" class="btn btn-primary" href="../instructor/aio.html" role="button" aria-label="Search the All In One page">Search the All In One page</a>
  </div>
<!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  JAX: (Bio)Image Processing with Python
</div>

<aside class="col-md-12 lesson-progress"><div style="width: %" class="percentage">
    %
  </div>
  <div class="progress data">
    <div class="progress-bar data" role="progressbar" style="width: %" aria-valuenow="" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner">
          <div class="row mobile-row" id="theme-row-mobile">
            <div class="col" id="theme-selector">
              <li class="nav-item dropdown" id="theme-button-list">
                <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
                  <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><span class="d-lg-none ms-1" id="bd-theme-text">Toggle Theme</span>
                </button>
                <ul class="dropdown-menu dropdown-menu-right" aria-labelledby="bd-theme-text">
<li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                      Light
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                      Dark
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                      <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                      Auto
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                </ul>
</li>
            </div>
          </div>
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="../aio.html">Learner View</a>
                      </div>
                    </div>
                  </div>
<!--/div.accordion-item-->
                </div>
<!--/div.accordion-flush-->
              </div>
<!--div.sidenav-view-selector -->
            </div>
<!--/div.col -->

            <hr>
</div>
<!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Schedule</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="01-introduction.html">1. Introduction</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="02-image-basics.html">2. Image Basics</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush4">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading4">
        <a href="03-skimage-images.html">3. Working with scikit-image</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush5">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading5">
        <a href="04-drawing.html">4. Drawing and Bitwise Operations</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush6">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading6">
        <a href="05-creating-histograms.html">5. Creating Histograms</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush7">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading7">
        <a href="06-blurring.html">6. Blurring Images</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush8">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading8">
        <a href="07-thresholding.html">7. Thresholding</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush9">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading9">
        <a href="08-connected-components.html">8. Connected Component Analysis</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width">
<div class="accordion accordion-flush lesson-resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="lesson-resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul>
<li>
                        <a href="../instructor/key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="../instructor/instructor-notes.html">Instructor Notes</a>
                      </li>
                      <li>
                        <a href="../instructor/images.html">Extract All Images</a>
                      </li>
                      <hr>
<li><a class="dropdown-item" href="discuss.html">Discussion</a></li>
<li><a class="dropdown-item" href="edge-detection.html">Extra Episode: Edge Detection</a></li>
<li><a class="dropdown-item" href="prereqs.html">Prerequisites</a></li>
<li><a class="dropdown-item" href="reference.html">Reference</a></li>
                    </ul>
</div>
                </div>
              </div>
            </div>
            <hr class="half-width lesson-resources">
<a href="../instructor/aio.html">See all in one page</a>


            <hr class="d-none d-sm-block d-md-none">
<div class="d-grid gap-1">

            </div>
          </div>
<!-- /div.accordion -->
        </div>
<!-- /div.sidebar-inner -->
      </nav>
</div>
<!-- /div.sidebar -->
  </div>
<!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-extra.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <main id="main-content" class="main-content"><div class="container lesson-content">
        
        
<section id="aio-01-introduction"><p>Content from <a href="01-introduction.html">Introduction</a></p>
<hr>
<p>Last updated on 2024-03-19 |

        <a href="https://github.com/govekk/image-processing/edit/main/episodes/01-introduction.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 5 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div id="accordionInstructor1" class="accordion instructor-note accordion-flush">
<div class="accordion-item">
<button class="accordion-button instructor-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseInstructor1" aria-expanded="false" aria-controls="collapseInstructor1">
  <h3 class="accordion-header" id="headingInstructor1">  <div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="edit-2"></i></div> Instructor Note </h3>
</button>
<div id="collapseInstructor1" class="accordion-collapse collapse" aria-labelledby="headingInstructor1" data-bs-parent="#accordionInstructor1">
<div class="accordion-body">
<ul>
<li><p>Hello, who are we</p></li>
<li><p>Please ask questions, either chat or raise hand. Helper will be
monitoring Zoom.</p></li>
<li><p>ok to have videos off, going to be using Zoom reacts</p></li>
<li><p>start up jupyter</p></li>
<li>
<p>overview of jupyter shortcuts I may use</p>
<ul>
<li>enter to enter block, escape to exit</li>
<li>ctrl enter to run current block</li>
<li>b to add block below, a to add above</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What sort of scientific questions can we answer with image
processing / computer vision?</li>
<li>What are morphometric problems?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Recognise scientific questions that could be solved with image
processing / computer vision.</li>
<li>Recognise morphometric problems (those dealing with the number,
size, or shape of the objects in an image).</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p>As computer systems have become faster and more powerful, and cameras
and other imaging systems have become commonplace in many other areas of
life, the need has grown for researchers to be able to process and
analyse image data. Considering the large volumes of data that can be
involved - high-resolution images that take up a lot of disk
space/virtual memory, and/or collections of many images that must be
processed together - and the time-consuming and error-prone nature of
manual processing, it can be advantageous or even necessary for this
processing and analysis to be automated as a computer program.</p>
<p>This lesson introduces an open source toolkit for processing image
data: the Python programming language and <a href="https://scikit-image.org/" class="external-link">the <em>scikit-image</em>
(<code>skimage</code>) library</a>. With careful experimental design,
Python code can be a powerful instrument in answering many different
kinds of questions.</p>
<section><h2 class="section-heading" id="uses-of-image-processing-in-research">Uses of Image Processing in Research<a class="anchor" aria-label="anchor" href="#uses-of-image-processing-in-research"></a>
</h2>
<hr class="half-width">
<p>Automated processing can be used to analyse many different properties
of an image, including the distribution and change in colours in the
image, the number, size, position, orientation, and shape of objects in
the image, and even - when combined with machine learning techniques for
object recognition - the type of objects in the image.</p>
<p>Some examples of image processing methods applied in research
include:</p>
<ul>
<li><a href="https://iopscience.iop.org/article/10.3847/2041-8213/ab0e85" class="external-link">imaging
a Black Hole</a></li>
<li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3325796/" class="external-link">estimating
the population of Emperor Penguins</a></li>
<li><a href="https://www.cell.com/cell/fulltext/S0092-8674(19)31124-9" class="external-link">the
global-scale analysis of marine plankton diversity</a></li>
<li><a href="https://doi.org/10.1016/j.cmpb.2017.12.008" class="external-link">segmentation of
liver and vessels from CT images</a></li>
</ul>
<p>With this lesson, we aim to provide a thorough grounding in the
fundamental concepts and skills of working with image data in Python.
Most of the examples used in this lesson focus on one particular class
of image processing technique, <em>morphometrics</em>, but what you will
learn can be used to solve a much wider range of problems.</p>
</section><section><h2 class="section-heading" id="morphometrics">Morphometrics<a class="anchor" aria-label="anchor" href="#morphometrics"></a>
</h2>
<hr class="half-width">
<p>Morphometrics involves counting the number of objects in an image,
analyzing the size of the objects, or analyzing the shape of the
objects. For example, we might be interested in automatically counting
the number of bacterial colonies growing in a Petri dish, as shown in
this image:</p>
<figure><img src="../fig/colonies-01.jpg" alt="Bacteria colony" class="figure mx-auto d-block"></figure><p>We could use image processing to find the colonies, count them, and
then highlight their locations on the original image, resulting in an
image like this:</p>
<figure><img src="../fig/colony-mask.png" alt="Colonies counted" class="figure mx-auto d-block"></figure><div id="why-write-a-program-to-do-that" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="why-write-a-program-to-do-that" class="callout-inner">
<h3 class="callout-title">Why write a program to do that?</h3>
<div class="callout-content">
<p>Note that you can easily manually count the number of bacteria
colonies shown in the morphometric example above. Why should we learn
how to write a Python program to do a task we could easily perform with
our own eyes? There are at least two reasons to learn how to perform
tasks like these with Python and scikit-image:</p>
<ol style="list-style-type: decimal">
<li>What if there are many more bacteria colonies in the Petri dish? For
example, suppose the image looked like this:</li>
</ol>
<figure><img src="../fig/colonies-03.jpg" alt="Bacteria colony" class="figure mx-auto d-block"></figure><p>Manually counting the colonies in that image would present more of a
challenge. A Python program using scikit-image could count the number of
colonies more accurately, and much more quickly, than a human could.</p>
<ol start="2" style="list-style-type: decimal">
<li>What if you have hundreds, or thousands, of images to consider?
Imagine having to manually count colonies on several thousand images
like those above. A Python program using scikit-image could move through
all of the images in seconds; how long would a graduate student require
to do the task? Which process would be more accurate and
repeatable?</li>
</ol>
<p>As you can see, the simple image processing / computer vision
techniques you will learn during this workshop can be very valuable
tools for scientific research.</p>
</div>
</div>
</div>
<p>As we move through this workshop, we will learn image analysis
methods useful for many different scientific problems. These will be
linked together and applied to a real problem in the final
end-of-workshop <a href="09-challenges.html">capstone challenge</a>.</p>
<p>Let’s get started, by learning some basics about how images are
represented and stored digitally.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul>
<li>Simple Python and scikit-image techniques can be used to solve
genuine image analysis problems.</li>
<li>Morphometric problems involve the number, shape, and / or size of
the objects in an image.</li>
</ul>
</div>
</div>
</div>
</section></section><section id="aio-02-image-basics"><p>Content from <a href="02-image-basics.html">Image Basics</a></p>
<hr>
<p>Last updated on 2024-03-11 |

        <a href="https://github.com/govekk/image-processing/edit/main/episodes/02-image-basics.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 25 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How are images represented in digital format?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Define the terms bit, byte, kilobyte, megabyte, etc.</li>
<li>Explain how a digital image is composed of pixels.</li>
<li>Recommend using imageio (resp. scikit-image) for I/O (resp. image
processing) tasks.</li>
<li>Explain how images are stored in NumPy arrays.</li>
<li>Explain the left-hand coordinate system used in digital images.</li>
<li>Explain the RGB additive colour model used in digital images.</li>
<li>Explain the order of the three colour values in scikit-image
images.</li>
<li>Explain the characteristics of the BMP, JPEG, and TIFF image
formats.</li>
<li>Explain the difference between lossy and lossless compression.</li>
<li>Explain the advantages and disadvantages of compressed image
formats.</li>
<li>Explain what information could be contained in image metadata.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p>The images we see on hard copy, view with our electronic devices, or
process with our programs are represented and stored in the computer as
numeric abstractions, approximations of what we see with our eyes in the
real world. Before we begin to learn how to process images with Python
programs, we need to spend some time understanding how these
abstractions work.</p>
<section><h2 class="section-heading" id="pixels">Pixels<a class="anchor" aria-label="anchor" href="#pixels"></a>
</h2>
<hr class="half-width">
<p>It is important to realise that images are stored as rectangular
arrays of hundreds, thousands, or millions of discrete “picture
elements,” otherwise known as <em>pixels</em>. Each pixel can be thought
of as a single square point of coloured light.</p>
<p>For example, consider this image of a maize seedling, with a square
area designated by a red box:</p>
<figure><img src="../fig/maize-seedling-original.jpg" alt="Original size image" class="figure mx-auto d-block"></figure><p>Now, if we zoomed in close enough to see the pixels in the red box,
we would see something like this:</p>
<figure><img src="../fig/maize-seedling-enlarged.jpg" alt="Enlarged image area" class="figure mx-auto d-block"></figure><p>Note that each square in the enlarged image area - each pixel - is
all one colour, but that each pixel can have a different colour from its
neighbors. Viewed from a distance, these pixels seem to blend together
to form the image we see.</p>
<p>Real-world images are typically made up of a vast number of pixels,
and each of these pixels is one of potentially millions of colours.
While we will deal with pictures of such complexity in this lesson,
let’s start our exploration with just 15 pixels in a 5 x 3 matrix with 2
colours, and work our way up to that complexity.</p>
<div id="matrices-arrays-images-and-pixels" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="matrices-arrays-images-and-pixels" class="callout-inner">
<h3 class="callout-title">Matrices, arrays, images and pixels</h3>
<div class="callout-content">
<p>A <strong>matrix</strong> is a mathematical concept - numbers evenly
arranged in a rectangle. This can be a two-dimensional rectangle, like
the shape of the screen you’re looking at now. Or it could be a
three-dimensional equivalent, a cuboid, or have even more dimensions,
but always keeping the evenly spaced arrangement of numbers. In
computing, an <strong>array</strong> refers to a structure in the
computer’s memory where data is stored in evenly spaced
<strong>elements</strong>. This is strongly analogous to a matrix. A
NumPy array is a <strong>type</strong> of variable (a simpler example of
a type is an integer). For our purposes, the distinction between
matrices and arrays is not important, we don’t really care how the
computer arranges our data in its memory. The important thing is that
the computer stores values describing the pixels in images, as arrays.
And the terms matrix and array will be used interchangeably.</p>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="loading-images">Loading images<a class="anchor" aria-label="anchor" href="#loading-images"></a>
</h2>
<hr class="half-width">
<p>As noted, images we want to analyze (process) with Python are loaded
into arrays. There are multiple ways to load images. In this lesson, we
use imageio, a Python library for reading (loading) and writing (saving)
image data, and more specifically its version 3. But, really, we could
use any image loader which would return a NumPy array.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="co">"""Python library for reading and writing images."""</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">import</span> imageio.v3 <span class="im">as</span> iio</span></code></pre>
</div>
<p>The <code>v3</code> module of imageio (<code>imageio.v3</code>) is
imported as <code>iio</code> (see note in the next section). Version 3
of imageio has the benefit of supporting nD (multidimensional) image
data natively (think of volumes, movies).</p>
<p>Let us load our image data from disk using the <code>imread</code>
function from the <code>imageio.v3</code> module.</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>eight <span class="op">=</span> iio.imread(uri<span class="op">=</span><span class="st">"data/eight.tif"</span>)</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">type</span>(eight))</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>&lt;class 'numpy.ndarray'&gt;</code></pre>
</div>
<p>Note that, using the same image loader or a different one, we could
also read in remotely hosted data.</p>
<div id="why-not-use-skimage.io.imread" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="why-not-use-skimage.io.imread" class="callout-inner">
<h3 class="callout-title">Why not use
<code>skimage.io.imread()</code>?</h3>
<div class="callout-content">
<p>The scikit-image library has its own function to read an image, so
you might be asking why we don’t use it here. Actually,
<code>skimage.io.imread()</code> uses <code>iio.imread()</code>
internally when loading an image into Python. It is certainly something
you may use as you see fit in your own code. In this lesson, we use the
imageio library to read or write images, while scikit-image is dedicated
to performing operations on the images. Using imageio gives us more
flexibility, especially when it comes to handling metadata.</p>
</div>
</div>
</div>
<div id="beyond-numpy-arrays" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="beyond-numpy-arrays" class="callout-inner">
<h3 class="callout-title">Beyond NumPy arrays</h3>
<div class="callout-content">
<p>Beyond NumPy arrays, there exist other types of variables which are
array-like. Notably, <a href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html" class="external-link">pandas.DataFrame</a>
and <a href="https://docs.xarray.dev/en/stable/generated/xarray.DataArray.html" class="external-link">xarray.DataArray</a>
can hold labeled, tabular data. These are not natively supported in
scikit-image, the scientific toolkit we use in this lesson for
processing image data. However, data stored in these types can be
converted to <code>numpy.ndarray</code> with certain assumptions (see
<code>pandas.DataFrame.to_numpy()</code> and
<code>xarray.DataArray.data</code>). Particularly, these conversions
ignore the sampling coordinates (<code>DataFrame.index</code>,
<code>DataFrame.columns</code>, or <code>DataArray.coords</code>), which
may result in misrepresented data, for instance, when the original data
points are irregularly spaced.</p>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="working-with-pixels">Working with pixels<a class="anchor" aria-label="anchor" href="#working-with-pixels"></a>
</h2>
<hr class="half-width">
<p>First, let us add the necessary imports:</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="co">"""Python libraries for learning and performing image processing."""</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a><span class="im">import</span> ipympl</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a><span class="im">import</span> skimage <span class="im">as</span> ski</span></code></pre>
</div>
<div id="import-statements-in-python" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="import-statements-in-python" class="callout-inner">
<h3 class="callout-title">Import statements in Python</h3>
<div class="callout-content">
<p>In Python, the <code>import</code> statement is used to load
additional functionality into a program. This is necessary when we want
our code to do something more specialised, which cannot easily be
achieved with the limited set of basic tools and data structures
available in the default Python environment.</p>
<p>Additional functionality can be loaded as a single function or
object, a module defining several of these, or a library containing many
modules. You will encounter several different forms of
<code>import</code> statement.</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="im">import</span> skimage                 <span class="co"># form 1, load whole skimage library</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a><span class="im">import</span> skimage.draw            <span class="co"># form 2, load skimage.draw module only</span></span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a><span class="im">from</span> skimage.draw <span class="im">import</span> disk  <span class="co"># form 3, load only the disk function</span></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a><span class="im">import</span> skimage <span class="im">as</span> ski          <span class="co"># form 4, load all of skimage into an object called ski</span></span></code></pre>
</div>
<div id="accordionSpoiler1" class="accordion spoiler-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button spoiler-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSpoiler1" aria-expanded="false" aria-controls="collapseSpoiler1">
  <h3 class="accordion-header" id="headingSpoiler1">  <div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="eye"></i></div> Further explanation </h3>
</button>
<div id="collapseSpoiler1" class="accordion-collapse collapse" aria-labelledby="headingSpoiler1" data-bs-parent="#accordionSpoiler1">
<div class="accordion-body">
<p>In the example above, form 1 loads the entire scikit-image library
into the program as an object. Individual modules of the library are
then available within that object, e.g., to access the <code>disk</code>
function used in <a href="04-drawing.html">the drawing episode</a>, you
would write <code>skimage.draw.disk()</code>.</p>
<p>Form 2 loads only the <code>draw</code> module of
<code>skimage</code> into the program. The syntax needed to use the
module remains unchanged: to access the <code>disk</code> function, we
would use the same function call as given for form 1.</p>
<p>Form 3 can be used to import only a specific function/class from a
library/module. Unlike the other forms, when this approach is used, the
imported function or class can be called by its name only, without
prefixing it with the name of the library/module from which it was
loaded, i.e., <code>disk()</code> instead of
<code>skimage.draw.disk()</code> using the example above. One hazard of
this form is that importing like this will overwrite any object with the
same name that was defined/imported earlier in the program, i.e., the
example above would replace any existing object called <code>disk</code>
with the <code>disk</code> function from <code>skimage.draw</code>.</p>
<p>Finally, the <code>as</code> keyword can be used when importing, to
define a name to be used as shorthand for the library/module being
imported. This name is referred to as an alias. Typically, using an
alias (such as <code>np</code> for the NumPy library) saves us a little
typing. You may see <code>as</code> combined with any of the other first
three forms of <code>import</code> statements.</p>
<p>Which form is used often depends on the size and number of additional
tools being loaded into the program.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<p>Now that we have our libraries loaded, we will run a Jupyter Magic
Command that will ensure our images display in our Jupyter document with
pixel information that will help us more efficiently run commands later
in the session.</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="op">%</span>matplotlib widget</span></code></pre>
</div>
<p>With that taken care of, let us display the image we have loaded,
using the <code>imshow</code> function from the
<code>matplotlib.pyplot</code> module.</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>plt.imshow(eight)</span></code></pre>
</div>
<figure><img src="../fig/eight.png" alt="Image of 8" class="figure mx-auto d-block"></figure><p>You might be thinking, “That does look vaguely like an eight, and I
see two colours but how can that be only 15 pixels”. The display of the
eight you see does use a lot more screen pixels to display our eight so
large, but that does not mean there is information for all those screen
pixels in the file. All those extra pixels are a consequence of our
viewer creating additional pixels through interpolation. It could have
just displayed it as a tiny image using only 15 screen pixels if the
viewer was designed differently.</p>
<p>While many image file formats contain descriptive metadata that can
be essential, the bulk of a picture file is just arrays of numeric
information that, when interpreted according to a certain rule set,
become recognizable as an image to us. Our image of an eight is no
exception, and <code>imageio.v3</code> stored that image data in an
array of arrays making a 5 x 3 matrix of 15 pixels. We can demonstrate
that by calling on the shape property of our image variable and see the
matrix by printing our image variable to the screen.</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="bu">print</span>(eight.shape)</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a><span class="bu">print</span>(eight)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>(5, 3)
[[0. 0. 0.]
 [0. 1. 0.]
 [0. 0. 0.]
 [0. 1. 0.]
 [0. 0. 0.]]</code></pre>
</div>
<p>Thus if we have tools that will allow us to manipulate these arrays
of numbers, we can manipulate the image. The NumPy library can be
particularly useful here, so let’s try that out using NumPy array
slicing. Notice that the default behavior of the <code>imshow</code>
function appended row and column numbers that will be helpful to us as
we try to address individual or groups of pixels. First let’s load
another copy of our eight, and then make it look like a zero.</p>
<p>To make it look like a zero, we need to change the number underlying
the centremost pixel to be 1. With the help of those row and column
headers, at this small scale we can determine the centre pixel is in row
labeled 2 and column labeled 1. Using array slicing, we can then address
and assign a new value to that position.</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a>zero <span class="op">=</span> iio.imread(uri<span class="op">=</span><span class="st">"data/eight.tif"</span>)</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>zero[<span class="dv">2</span>,<span class="dv">1</span>]<span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a><span class="co"># The following line of code creates a new figure for imshow to use in displaying our output.</span></span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a><span class="co"># Without it, plt.imshow() would overwrite our previous image in the cell above</span></span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a>plt.imshow(zero)</span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a><span class="bu">print</span>(zero)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>[[0. 0. 0.]
 [0. 1. 0.]
 [0. 1. 0.]
 [0. 1. 0.]
 [0. 0. 0.]]</code></pre>
</div>
<figure><img src="../fig/zero.png" alt="Image of 0" class="figure mx-auto d-block"></figure><div id="coordinate-system" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="coordinate-system" class="callout-inner">
<h3 class="callout-title">Coordinate system</h3>
<div class="callout-content">
<p>When we process images, we can access, examine, and / or change the
colour of any pixel we wish. To do this, we need some convention on how
to access pixels individually; a way to give each one a name, or an
address of a sort.</p>
<p>The most common manner to do this, and the one we will use in our
programs, is to assign a modified Cartesian coordinate system to the
image. The coordinate system we usually see in mathematics has a
horizontal x-axis and a vertical y-axis, like this:</p>
<figure><img src="../fig/cartesian-coordinates.png" alt="Cartesian coordinate system" class="figure mx-auto d-block"></figure><p>The modified coordinate system used for our images will have only
positive coordinates, the origin will be in the upper left corner
instead of the centre, and y coordinate values will get larger as they
go down instead of up, like this:</p>
<figure><img src="../fig/image-coordinates.png" alt="Image coordinate system" class="figure mx-auto d-block"></figure><p>This is called a <em>left-hand coordinate system</em>. If you hold
your left hand in front of your face and point your thumb at the floor,
your extended index finger will correspond to the x-axis while your
thumb represents the y-axis.</p>
<figure><img src="../fig/left-hand-coordinates.png" alt="Left-hand coordinate system" class="figure mx-auto d-block"></figure><p>Until you have worked with images for a while, the most common
mistake that you will make with coordinates is to forget that y
coordinates get larger as they go down instead of up as in a normal
Cartesian coordinate system. Consequently, it may be helpful to think in
terms of counting down rows (r) for the y-axis and across columns (c)
for the x-axis. This can be especially helpful in cases where you need
to transpose image viewer data provided in <em>x,y</em> format to
<em>y,x</em> format. Thus, we will use <em>cx</em> and <em>ry</em> where
appropriate to help bridge these two approaches.</p>
</div>
</div>
</div>
<div id="changing-pixel-values-5-min" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="changing-pixel-values-5-min" class="callout-inner">
<h3 class="callout-title">Changing Pixel Values (5 min)</h3>
<div class="callout-content">
<p>Load another copy of eight named five, and then change the value of
pixels so you have what looks like a 5 instead of an 8. Display the
image and print out the matrix as well.</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<p>There are many possible solutions, but one method would be . . .</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a>five <span class="op">=</span> iio.imread(uri<span class="op">=</span><span class="st">"data/eight.tif"</span>)</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a>five[<span class="dv">1</span>,<span class="dv">2</span>]<span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a>five[<span class="dv">3</span>,<span class="dv">0</span>]<span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a>plt.imshow(five)</span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a><span class="bu">print</span>(five)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>[[0. 0. 0.]
 [0. 1. 1.]
 [0. 0. 0.]
 [1. 1. 0.]
 [0. 0. 0.]]</code></pre>
</div>
<figure><img src="../fig/five.png" alt="Image of 5" class="figure mx-auto d-block"></figure>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="more-colours">More colours<a class="anchor" aria-label="anchor" href="#more-colours"></a>
</h2>
<hr class="half-width">
<p>Up to now, we only had a 2 colour matrix, but we can have more if we
use other numbers or fractions. One common way is to use the numbers
between 0 and 255 to allow for 256 different colours or 256 different
levels of grey. Let’s try that out.</p>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="co"># make a copy of eight</span></span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a>three_colours <span class="op">=</span> iio.imread(uri<span class="op">=</span><span class="st">"data/eight.tif"</span>)</span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a><span class="co"># multiply the whole matrix by 128</span></span>
<span id="cb14-5"><a href="#cb14-5" tabindex="-1"></a>three_colours <span class="op">=</span> three_colours <span class="op">*</span> <span class="dv">128</span></span>
<span id="cb14-6"><a href="#cb14-6" tabindex="-1"></a></span>
<span id="cb14-7"><a href="#cb14-7" tabindex="-1"></a><span class="co"># set the middle row (index 2) to the value of 255.,</span></span>
<span id="cb14-8"><a href="#cb14-8" tabindex="-1"></a><span class="co"># so you end up with the values 0., 128., and 255.</span></span>
<span id="cb14-9"><a href="#cb14-9" tabindex="-1"></a>three_colours[<span class="dv">2</span>,:] <span class="op">=</span> <span class="fl">255.</span></span>
<span id="cb14-10"><a href="#cb14-10" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb14-11"><a href="#cb14-11" tabindex="-1"></a>plt.imshow(three_colours)</span>
<span id="cb14-12"><a href="#cb14-12" tabindex="-1"></a><span class="bu">print</span>(three_colours)</span></code></pre>
</div>
<figure><img src="../fig/three-colours.png" alt="Image of three colours" class="figure mx-auto d-block"></figure><p>We now have 3 colours, but are they the three colours you expected?
They all appear to be on a continuum of dark purple on the low end and
yellow on the high end. This is a consequence of the default colour map
(cmap) in this library. You can think of a colour map as an association
or mapping of numbers to a specific colour. However, the goal here is
not to have one number for every possible colour, but rather to have a
continuum of colours that demonstrate relative intensity. In our
specific case here for example, 255 or the highest intensity is mapped
to yellow, and 0 or the lowest intensity is mapped to a dark purple. The
best colour map for your data will vary and there are many options built
in, but this default selection was not arbitrary. A lot of science went
into making this the default due to its robustness when it comes to how
the human mind interprets relative colour values, grey-scale
printability, and colour-blind friendliness (You can read more about
this default colour map in <a href="https://matplotlib.org/stable/tutorials/colors/colormaps.html" class="external-link">a
Matplotlib tutorial</a> and <a href="https://bids.github.io/colormap/" class="external-link">an explanatory article by the
authors</a>). Thus it is a good place to start, and you should change it
only with purpose and forethought. For now, let’s see how you can do
that using an alternative map you have likely seen before where it will
be even easier to see it as a mapped continuum of intensities:
greyscale.</p>
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a>plt.imshow(three_colours,cmap<span class="op">=</span>plt.cm.gray)</span></code></pre>
</div>
<figure><img src="../fig/grayscale.png" alt="Image in greyscale" class="figure mx-auto d-block"></figure><p>Above we have exactly the same underying data matrix, but in
greyscale. Zero maps to black, 255 maps to white, and 128 maps to medium
grey. Here we only have a single channel in the data and utilize a
grayscale color map to represent the luminance, or intensity of the data
and correspondingly this channel is referred to as the luminance
channel.</p>
</section><section><h2 class="section-heading" id="even-more-colours">Even more colours<a class="anchor" aria-label="anchor" href="#even-more-colours"></a>
</h2>
<hr class="half-width">
<p>This is all well and good at this scale, but what happens when we
instead have a picture of a natural landscape that contains millions of
colours. Having a one to one mapping of number to colour like this would
be inefficient and make adjustments and building tools to do so very
difficult. Rather than larger numbers, the solution is to have more
numbers in more dimensions. Storing the numbers in a multi-dimensional
matrix where each colour or property like transparency is associated
with its own dimension allows for individual contributions to a pixel to
be adjusted independently. This ability to manipulate properties of
groups of pixels separately will be key to certain techniques explored
in later chapters of this lesson. To get started let’s see an example of
how different dimensions of information combine to produce a set of
pixels using a 4 x 4 matrix with 3 dimensions for the colours red,
green, and blue. Rather than loading it from a file, we will generate
this example using NumPy.</p>
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="co"># set the random seed so we all get the same matrix</span></span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a>pseudorandomizer <span class="op">=</span> np.random.RandomState(<span class="dv">2021</span>)</span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a><span class="co"># create a 4 × 4 checkerboard of random colours</span></span>
<span id="cb16-4"><a href="#cb16-4" tabindex="-1"></a>checkerboard <span class="op">=</span> pseudorandomizer.randint(<span class="dv">0</span>, <span class="dv">255</span>, size<span class="op">=</span>(<span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">3</span>))</span>
<span id="cb16-5"><a href="#cb16-5" tabindex="-1"></a><span class="co"># restore the default map as you show the image</span></span>
<span id="cb16-6"><a href="#cb16-6" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb16-7"><a href="#cb16-7" tabindex="-1"></a>plt.imshow(checkerboard)</span>
<span id="cb16-8"><a href="#cb16-8" tabindex="-1"></a><span class="co"># display the arrays</span></span>
<span id="cb16-9"><a href="#cb16-9" tabindex="-1"></a><span class="bu">print</span>(checkerboard)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>[[[116  85  57]
  [128 109  94]
  [214  44  62]
  [219 157  21]]

 [[ 93 152 140]
  [246 198 102]
  [ 70  33 101]
  [  7   1 110]]

 [[225 124 229]
  [154 194 176]
  [227  63  49]
  [144 178  54]]

 [[123 180  93]
  [120   5  49]
  [166 234 142]
  [ 71  85  70]]]</code></pre>
</div>
<figure><img src="../fig/checkerboard.png" alt="Image of checkerboard" class="figure mx-auto d-block"></figure><p>Previously we had one number being mapped to one colour or intensity.
Now we are combining the effect of 3 numbers to arrive at a single
colour value. Let’s see an example of that using the blue square at the
end of the second row, which has the index [1, 3].</p>
<div class="codewrapper sourceCode" id="cb18">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a><span class="co"># extract all the colour information for the blue square</span></span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a>upper_right_square <span class="op">=</span> checkerboard[<span class="dv">1</span>, <span class="dv">3</span>, :]</span>
<span id="cb18-3"><a href="#cb18-3" tabindex="-1"></a>upper_right_square</span></code></pre>
</div>
<p>This outputs: array([ 7, 1, 110]) The integers in order represent
Red, Green, and Blue. Looking at the 3 values and knowing how they map,
can help us understand why it is blue. If we divide each value by 255,
which is the maximum, we can determine how much it is contributing
relative to its maximum potential. Effectively, the red is at 7/255 or
2.8 percent of its potential, the green is at 1/255 or 0.4 percent, and
blue is 110/255 or 43.1 percent of its potential. So when you mix those
three intensities of colour, blue is winning by a wide margin, but the
red and green still contribute to make it a slightly different shade of
blue than 0,0,110 would be on its own.</p>
<p>These colours mapped to dimensions of the matrix may be referred to
as channels. It may be helpful to display each of these channels
independently, to help us understand what is happening. We can do that
by multiplying our image array representation with a 1d matrix that has
a one for the channel we want to keep and zeros for the rest.</p>
<div class="codewrapper sourceCode" id="cb19">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a>red_channel <span class="op">=</span> checkerboard <span class="op">*</span> [<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>]</span>
<span id="cb19-2"><a href="#cb19-2" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb19-3"><a href="#cb19-3" tabindex="-1"></a>plt.imshow(red_channel)</span></code></pre>
</div>
<figure><img src="../fig/checkerboard-red-channel.png" alt="Image of red channel" class="figure mx-auto d-block"></figure><div class="codewrapper sourceCode" id="cb20">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a>green_channel <span class="op">=</span> checkerboard <span class="op">*</span> [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>]</span>
<span id="cb20-2"><a href="#cb20-2" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb20-3"><a href="#cb20-3" tabindex="-1"></a>plt.imshow(green_channel)</span></code></pre>
</div>
<figure><img src="../fig/checkerboard-green-channel.png" alt="Image of green channel" class="figure mx-auto d-block"></figure><div class="codewrapper sourceCode" id="cb21">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" tabindex="-1"></a>blue_channel <span class="op">=</span> checkerboard <span class="op">*</span> [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>]</span>
<span id="cb21-2"><a href="#cb21-2" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb21-3"><a href="#cb21-3" tabindex="-1"></a>plt.imshow(blue_channel)</span></code></pre>
</div>
<figure><img src="../fig/checkerboard-blue-channel.png" alt="Image of blue channel" class="figure mx-auto d-block"></figure><p>If we look at the upper [1, 3] square in all three figures, we can
see each of those colour contributions in action. Notice that there are
several squares in the blue figure that look even more intensely blue
than square [1, 3]. When all three channels are combined though, the
blue light of those squares is being diluted by the relative strength of
red and green being mixed in with them.</p>
</section><section><h2 class="section-heading" id="bit-rgb-colour">24-bit RGB colour<a class="anchor" aria-label="anchor" href="#bit-rgb-colour"></a>
</h2>
<hr class="half-width">
<p>This last colour model we used, known as the <em>RGB (Red, Green,
Blue)</em> model, is the most common.</p>
<p>As we saw, the RGB model is an <em>additive</em> colour model, which
means that the primary colours are mixed together to form other colours.
Most frequently, the amount of the primary colour added is represented
as an integer in the closed range [0, 255] as seen in the example.
Therefore, there are 256 discrete amounts of each primary colour that
can be added to produce another colour. The number of discrete amounts
of each colour, 256, corresponds to the number of bits used to hold the
colour channel value, which is eight (2<sup>8</sup>=256). Since we have
three channels with 8 bits for each (8+8+8=24), this is called 24-bit
colour depth.</p>
<p>Any particular colour in the RGB model can be expressed by a triplet
of integers in [0, 255], representing the red, green, and blue channels,
respectively. A larger number in a channel means that more of that
primary colour is present.</p>
<div id="thinking-about-rgb-colours-5-min" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="thinking-about-rgb-colours-5-min" class="callout-inner">
<h3 class="callout-title">Thinking about RGB colours (5 min)</h3>
<div class="callout-content">
<p>Suppose that we represent colours as triples (r, g, b), where each of
r, g, and b is an integer in [0, 255]. What colours are represented by
each of these triples? (Try to answer these questions without reading
further.)</p>
<ol style="list-style-type: decimal">
<li>(255, 0, 0)</li>
<li>(0, 255, 0)</li>
<li>(0, 0, 255)</li>
<li>(255, 255, 255)</li>
<li>(0, 0, 0)</li>
<li>(128, 128, 128)</li>
</ol>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" aria-labelledby="headingSolution2" data-bs-parent="#accordionSolution2">
<div class="accordion-body">
<ol style="list-style-type: decimal">
<li>(255, 0, 0) represents red, because the red channel is maximised,
while the other two channels have the minimum values.</li>
<li>(0, 255, 0) represents green.</li>
<li>(0, 0, 255) represents blue.</li>
<li>(255, 255, 255) is a little harder. When we mix the maximum value of
all three colour channels, we see the colour white.</li>
<li>(0, 0, 0) represents the absence of all colour, or black.</li>
<li>(128, 128, 128) represents a medium shade of gray. Note that the
24-bit RGB colour model provides at least 254 shades of gray, rather
than only fifty.</li>
</ol>
<p>Note that the RGB colour model may run contrary to your experience,
especially if you have mixed primary colours of paint to create new
colours. In the RGB model, the <em>lack of</em> any colour is black,
while the <em>maximum amount</em> of each of the primary colours is
white. With physical paint, we might start with a white base, and then
add differing amounts of other paints to produce a darker shade.</p>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="image-formats">Image formats<a class="anchor" aria-label="anchor" href="#image-formats"></a>
</h2>
<hr class="half-width">
<p>Although the images we will manipulate in our programs are
conceptualised as rectangular arrays of RGB triplets, they are not
necessarily created, stored, or transmitted in that format. There are
several image formats we might encounter, and we should know the basics
of at least of few of them. Some formats we might encounter, and their
file extensions, are shown in this table:</p>
<table class="table">
<thead><tr class="header">
<th align="left">Format</th>
<th align="left">Extension</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">Device-Independent Bitmap (BMP)</td>
<td align="left">.bmp</td>
</tr>
<tr class="even">
<td align="left">Joint Photographic Experts Group (JPEG)</td>
<td align="left">.jpg or .jpeg</td>
</tr>
<tr class="odd">
<td align="left">Tagged Image File Format (TIFF)</td>
<td align="left">.tif or .tiff</td>
</tr>
</tbody>
</table></section><section><h2 class="section-heading" id="bmp">BMP<a class="anchor" aria-label="anchor" href="#bmp"></a>
</h2>
<hr class="half-width">
<p>The file format that comes closest to our preceding conceptualisation
of images is the Device-Independent Bitmap, or BMP, file format. BMP
files store raster graphics images as long sequences of binary-encoded
numbers that specify the colour of each pixel in the image. Since
computer files are one-dimensional structures, the pixel colours are
stored one row at a time. That is, the first row of pixels (those with
y-coordinate 0) are stored first, followed by the second row (those with
y-coordinate 1), and so on. Depending on how it was created, a BMP image
might have 8-bit, 16-bit, or 24-bit colour depth.</p>
<p>24-bit BMP images have a relatively simple file format, can be viewed
and loaded across a wide variety of operating systems, and have high
quality. However, BMP images are not <em>compressed</em>, resulting in
very large file sizes for any useful image resolutions.</p>
<p>The idea of image compression is important to us for two reasons:
first, compressed images have smaller file sizes, and are therefore
easier to store and transmit; and second, compressed images may not have
as much detail as their uncompressed counterparts, and so our programs
may not be able to detect some important aspect if we are working with
compressed images. Since compression is important to us, we should take
a brief detour and discuss the concept.</p>
</section><section><h2 class="section-heading" id="image-compression">Image compression<a class="anchor" aria-label="anchor" href="#image-compression"></a>
</h2>
<hr class="half-width">
<p>Before discussing additional formats, familiarity with image
compression will be helpful. Let’s delve into that subject with a
challenge. For this challenge, you will need to know about bits / bytes
and how those are used to express computer storage capacities. If you
already know, you can skip to the challenge below.</p>
<div id="bits-and-bytes" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="bits-and-bytes" class="callout-inner">
<h3 class="callout-title">Bits and bytes</h3>
<div class="callout-content">
<p>Before we talk specifically about images, we first need to understand
how numbers are stored in a modern digital computer. When we think of a
number, we do so using a <em>decimal</em>, or <em>base-10</em>
place-value number system. For example, a number like 659 is 6 ×
10<sup>2</sup> + 5 × 10<sup>1</sup> + 9 × 10<sup>0</sup>. Each digit in
the number is multiplied by a power of 10, based on where it occurs, and
there are 10 digits that can occur in each position (0, 1, 2, 3, 4, 5,
6, 7, 8, 9).</p>
<p>In principle, computers could be constructed to represent numbers in
exactly the same way. But, the electronic circuits inside a computer are
much easier to construct if we restrict the numeric base to only two,
instead of 10. (It is easier for circuitry to tell the difference
between two voltage levels than it is to differentiate among 10 levels.)
So, values in a computer are stored using a <em>binary</em>, or
<em>base-2</em> place-value number system.</p>
<p>In this system, each symbol in a number is called a <em>bit</em>
instead of a digit, and there are only two values for each bit (0 and
1). We might imagine a four-bit binary number, 1101. Using the same kind
of place-value expansion as we did above for 659, we see that 1101 = 1 ×
2<sup>3</sup> + 1 × 2<sup>2</sup> + 0 × 2<sup>1</sup> + 1 ×
2<sup>0</sup>, which if we do the math is 8 + 4 + 0 + 1, or 13 in
decimal.</p>
<p>Internally, computers have a minimum number of bits that they work
with at a given time: eight. A group of eight bits is called a
<em>byte</em>. The amount of memory (RAM) and drive space our computers
have is quantified by terms like Megabytes (MB), Gigabytes (GB), and
Terabytes (TB). The following table provides more formal definitions for
these terms.</p>
<table class="table">
<thead><tr class="header">
<th align="left">Unit</th>
<th>Abbreviation</th>
<th align="left">Size</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">Kilobyte</td>
<td>KB</td>
<td align="left">1024 bytes</td>
</tr>
<tr class="even">
<td align="left">Megabyte</td>
<td>MB</td>
<td align="left">1024 KB</td>
</tr>
<tr class="odd">
<td align="left">Gigabyte</td>
<td>GB</td>
<td align="left">1024 MB</td>
</tr>
<tr class="even">
<td align="left">Terabyte</td>
<td>TB</td>
<td align="left">1024 GB</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>Since image files can be very large, various <em>compression</em>
schemes exist for saving (approximately) the same information while
using less space. These compression techniques can be categorised as
<em>lossless</em> or <em>lossy</em>.</p>
<div class="section level3">
<h3 id="lossless-compression">Lossless compression<a class="anchor" aria-label="anchor" href="#lossless-compression"></a>
</h3>
<p>In lossless image compression, we apply some algorithm (i.e., a
computerised procedure) to the image, resulting in a file that is
significantly smaller than the uncompressed BMP file equivalent would
be. Then, when we wish to load and view or process the image, our
program reads the compressed file, and reverses the compression process,
resulting in an image that is <em>identical</em> to the original.
Nothing is lost in the process – hence the term “lossless.”</p>
<p>The general idea of lossless compression is to somehow detect long
patterns of bytes in a file that are repeated over and over, and then
assign a smaller bit pattern to represent the longer sample. Then, the
compressed file is made up of the smaller patterns, rather than the
larger ones, thus reducing the number of bytes required to save the
file. The compressed file also contains a table of the substituted
patterns and the originals, so when the file is decompressed it can be
made identical to the original before compression.</p>
<p>To provide you with a concrete example, consider the 71.5 MB white
BMP image discussed above. When put through the zip compression utility
on Microsoft Windows, the resulting .zip file is only 72 KB in size!
That is, the .zip version of the image is three orders of magnitude
smaller than the original, and it can be decompressed into a file that
is byte-for-byte the same as the original. Since the original is so
repetitious - simply the same colour triplet repeated 25,000,000 times -
the compression algorithm can dramatically reduce the size of the
file.</p>
<p>If you work with .zip or .gz archives, you are dealing with lossless
compression.</p>
</div>
<div class="section level3">
<h3 id="lossy-compression">Lossy compression<a class="anchor" aria-label="anchor" href="#lossy-compression"></a>
</h3>
<p>Lossy compression takes the original image and discards some of the
detail in it, resulting in a smaller file format. The goal is to only
throw away detail that someone viewing the image would not notice. Many
lossy compression schemes have adjustable levels of compression, so that
the image creator can choose the amount of detail that is lost. The more
detail that is sacrificed, the smaller the image files will be - but of
course, the detail and richness of the image will be lower as well.</p>
<p>This is probably fine for images that are shown on Web pages or
printed off on 4 × 6 photo paper, but may or may not be fine for
scientific work. You will have to decide whether the loss of image
quality and detail are important to your work, versus the space savings
afforded by a lossy compression format.</p>
<p>It is important to understand that once an image is saved in a lossy
compression format, the lost detail is just that - lost. I.e., unlike
lossless formats, given an image saved in a lossy format, there is no
way to reconstruct the original image in a byte-by-byte manner.</p>
</div>
</section><section><h2 class="section-heading" id="jpeg">JPEG<a class="anchor" aria-label="anchor" href="#jpeg"></a>
</h2>
<hr class="half-width">
<p>JPEG images are perhaps the most commonly encountered digital images
today. JPEG uses lossy compression, and the degree of compression can be
tuned to your liking. It supports 24-bit colour depth, and since the
format is so widely used, JPEG images can be viewed and manipulated
easily on all computing platforms.</p>
<p>Here is an example showing how JPEG compression might impact image
quality. Consider this image of several maize seedlings (scaled down
here from 11,339 × 11,336 pixels in order to fit the display).</p>
<figure><img src="../fig/quality-original.jpg" alt="Original image" class="figure mx-auto d-block"></figure><p>Now, let us zoom in and look at a small section of the label in the
original, first in the uncompressed format:</p>
<figure><img src="../fig/quality-tif.jpg" alt="Enlarged, uncompressed" class="figure mx-auto d-block"></figure><p>Here is the same area of the image, but in JPEG format. We used a
fairly aggressive compression parameter to make the JPEG, in order to
illustrate the problems you might encounter with the format.</p>
<figure><img src="../fig/quality-jpg.jpg" alt="Enlarged, compressed" class="figure mx-auto d-block"></figure><p>The JPEG image is of clearly inferior quality. It has less colour
variation and noticeable pixelation. Quality differences become even
more marked when one examines the colour histograms for each image. A
histogram shows how often each colour value appears in an image. The
histograms for the uncompressed (left) and compressed (right) images are
shown below:</p>
<figure><img src="../fig/quality-histogram.jpg" alt="Uncompressed histogram" class="figure mx-auto d-block"></figure><p>We learn how to make histograms such as these later on in the
workshop. The differences in the colour histograms are even more
apparent than in the images themselves; clearly the colours in the JPEG
image are different from the uncompressed version.</p>
<p>If the quality settings for your JPEG images are high (and the
compression rate therefore relatively low), the images may be of
sufficient quality for your work. It all depends on how much quality you
need, and what restrictions you have on image storage space. Another
consideration may be <em>where</em> the images are stored. For example,
if your images are stored in the cloud and therefore must be downloaded
to your system before you use them, you may wish to use a compressed
image format to speed up file transfer time.</p>
</section><section><h2 class="section-heading" id="png">PNG<a class="anchor" aria-label="anchor" href="#png"></a>
</h2>
<hr class="half-width">
<p>PNG images are well suited for storing diagrams. It uses a lossless
compression and is hence often used in web applications for
non-photographic images. The format is able to store RGB and plain
luminance (single channel, without an associated color) data, among
others. Image data is stored row-wise and then, per row, a simple
filter, like taking the difference of adjacent pixels, can be applied to
increase the compressability of the data. The filtered data is then
compressed in the next step and written out to the disk.</p>
</section><section><h2 class="section-heading" id="tiff">TIFF<a class="anchor" aria-label="anchor" href="#tiff"></a>
</h2>
<hr class="half-width">
<p>TIFF images are popular with publishers, graphics designers, and
photographers. TIFF images can be uncompressed, or compressed using
either lossless or lossy compression schemes, depending on the settings
used, and so TIFF images seem to have the benefits of both the BMP and
JPEG formats. The main disadvantage of TIFF images (other than the size
of images in the uncompressed version of the format) is that they are
not universally readable by image viewing and manipulation software.</p>
</section><section><h2 class="section-heading" id="metadata">Metadata<a class="anchor" aria-label="anchor" href="#metadata"></a>
</h2>
<hr class="half-width">
<p>JPEG and TIFF images support the inclusion of <em>metadata</em> in
images. Metadata is textual information that is contained within an
image file. Metadata holds information about the image itself, such as
when the image was captured, where it was captured, what type of camera
was used and with what settings, etc. We normally don’t see this
metadata when we view an image, but we can view it independently if we
wish to (see <a href="#accessing-metadata"><em>Accessing
Metadata</em></a>, below). The important thing to be aware of at this
stage is that you cannot rely on the metadata of an image being fully
preserved when you use software to process that image. The image
reader/writer library that we use throughout this lesson,
<code>imageio.v3</code>, includes metadata when saving new images but
may fail to keep certain metadata fields. In any case, remember:
<strong>if metadata is important to you, take precautions to always
preserve the original files</strong>.</p>
<div id="accessing-metadata" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="accessing-metadata" class="callout-inner">
<h3 class="callout-title">Accessing Metadata</h3>
<div class="callout-content">
<p><code>imageio.v3</code> provides a way to display or explore the
metadata associated with an image. Metadata is served independently from
pixel data:</p>
<div class="codewrapper sourceCode" id="cb22">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" tabindex="-1"></a><span class="co"># read metadata</span></span>
<span id="cb22-2"><a href="#cb22-2" tabindex="-1"></a>metadata <span class="op">=</span> iio.immeta(uri<span class="op">=</span><span class="st">"data/eight.tif"</span>)</span>
<span id="cb22-3"><a href="#cb22-3" tabindex="-1"></a><span class="co"># display the format-specific metadata</span></span>
<span id="cb22-4"><a href="#cb22-4" tabindex="-1"></a>metadata</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>{'is_fluoview': False,
 'is_nih': False,
 'is_micromanager': False,
 'is_ome': False,
 'is_lsm': False,
 'is_reduced': False,
 'is_shaped': True,
 'is_stk': False,
 'is_tiled': False,
 'is_mdgel': False,
 'compression': &lt;COMPRESSION.NONE: 1&gt;,
 'predictor': 1,
 'is_mediacy': False,
 'description': '{"shape": [5, 3]}',
 'description1': '',
 'is_imagej': False,
 'software': 'tifffile.py',
 'resolution_unit': 1,
 'resolution': (1.0, 1.0, 'NONE')}</code></pre>
</div>
<p>Other software exists that can help you handle metadata, e.g., <a href="https://imagej.net/Fiji" class="external-link">Fiji</a> and <a href="https://imagemagick.org/index.php" class="external-link">ImageMagick</a>. You may want
to explore these options if you need to work with the metadata of your
images.</p>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="summary-of-image-formats-used-in-this-lesson">Summary of image formats used in this lesson<a class="anchor" aria-label="anchor" href="#summary-of-image-formats-used-in-this-lesson"></a>
</h2>
<hr class="half-width">
<p>The following table summarises the characteristics of the BMP, JPEG,
and TIFF image formats:</p>
<table class="table">
<colgroup>
<col width="19%">
<col width="15%">
<col width="12%">
<col width="26%">
<col width="26%">
</colgroup>
<thead><tr class="header">
<th align="left">Format</th>
<th align="left">Compression</th>
<th align="left">Metadata</th>
<th align="left">Advantages</th>
<th align="left">Disadvantages</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">BMP</td>
<td align="left">None</td>
<td align="left">None</td>
<td align="left">Universally viewable, high quality</td>
<td align="left">Large file sizes</td>
</tr>
<tr class="even">
<td align="left">JPEG</td>
<td align="left">Lossy</td>
<td align="left">Yes</td>
<td align="left">Universally viewable, smaller file size</td>
<td align="left">Detail may be lost</td>
</tr>
<tr class="odd">
<td align="left">PNG</td>
<td align="left">Lossless</td>
<td align="left"><a href="https://www.w3.org/TR/PNG/#11keywords" class="external-link">Yes</a></td>
<td align="left">Universally viewable, <a href="https://www.w3.org/TR/PNG/" class="external-link">open standard</a>, smaller file
size</td>
<td align="left">Metadata less flexible than TIFF, RGB only</td>
</tr>
<tr class="even">
<td align="left">TIFF</td>
<td align="left">None, lossy, or lossless</td>
<td align="left">Yes</td>
<td align="left">High quality or smaller file size</td>
<td align="left">Not universally viewable</td>
</tr>
</tbody>
</table>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul>
<li>Digital images are represented as rectangular arrays of square
pixels.</li>
<li>Digital images use a left-hand coordinate system, with the origin in
the upper left corner, the x-axis running to the right, and the y-axis
running down. Some learners may prefer to think in terms of counting
down rows for the y-axis and across columns for the x-axis. Thus, we
will make an effort to allow for both approaches in our lesson
presentation.</li>
<li>Most frequently, digital images use an additive RGB model, with
eight bits for the red, green, and blue channels.</li>
<li>scikit-image images are stored as multi-dimensional NumPy
arrays.</li>
<li>In scikit-image images, the red channel is specified first, then the
green, then the blue, i.e., RGB.</li>
<li>Lossless compression retains all the details in an image, but lossy
compression results in loss of some of the original image detail.</li>
<li>BMP images are uncompressed, meaning they have high quality but also
that their file sizes are large.</li>
<li>JPEG images use lossy compression, meaning that their file sizes are
smaller, but image quality may suffer.</li>
<li>TIFF images can be uncompressed or compressed with lossy or lossless
compression.</li>
<li>Depending on the camera or sensor, various useful pieces of
information may be stored in an image file, in the image metadata.</li>
</ul>
</div>
</div>
</div>
</section></section><section id="aio-03-skimage-images"><p>Content from <a href="03-skimage-images.html">Working with scikit-image</a></p>
<hr>
<p>Last updated on 2024-03-19 |

        <a href="https://github.com/govekk/image-processing/edit/main/episodes/03-skimage-images.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 120 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How can the scikit-image Python computer vision library be used to
work with images?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Read and save images with imageio.</li>
<li>Display images with Matplotlib.</li>
<li>Understand RGB vs Multichannel bioimages</li>
<li>Extract sub-images using array slicing.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p>We have covered much of how images are represented in computer
software. In this episode we will learn some more methods for accessing
and changing digital images.</p>
<section><h2 class="section-heading" id="first-import-the-packages-needed-for-this-episode">First, import the packages needed for this episode<a class="anchor" aria-label="anchor" href="#first-import-the-packages-needed-for-this-episode"></a>
</h2>
<hr class="half-width">
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">import</span> imageio.v3 <span class="im">as</span> iio</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">import</span> ipympl</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="im">import</span> skimage <span class="im">as</span> ski</span></code></pre>
</div>
</section><section><h2 class="section-heading" id="reading-and-displaying-images">Reading and displaying images<a class="anchor" aria-label="anchor" href="#reading-and-displaying-images"></a>
</h2>
<hr class="half-width">
<p>Imageio provides intuitive functions for reading and writing (saving)
images. All of the popular image formats, such as BMP, PNG, JPEG, and
TIFF are supported, along with several more esoteric formats. Check the
<a href="https://imageio.readthedocs.io/en/stable/formats/index.html" class="external-link">Supported
Formats docs</a> for a list of all formats. Matplotlib provides a large
collection of plotting utilities.</p>
<p>Let us examine a simple Python program to load, display, and save an
image to a different format. Here are the first few lines:</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="co">"""Python program to open, display, and save an image."""</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="co"># read image</span></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>cells <span class="op">=</span> iio.imread(uri<span class="op">=</span><span class="st">"data/hela-cells-8bit.tif"</span>)</span></code></pre>
</div>
<p>We use the <code>iio.imread()</code> function to read a TIFF image
entitled <strong>hela-cells-8bit</strong>. Imageio reads the image,
converts it from TIFF into a NumPy array, and returns the array; we save
the array in a variable named <code>cells</code>.</p>
<p>Next, we will do something with the image:</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>plt.imshow(cells)</span></code></pre>
</div>
<p>Once we have the image in the program, we first call
<code>plt.subplots()</code> so that we will have a fresh figure with a
set of axis independent from our previous calls. Next we call
<code>plt.imshow()</code> in order to display the image.</p>
</section><section><h2 class="section-heading" id="saving-images">Saving images<a class="anchor" aria-label="anchor" href="#saving-images"></a>
</h2>
<hr class="half-width">
<p>Another image we will use will be one of scikit-image’s example
images. These can be loaded through the skimage.data module.</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a>hed_image <span class="op">=</span> ski.data.immunohistochemistry()</span></code></pre>
</div>
<p>Let’s look at this image:</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>plt.imshow(hed_image)</span></code></pre>
</div>
<p>What if we want to keep a local copy?</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="co"># save a new version in .tif format</span></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>iio.imwrite(uri<span class="op">=</span><span class="st">"data/immunohistochemistry.tif"</span>, image<span class="op">=</span>hed_image)</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a><span class="co"># save a new version in .jpg format</span></span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a>iio.imwrite(uri<span class="op">=</span><span class="st">"data/immunohistochemistry.jpg"</span>, image<span class="op">=</span>hed_image)</span></code></pre>
</div>
<p>The final statement in the program,
<code>iio.imwrite(uri="data/immunohistochemistry.jpg", image=hed_image)</code>,
writes the image to a file named <code>immunohistochemistry.jpg</code>
in the <code>data/</code> directory. The <code>imwrite()</code> function
automatically determines the type of the file, based on the file
extension we provide. In this case, the <code>.tif</code> extension
causes the image to be saved as a TIFF, and the <code>.jpg</code>
extension causes the image to be saved as a JPG. Using Finder or File
Explorer, check out the size difference between these two files. As we
discussed in <a href="02-image-basics.html">the <em>Image Basics</em>
episode</a>, JPG is performing a lossy compression to save a smaller
file.</p>
<div id="metadata-revisited" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="metadata-revisited" class="callout-inner">
<h3 class="callout-title">Metadata, revisited</h3>
<div class="callout-content">
<p>Remember, as mentioned in the previous section, <em>images saved with
<code>imwrite()</code> will not retain all metadata associated with the
original image that was loaded into Python!</em> If the image metadata
is important to you, be sure to <strong>always keep an unchanged copy of
the original image!</strong></p>
</div>
</div>
</div>
<div id="extensions-do-not-always-dictate-file-type" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="extensions-do-not-always-dictate-file-type" class="callout-inner">
<h3 class="callout-title">Extensions do not always dictate file type</h3>
<div class="callout-content">
<p>The <code>iio.imwrite()</code> function automatically uses the file
type we specify in the file name parameter’s extension. Note that this
is not always the case. For example, if we are editing a document in
Microsoft Word, and we save the document as <code>paper.pdf</code>
instead of <code>paper.docx</code>, the file <em>is not</em> saved as a
PDF document.</p>
</div>
</div>
</div>
<div id="named-versus-positional-arguments" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="named-versus-positional-arguments" class="callout-inner">
<h3 class="callout-title">Named versus positional arguments</h3>
<div class="callout-content">
<p>When we call functions in Python, there are two ways we can specify
the necessary arguments. We can specify the arguments
<em>positionally</em>, i.e., in the order the parameters appear in the
function definition, or we can use <em>named arguments</em>.</p>
<p>For example, the <code>iio.imwrite()</code> <a href="https://imageio.readthedocs.io/en/stable/_autosummary/imageio.v3.imwrite.html" class="external-link">function
definition</a> specifies two parameters, the resource to save the image
to (e.g., a file name, an http address) and the image to write to disk.
So, we could save the chair image in the sample code above using
positional arguments like this:</p>
<p><code>iio.imwrite("data/immunohistochemistry.jpg", hed_image)</code></p>
<p>Since the function expects the first argument to be the file name,
there is no confusion about what
<code>"data/immunohistochemistry.jpg"</code> means. The same goes for
the second argument.</p>
<p>The style we will use in this workshop is to name each argument, like
this:</p>
<p><code>iio.imwrite(uri="data/immunohistochemistry.jpg", image=hed_image)</code></p>
<p>This style will make it easier for you to learn how to use the
variety of functions we will cover in this workshop.</p>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="converting-colour-images-to-grayscale">Converting colour images to grayscale<a class="anchor" aria-label="anchor" href="#converting-colour-images-to-grayscale"></a>
</h2>
<hr class="half-width">
<p>It is often easier to work with grayscale images, which have a single
channel, instead of colour images, which have three channels.
scikit-image offers the function <code>ski.color.rgb2gray()</code> to
achieve this. This function adds up the three colour channels in a way
that matches human colour perception, see <a href="https://scikit-image.org/docs/dev/api/skimage.color.html#skimage.color.rgb2gray" class="external-link">the
scikit-image documentation for details</a>. It returns a grayscale image
with floating point values in the range from 0 to 1. We can use the
function <code>ski.util.img_as_ubyte()</code> in order to convert it
back to the original data type and the data range back 0 to 255. Note
that it is often better to use image values represented by floating
point values, because using floating point numbers is numerically more
stable.</p>
<div id="colour-and-color" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="colour-and-color" class="callout-inner">
<h3 class="callout-title">Colour and <code>color</code>
</h3>
<div class="callout-content">
<p>The Carpentries generally prefers UK English spelling, which is why
we use “colour” in the explanatory text of this lesson. However,
scikit-image contains many modules and functions that include the US
English spelling, <code>color</code>. The exact spelling matters here,
e.g. you will encounter an error if you try to run
<code>ski.colour.rgb2gray()</code>. To account for this, we will use the
US English spelling, <code>color</code>, in example Python code
throughout the lesson. You will encounter a similar approach with
“centre” and <code>center</code>.</p>
</div>
</div>
</div>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="co">"""Python script to load a color image as grayscale."""</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a><span class="co"># read input image</span></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>hed_color <span class="op">=</span> iio.imread(uri<span class="op">=</span><span class="st">"data/immunohistochemistry.tif"</span>)</span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a><span class="co"># display original image</span></span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a>plt.imshow(hed_color)</span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a></span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a><span class="co"># convert to grayscale and display</span></span>
<span id="cb7-11"><a href="#cb7-11" tabindex="-1"></a>hed_gray <span class="op">=</span> ski.color.rgb2gray(hed_color)</span>
<span id="cb7-12"><a href="#cb7-12" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb7-13"><a href="#cb7-13" tabindex="-1"></a>plt.imshow(hed_gray, cmap<span class="op">=</span><span class="st">"gray"</span>)</span></code></pre>
</div>
<p>We can also load colour images of certain formats as grayscale
directly by passing the argument <code>mode="L"</code> to
<code>iio.imread()</code>.</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="co">"""Python script to load a color image as grayscale."""</span></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a><span class="co"># read input image, based on filename parameter</span></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a>hed_gray <span class="op">=</span> iio.imread(uri<span class="op">=</span><span class="st">"data/immunohistochemistry.jpg"</span>, mode<span class="op">=</span><span class="st">"L"</span>)</span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a><span class="co"># display grayscale image</span></span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a>plt.imshow(hed_gray, cmap<span class="op">=</span><span class="st">"gray"</span>)</span></code></pre>
</div>
<p>The first argument to <code>iio.imread()</code> is the filename of
the image. The second argument <code>mode="L"</code> determines the type
and range of the pixel values in the image (e.g., an 8-bit pixel has a
range of 0-255). This argument is forwarded to the <code>pillow</code>
backend, a Python imaging library for which mode “L” means 8-bit pixels
and single-channel (i.e., grayscale). The backend used by
<code>iio.imread()</code> may be specified as an optional argument: to
use <code>pillow</code>, you would pass <code>plugin="pillow"</code>. If
the backend is not specified explicitly, <code>iio.imread()</code>
determines the backend to use based on the image type.</p>
<div id="loading-images-with-imageio-pixel-type-and-depth" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="loading-images-with-imageio-pixel-type-and-depth" class="callout-inner">
<h3 class="callout-title">Loading images with imageio: Pixel type and depth</h3>
<div class="callout-content">
<p>When loading an image with <code>mode="L"</code>, the pixel values
are stored as 8-bit integer numbers that can take values in the range
0-255. However, pixel values may also be stored with other types and
ranges. For example, some scikit-image functions return the pixel values
as floating point numbers in the range 0-1. The type and range of the
pixel values are important for the colorscale when plotting, and for
masking and thresholding images as we will see later in the lesson. If
you are unsure about the type of the pixel values, you can inspect it
with <code>print(image.dtype)</code>. For the example above, you should
find that it is <code>dtype('uint8')</code> indicating 8-bit integer
numbers.</p>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="multichannel-images">Multichannel images<a class="anchor" aria-label="anchor" href="#multichannel-images"></a>
</h2>
<hr class="half-width">
<p>In <a href="02-image-basics.html">the <em>Image Basics</em>
episode</a> we discussed how color is represented by three numbers in
RGB images. The immunohistochemistry image we have been using is an RGB
image. The tissue was stained with hematoxylin (blue) and DAB (brown),
but if we split apart the RGB color channels, each one isn’t
particularly useful in identifying that staining:</p>
<figure><img src="../fig/hed-rgb-separate.png" alt="A grid showing each RGB color of the immunohistochemistry image" class="figure mx-auto d-block"></figure><p>In contrast, the image of HeLa cells is a multichannel image. We can
conveniently read it and view it using the same functions as RGB, since
it’s still 8bit with three channels. But in reality, those channels
represent fluorescence of three different parts of the cell: lysosomes,
mitochondria and nucleus. Currently, the lysosomes are marked in red,
mitochondria in green, and nucleus in blue, but it doesn’t really matter
what color each is represented by. It’s often more useful to view
multichannel images one channel at a time.</p>
<figure><img src="../fig/hela-cells-channels.png" alt="A grid showing each channel of the hela cells image" class="figure mx-auto d-block"></figure><div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a>cells <span class="op">=</span> iio.imread(uri<span class="op">=</span><span class="st">"data/hela-cells-8bit.tif"</span>)</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>nuclei <span class="op">=</span> cells[:,:,<span class="dv">2</span>]</span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a>plt.imshow(nuclei)</span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a>mitochondria <span class="op">=</span> cells[:,:,<span class="dv">1</span>]</span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a>plt.imshow(mitochondria, vmax<span class="op">=</span><span class="dv">255</span>)</span></code></pre>
</div>
<div id="plotting-single-channel-images-cmap-vmin-vmax" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="plotting-single-channel-images-cmap-vmin-vmax" class="callout-inner">
<h3 class="callout-title">Plotting single channel images (cmap, vmin, vmax)</h3>
<div class="callout-content">
<p>Compared to a colour image, a grayscale image or a single channel
contains only a single intensity value per pixel. When we plot such an
image with <code>plt.imshow</code>, Matplotlib uses a colour map, to
assign each intensity value a colour. The default colour map is called
“viridis” and maps low values to purple and high values to yellow. We
can instruct Matplotlib to map low values to black and high values to
white instead, by calling <code>plt.imshow</code> with
<code>cmap="gray"</code>. <a href="https://matplotlib.org/stable/gallery/color/colormap_reference.html" class="external-link">The
documentation contains an overview of pre-defined colour maps</a>.</p>
<p>Furthermore, Matplotlib determines the minimum and maximum values of
the colour map dynamically from the image, by default. That means that
in an image where the minimum is 64 and the maximum is 192, those values
will be mapped to black and white respectively (and not dark gray and
light gray as you might expect). If there are defined minimum and
maximum vales, you can specify them via <code>vmin</code> and
<code>vmax</code> to get the desired output.</p>
<p>If you forget about this, it can lead to unexpected results.</p>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="access-via-slicing">Access via slicing<a class="anchor" aria-label="anchor" href="#access-via-slicing"></a>
</h2>
<hr class="half-width">
<p>As noted in the previous lesson scikit-image images are stored as
NumPy arrays, so we can use array slicing to select rectangular areas of
an image. Then, we can save the selection as a new image, change the
pixels in the image, and so on. It is important to remember that
coordinates are specified in <em>(ry, cx)</em> order and that colour
values are specified in <em>(r, g, b)</em> order when doing these
manipulations.</p>
<p>Consider this image of HeLa cells, and suppose that we want to create
a sub-image with just one of the cells.</p>
<figure><img src="../fig/hela-cells-8bit.jpg" alt="HeLa cells image" class="figure mx-auto d-block"></figure><p>Using <code>matplotlib.pyplot.imshow</code> we can determine the
coordinates of the corners of the area we wish to extract by hovering
the mouse near the points of interest and noting the coordinates
(remember to run <code>%matplotlib widget</code> first if you haven’t
already). If we do that, we might settle on a rectangular area with an
upper-left coordinate of <em>(180, 280)</em> and a lower-right
coordinate of <em>(520, 500)</em>, as shown in this version of the HeLa
picture:</p>
<figure><img src="../fig/hela-cells-coordinates.jpg" alt="Sub picture coordinates for one cell" class="figure mx-auto d-block"></figure><p>Note that the coordinates in the preceding image are specified in
<em>(cx, ry)</em> order. Now if our entire HeLa cell image is stored as
a NumPy array named <code>image</code>, we can create a new image of the
selected region with a statement like this:</p>
<p><code>clip = image[280:501, 180:521, :]</code></p>
<p>Our array slicing specifies the range of y-coordinates or rows first,
<code>280:501</code>, and then the range of x-coordinates or columns,
<code>180:521</code>. Note we go one beyond the maximum value in each
dimension, so that the entire desired area is selected. The third part
of the slice, <code>:</code>, indicates that we want all three colour
channels in our new image.</p>
<p>A script to create the subimage would start by loading the image:</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="co">"""Python script demonstrating image modification and creation via NumPy array slicing."""</span></span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a><span class="co"># load and display original image</span></span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a>cells <span class="op">=</span> iio.imread(uri<span class="op">=</span><span class="st">"data/hela-cells-8bit.tif"</span>)</span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a>cells <span class="op">=</span> np.array(cells)</span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a>plt.imshow(cells)</span></code></pre>
</div>
<p>Then we use array slicing to create a new image with our selected
area and then display the new image.</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="co"># extract, display, and save sub-image</span></span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a>cell_one <span class="op">=</span> cells[<span class="dv">280</span>:<span class="dv">501</span>, <span class="dv">180</span>:<span class="dv">521</span>, :]</span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a>plt.imshow(cell_one)</span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a>iio.imwrite(uri<span class="op">=</span><span class="st">"data/cell_one.tif"</span>, image<span class="op">=</span>cell_one)</span></code></pre>
</div>
<p>We can also change the values in an image, as shown next.</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="co"># replace clipped area with sampled color</span></span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a>color <span class="op">=</span> cells[<span class="dv">30</span>,<span class="dv">30</span>]</span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a>cells[<span class="dv">280</span>:<span class="dv">501</span>, <span class="dv">180</span>:<span class="dv">521</span>] <span class="op">=</span> color</span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a>plt.imshow(cells)</span></code></pre>
</div>
<p>First, we sample a single pixel’s colour at a particular location of
the image, saving it in a variable named <code>color</code>, which
creates a 1 × 1 × 3 NumPy array with the blue, green, and red colour
values for the pixel located at <em>(ry = 30, cx = 30)</em>. Then, with
the <code>img[280:501, 180:521] = color</code> command, we modify the
image in the specified area. From a NumPy perspective, this changes all
the pixel values within that range to array saved in the
<code>color</code> variable. In this case, the command “erases” that
area of the image, replacing the words with the background black color,
as shown in the final image produced by the program:</p>
<figure><img src="../fig/hela-cells-erased.jpg" alt='"Erased" one cell from hela cells image' class="figure mx-auto d-block"></figure><div id="practicing-with-slices-10-min" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="practicing-with-slices-10-min" class="callout-inner">
<h3 class="callout-title">Practicing with slices (10 min)</h3>
<div class="callout-content">
<p>Repeat the above exercise for the leftmost cell. Using the techniques
you just learned, write a script that creates, displays, and saves a
sub-image containing only the leftmost cell from the HeLa cells
image.</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<p>Here is the completed Python program to select only the leftmost cell
in the image</p>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="co">"""Python script to extract a sub-image containing only the leftmost cell in an existing image."""</span></span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a><span class="co"># load and display original image</span></span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a>cells <span class="op">=</span> iio.imread(uri<span class="op">=</span><span class="st">"data/hela-cells-8bit.tif"</span>)</span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a>plt.imshow(cells)</span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a></span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a><span class="co"># extract and display sub-image</span></span>
<span id="cb13-9"><a href="#cb13-9" tabindex="-1"></a>cell_two <span class="op">=</span> cells[<span class="dv">70</span>:<span class="dv">391</span>, <span class="dv">20</span>:<span class="dv">211</span>, :]</span>
<span id="cb13-10"><a href="#cb13-10" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb13-11"><a href="#cb13-11" tabindex="-1"></a>plt.imshow(cell_two)</span>
<span id="cb13-12"><a href="#cb13-12" tabindex="-1"></a></span>
<span id="cb13-13"><a href="#cb13-13" tabindex="-1"></a></span>
<span id="cb13-14"><a href="#cb13-14" tabindex="-1"></a><span class="co"># save sub-image</span></span>
<span id="cb13-15"><a href="#cb13-15" tabindex="-1"></a>iio.imwrite(uri<span class="op">=</span><span class="st">"data/cell_two.jpg"</span>, image<span class="op">=</span>cell_two)</span></code></pre>
</div>
</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul>
<li>Images are read from disk with the <code>iio.imread()</code>
function.</li>
<li>We create a window that automatically scales the displayed image
with Matplotlib and calling <code>imshow()</code> on the global figure
object.</li>
<li>Colour images can be transformed to grayscale using
<code>ski.color.rgb2gray()</code> or, in many cases, be read as
grayscale directly by passing the argument <code>mode="L"</code> to
<code>iio.imread()</code>.</li>
<li>Array slicing can be used to extract sub-images or modify areas of
images, e.g., <code>clip = image[280:501, 180:521, :]</code>.</li>
<li>Metadata is not retained when images are loaded as NumPy arrays
using <code>iio.imread()</code>.</li>
</ul>
</div>
</div>
</div>
</section></section><section id="aio-04-drawing"><p>Content from <a href="04-drawing.html">Drawing and Bitwise Operations</a></p>
<hr>
<p>Last updated on 2024-03-19 |

        <a href="https://github.com/govekk/image-processing/edit/main/episodes/04-drawing.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 90 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How can we draw on scikit-image images and use bitwise operations
and masks to select certain parts of an image?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Create a blank, black scikit-image image.</li>
<li>Draw rectangles and other shapes on scikit-image images.</li>
<li>Explain how a white shape on a black background can be used as a
mask to select specific parts of an image.</li>
<li>Use bitwise operations to apply a mask to an image.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p>The next series of episodes covers a basic toolkit of scikit-image
operators. With these tools, we will be able to create programs to
perform simple analyses of images based on changes in colour or
shape.</p>
<section><h2 class="section-heading" id="first-import-the-packages-needed-for-this-episode">First, import the packages needed for this episode<a class="anchor" aria-label="anchor" href="#first-import-the-packages-needed-for-this-episode"></a>
</h2>
<hr class="half-width">
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">import</span> imageio.v3 <span class="im">as</span> iio</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">import</span> ipympl</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="im">import</span> skimage <span class="im">as</span> ski</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="op">%</span>matplotlib widget</span></code></pre>
</div>
<p>Here, we import the same packages as earlier in the lesson.</p>
</section><section><h2 class="section-heading" id="drawing-on-images">Drawing on images<a class="anchor" aria-label="anchor" href="#drawing-on-images"></a>
</h2>
<hr class="half-width">
<p>Often we wish to select only a portion of an image to analyze, and
ignore the rest. Creating a rectangular sub-image with slicing, as we
did in <a href="03-skimage-images.html">the <em>Working with
scikit-image</em> episode</a> is one option for simple cases. Another
option is to create another special image, of the same size as the
original, with white pixels indicating the region to save and black
pixels everywhere else. Such an image is called a <em>mask</em>. In
preparing a mask, we sometimes need to be able to draw a shape - a
circle or a rectangle, say - on a black image. scikit-image provides
tools to do that.</p>
<p>Let’s repeat the challenge at the end of <a href="03-skimage-images.html">the <em>Working with scikit-image</em>
episode</a>, to select only the leftmost cell of HeLa cells image using
a rectangular selection.</p>
<p>A Python program to create a mask to select only that area of the
image would start with a now-familiar section of code to open and
display the original image:</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="co"># Load and display the original image</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>cells<span class="op">=</span> iio.imread(uri<span class="op">=</span><span class="st">"data/hela-cells-8bit.tif"</span>)</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>plt.imshow(cells)</span></code></pre>
</div>
<p>We load and display the initial image in the same way we have done
before.</p>
<p>NumPy allows indexing of images/arrays with “boolean” arrays of the
same size. Indexing with a boolean array is also called mask indexing.
The “pixels” in such a mask array can only take two values:
<code>True</code> or <code>False</code>. When indexing an image with
such a mask, only pixel values at positions where the mask is
<code>True</code> are accessed. But first, we need to generate a mask
array of the same size as the image. Luckily, the NumPy library provides
a function to create just such an array. The next section of code shows
how:</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="co"># Create the basic mask</span></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>mask <span class="op">=</span> np.ones(shape<span class="op">=</span>cells.shape[<span class="dv">0</span>:<span class="dv">2</span>], dtype<span class="op">=</span><span class="st">"bool"</span>)</span></code></pre>
</div>
<p>The first argument to the <code>ones()</code> function is the shape
of the original image, so that our mask will be exactly the same size as
the original. Notice, that we have only used the first two indices of
our shape. We omitted the channel dimension. Indexing with such a mask
will change all channel values simultaneously. The second argument,
<code>dtype = "bool"</code>, indicates that the elements in the array
should be booleans - i.e., values are either <code>True</code> or
<code>False</code>. Thus, even though we use <code>np.ones()</code> to
create the mask, its pixel values are in fact not <code>1</code> but
<code>True</code>. You could check this, e.g., by
<code>print(mask[0, 0])</code>.</p>
<p>Next, we draw a filled, rectangle on the mask:</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="co"># Draw filled rectangle on the mask image</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>rr, cc <span class="op">=</span> ski.draw.rectangle(start<span class="op">=</span>(<span class="dv">70</span>,<span class="dv">20</span>), end<span class="op">=</span>(<span class="dv">391</span>,<span class="dv">211</span>))</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>mask[rr, cc] <span class="op">=</span> <span class="va">False</span></span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a><span class="co"># Display mask image</span></span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a>plt.imshow(mask, cmap<span class="op">=</span><span class="st">"gray"</span>)</span></code></pre>
</div>
<p>Here is what our constructed mask looks like: <img src="../fig/cells-rectangle-mask.jpg" alt="Cells rectangle mask" class="figure"></p>
<p>The parameters of the <code>rectangle()</code> function
<code>(70,20)</code> and <code>(391,211)</code>, are the coordinates of
the upper-left (<code>start</code>) and lower-right (<code>end</code>)
corners of a rectangle in <em>(ry, cx)</em> order. The function returns
the rectangle as row (<code>rr</code>) and column (<code>cc</code>)
coordinate arrays.</p>
<div id="check-the-documentation" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="check-the-documentation" class="callout-inner">
<h3 class="callout-title">Check the documentation!</h3>
<div class="callout-content">
<p>When using an scikit-image function for the first time - or the fifth
time - it is wise to check how the function is used, via <a href="https://scikit-image.org/docs/dev/user_guide" class="external-link">the scikit-image
documentation</a> or other usage examples on programming-related sites
such as <a href="https://stackoverflow.com/" class="external-link">Stack Overflow</a>. Basic
information about scikit-image functions can be found interactively in
Python, via commands like <code>help(ski)</code> or
<code>help(ski.draw.rectangle)</code>. Take notes in your lab notebook.
And, it is always wise to run some test code to verify that the
functions your program uses are behaving in the manner you intend.</p>
</div>
</div>
</div>
<div id="variable-naming-conventions" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="variable-naming-conventions" class="callout-inner">
<h3 class="callout-title">Variable naming conventions!</h3>
<div class="callout-content">
<p>You may have wondered why we called the return values of the
rectangle function <code>rr</code> and <code>cc</code>?! You may have
guessed that <code>r</code> is short for <code>row</code> and
<code>c</code> is short for <code>column</code>. However, the rectangle
function returns mutiple rows and columns; thus we used a convention of
doubling the letter <code>r</code> to <code>rr</code> (and
<code>c</code> to <code>cc</code>) to indicate that those are multiple
values. In fact it may have even been clearer to name those variables
<code>rows</code> and <code>columns</code>; however this would have been
also much longer. Whatever you decide to do, try to stick to some
already existing conventions, such that it is easier for other people to
understand your code.</p>
</div>
</div>
</div>
<div id="other-drawing-operations-15-min" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="other-drawing-operations-15-min" class="callout-inner">
<h3 class="callout-title">Other drawing operations (15 min)</h3>
<div class="callout-content">
<p>There are other functions for drawing on images, in addition to the
<code>ski.draw.rectangle()</code> function. We can draw circles, lines,
text, and other shapes as well. These drawing functions may be useful
later on, to help annotate images that our programs produce. Practice
some of these functions here.</p>
<p>Circles can be drawn with the <code>ski.draw.disk()</code> function,
which takes two parameters: the (ry, cx) point of the centre of the
circle, and the radius of the circle. There is an optional
<code>shape</code> parameter that can be supplied to this function. It
will limit the output coordinates for cases where the circle dimensions
exceed the ones of the image.</p>
<p>Lines can be drawn with the <code>ski.draw.line()</code> function,
which takes four parameters: the (ry, cx) coordinate of one end of the
line, and the (ry, cx) coordinate of the other end of the line.</p>
<p>Other drawing functions supported by scikit-image can be found in <a href="https://scikit-image.org/docs/dev/api/skimage.draw.html?highlight=draw#module-skimage.draw" class="external-link">the
scikit-image reference pages</a>.</p>
<p>First let’s make an empty, black image with a size of 800x600 pixels.
Recall that a colour image has three channels for the colours red,
green, and blue (RGB, cf. <a href="03-skimage-images.html">Image
Basics</a>). Hence we need to create a 3D array of shape
<code>(600, 800, 3)</code> where the last dimension represents the RGB
colour channels.</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="co"># create the black canvas</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>canvas <span class="op">=</span> np.zeros(shape<span class="op">=</span>(<span class="dv">600</span>, <span class="dv">800</span>, <span class="dv">3</span>), dtype<span class="op">=</span><span class="st">"uint8"</span>)</span></code></pre>
</div>
<p>Now your task is to draw some other coloured shapes and lines on the
image, perhaps something like this:</p>
<figure><img src="../fig/drawing-practice.jpg" alt="Sample shapes" class="figure mx-auto d-block"></figure>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<p>Drawing a circle:</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="co"># Draw a blue circle with centre (200, 300) in (ry, cx) coordinates, and radius 100</span></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>rr, cc <span class="op">=</span> ski.draw.disk(center<span class="op">=</span>(<span class="dv">200</span>, <span class="dv">300</span>), radius<span class="op">=</span><span class="dv">100</span>, shape<span class="op">=</span>canvas.shape[<span class="dv">0</span>:<span class="dv">2</span>])</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>canvas[rr, cc] <span class="op">=</span> (<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">255</span>)</span></code></pre>
</div>
<p>Drawing a line:</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="co"># Draw a green line from (400, 200) to (500, 700) in (ry, cx) coordinates</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>rr, cc <span class="op">=</span> ski.draw.line(r0<span class="op">=</span><span class="dv">400</span>, c0<span class="op">=</span><span class="dv">200</span>, r1<span class="op">=</span><span class="dv">500</span>, c1<span class="op">=</span><span class="dv">700</span>)</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>canvas[rr, cc] <span class="op">=</span> (<span class="dv">0</span>, <span class="dv">255</span>, <span class="dv">0</span>)</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="co"># Display the image</span></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>plt.imshow(canvas)</span></code></pre>
</div>
<p>We could expand this solution, if we wanted, to draw rectangles,
circles and lines at random positions within our black canvas. To do
this, we could use the <code>random</code> python module, and the
function <code>random.randrange</code>, which can produce random numbers
within a certain range.</p>
<p>Let’s draw 15 randomly placed circles:</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a><span class="co"># create the black canvas</span></span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a>canvas <span class="op">=</span> np.zeros(shape<span class="op">=</span>(<span class="dv">600</span>, <span class="dv">800</span>, <span class="dv">3</span>), dtype<span class="op">=</span><span class="st">"uint8"</span>)</span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a><span class="co"># draw a blue circle at a random location 15 times</span></span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">15</span>):</span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a>    rr, cc <span class="op">=</span> ski.draw.disk(center<span class="op">=</span>(</span>
<span id="cb9-9"><a href="#cb9-9" tabindex="-1"></a>         random.randrange(<span class="dv">600</span>),</span>
<span id="cb9-10"><a href="#cb9-10" tabindex="-1"></a>         random.randrange(<span class="dv">800</span>)),</span>
<span id="cb9-11"><a href="#cb9-11" tabindex="-1"></a>         radius<span class="op">=</span><span class="dv">50</span>,</span>
<span id="cb9-12"><a href="#cb9-12" tabindex="-1"></a>         shape<span class="op">=</span>canvas.shape[<span class="dv">0</span>:<span class="dv">2</span>],</span>
<span id="cb9-13"><a href="#cb9-13" tabindex="-1"></a>        )</span>
<span id="cb9-14"><a href="#cb9-14" tabindex="-1"></a>    canvas[rr, cc] <span class="op">=</span> (<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">255</span>)</span>
<span id="cb9-15"><a href="#cb9-15" tabindex="-1"></a></span>
<span id="cb9-16"><a href="#cb9-16" tabindex="-1"></a><span class="co"># display the results</span></span>
<span id="cb9-17"><a href="#cb9-17" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb9-18"><a href="#cb9-18" tabindex="-1"></a>plt.imshow(canvas)</span></code></pre>
</div>
<p>We could expand this even further to also randomly choose whether to
plot a rectangle, a circle, or a square. Again, we do this with the
<code>random</code> module, now using the function
<code>random.random</code> that returns a random number between 0.0 and
1.0.</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a><span class="co"># Draw 15 random shapes (rectangle, circle or line) at random positions</span></span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">15</span>):</span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a>    <span class="co"># generate a random number between 0.0 and 1.0 and use this to decide if we</span></span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a>    <span class="co"># want a circle, a line or a sphere</span></span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a>    x <span class="op">=</span> random.random()</span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a>    <span class="cf">if</span> x <span class="op">&lt;</span> <span class="fl">0.33</span>:</span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a>        <span class="co"># draw a blue circle at a random location</span></span>
<span id="cb10-10"><a href="#cb10-10" tabindex="-1"></a>        rr, cc <span class="op">=</span> ski.draw.disk(center<span class="op">=</span>(</span>
<span id="cb10-11"><a href="#cb10-11" tabindex="-1"></a>            random.randrange(<span class="dv">600</span>),</span>
<span id="cb10-12"><a href="#cb10-12" tabindex="-1"></a>            random.randrange(<span class="dv">800</span>)),</span>
<span id="cb10-13"><a href="#cb10-13" tabindex="-1"></a>            radius<span class="op">=</span><span class="dv">50</span>,</span>
<span id="cb10-14"><a href="#cb10-14" tabindex="-1"></a>            shape<span class="op">=</span>canvas.shape[<span class="dv">0</span>:<span class="dv">2</span>],</span>
<span id="cb10-15"><a href="#cb10-15" tabindex="-1"></a>        )</span>
<span id="cb10-16"><a href="#cb10-16" tabindex="-1"></a>        color <span class="op">=</span> (<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">255</span>)</span>
<span id="cb10-17"><a href="#cb10-17" tabindex="-1"></a>    <span class="cf">elif</span> x <span class="op">&lt;</span> <span class="fl">0.66</span>:</span>
<span id="cb10-18"><a href="#cb10-18" tabindex="-1"></a>        <span class="co"># draw a green line at a random location</span></span>
<span id="cb10-19"><a href="#cb10-19" tabindex="-1"></a>        rr, cc <span class="op">=</span> ski.draw.line(</span>
<span id="cb10-20"><a href="#cb10-20" tabindex="-1"></a>            r0<span class="op">=</span>random.randrange(<span class="dv">600</span>),</span>
<span id="cb10-21"><a href="#cb10-21" tabindex="-1"></a>            c0<span class="op">=</span>random.randrange(<span class="dv">800</span>),</span>
<span id="cb10-22"><a href="#cb10-22" tabindex="-1"></a>            r1<span class="op">=</span>random.randrange(<span class="dv">600</span>),</span>
<span id="cb10-23"><a href="#cb10-23" tabindex="-1"></a>            c1<span class="op">=</span>random.randrange(<span class="dv">800</span>),</span>
<span id="cb10-24"><a href="#cb10-24" tabindex="-1"></a>        )</span>
<span id="cb10-25"><a href="#cb10-25" tabindex="-1"></a>        color <span class="op">=</span> (<span class="dv">0</span>, <span class="dv">255</span>, <span class="dv">0</span>)</span>
<span id="cb10-26"><a href="#cb10-26" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb10-27"><a href="#cb10-27" tabindex="-1"></a>        <span class="co"># draw a red rectangle at a random location</span></span>
<span id="cb10-28"><a href="#cb10-28" tabindex="-1"></a>        rr, cc <span class="op">=</span> ski.draw.rectangle(</span>
<span id="cb10-29"><a href="#cb10-29" tabindex="-1"></a>            start<span class="op">=</span>(random.randrange(<span class="dv">600</span>), random.randrange(<span class="dv">800</span>)),</span>
<span id="cb10-30"><a href="#cb10-30" tabindex="-1"></a>            extent<span class="op">=</span>(<span class="dv">50</span>, <span class="dv">50</span>),</span>
<span id="cb10-31"><a href="#cb10-31" tabindex="-1"></a>            shape<span class="op">=</span>canvas.shape[<span class="dv">0</span>:<span class="dv">2</span>],</span>
<span id="cb10-32"><a href="#cb10-32" tabindex="-1"></a>        )</span>
<span id="cb10-33"><a href="#cb10-33" tabindex="-1"></a>        color <span class="op">=</span> (<span class="dv">255</span>, <span class="dv">0</span>, <span class="dv">0</span>)</span>
<span id="cb10-34"><a href="#cb10-34" tabindex="-1"></a></span>
<span id="cb10-35"><a href="#cb10-35" tabindex="-1"></a>    canvas[rr, cc] <span class="op">=</span> color</span>
<span id="cb10-36"><a href="#cb10-36" tabindex="-1"></a></span>
<span id="cb10-37"><a href="#cb10-37" tabindex="-1"></a><span class="co"># display the results</span></span>
<span id="cb10-38"><a href="#cb10-38" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb10-39"><a href="#cb10-39" tabindex="-1"></a>plt.imshow(canvas)</span></code></pre>
</div>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="image-modification">Image modification<a class="anchor" aria-label="anchor" href="#image-modification"></a>
</h2>
<hr class="half-width">
<p>All that remains is the task of modifying the image using our mask in
such a way that the areas with <code>True</code> pixels in the mask are
not shown in the image any more.</p>
<div id="loading-images-with-imageio-read-only-arrays" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="loading-images-with-imageio-read-only-arrays" class="callout-inner">
<h3 class="callout-title">Loading images with imageio: Read-only arrays</h3>
<div class="callout-content">
<p>When loading an image with imageio, in certain situations the image
is stored in a read-only array. If you attempt to manipulate the pixels
in a read-only array, you will receive an error message
<code>ValueError: assignment destination is read-only</code>. In order
to make the image array writeable, we can create a copy with
<code>image = np.array(image)</code> before manipulating the pixel
values.</p>
</div>
</div>
</div>
<div id="how-does-a-mask-work-optional-not-included-in-timing" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="how-does-a-mask-work-optional-not-included-in-timing" class="callout-inner">
<h3 class="callout-title">How does a mask work? (optional, not included in timing)</h3>
<div class="callout-content">
<p>Now, consider the mask image we created above. The values of the mask
that corresponds to the portion of the image we are interested in are
all <code>False</code>, while the values of the mask that corresponds to
the portion of the image we want to remove are all
<code>True</code>.</p>
<p>How do we change the original image using the mask?</p>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" data-bs-parent="#accordionSolution2" aria-labelledby="headingSolution2">
<div class="accordion-body">
<p>When indexing the image using the mask, we access only those pixels
at positions where the mask is <code>True</code>. So, when indexing with
the mask, one can set those values to 0, and effectively remove them
from the image.</p>
</div>
</div>
</div>
</div>
<p>Now we can write a Python program to use a mask to retain only the
leftmost cell of the HeLa cells image. We load the original image and
create the mask in the same way as before:</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="co"># Load the original image</span></span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a>cells <span class="op">=</span> iio.imread(uri<span class="op">=</span><span class="st">"data/hela-cells-8bit.tif"</span>)</span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a><span class="co"># Create the basic mask</span></span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a>mask <span class="op">=</span> np.ones(shape<span class="op">=</span>cells.shape[<span class="dv">0</span>:<span class="dv">2</span>], dtype<span class="op">=</span><span class="st">"bool"</span>)</span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a><span class="co"># Draw a filled rectangle on the mask image</span></span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a>rr, cc <span class="op">=</span> ski.draw.rectangle(start<span class="op">=</span>(<span class="dv">70</span>,<span class="dv">20</span>), end<span class="op">=</span>(<span class="dv">391</span>,<span class="dv">211</span>))</span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a>mask[rr, cc] <span class="op">=</span> <span class="va">False</span></span></code></pre>
</div>
<p>Then, we use NumPy indexing to remove the portions of the image,
where the mask is <code>True</code>:</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="co"># Apply the mask</span></span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a>cells[mask] <span class="op">=</span> <span class="dv">0</span></span></code></pre>
</div>
<p>Then, we display the masked image.</p>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a>plt.imshow(cells)</span></code></pre>
</div>
<p>The resulting masked image should look like this:</p>
<p><img src="../fig/cells-masked-rectangle.jpg" alt="Applied mask" class="figure">s</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul>
<li>We can use the NumPy <code>zeros()</code> function to create a
blank, black image.</li>
<li>We can draw on scikit-image images with functions such as
<code>ski.draw.rectangle()</code>, <code>ski.draw.disk()</code>,
<code>ski.draw.line()</code>, and more.</li>
<li>The drawing functions return indices to pixels that can be set
directly.</li>
</ul>
</div>
</div>
</div>
</section></section><section id="aio-05-creating-histograms"><p>Content from <a href="05-creating-histograms.html">Creating Histograms</a></p>
<hr>
<p>Last updated on 2024-03-26 |

        <a href="https://github.com/govekk/image-processing/edit/main/episodes/05-creating-histograms.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 80 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How can we create grayscale and colour histograms to understand the
distribution of colour values in an image?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Explain what a histogram is.</li>
<li>Load an image in grayscale format.</li>
<li>Create and display grayscale and colour histograms for entire
images.</li>
<li>Create and display grayscale and colour histograms for certain areas
of images, via masks.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p>In this episode, we will learn how to use scikit-image functions to
create and display histograms for images.</p>
<section><h2 class="section-heading" id="first-import-the-packages-needed-for-this-episode">First, import the packages needed for this episode<a class="anchor" aria-label="anchor" href="#first-import-the-packages-needed-for-this-episode"></a>
</h2>
<hr class="half-width">
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">import</span> imageio.v3 <span class="im">as</span> iio</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">import</span> ipympl</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="im">import</span> skimage <span class="im">as</span> ski</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="op">%</span>matplotlib widget</span></code></pre>
</div>
</section><section><h2 class="section-heading" id="introduction-to-histograms">Introduction to Histograms<a class="anchor" aria-label="anchor" href="#introduction-to-histograms"></a>
</h2>
<hr class="half-width">
<p>As it pertains to images, a <em>histogram</em> is a graphical
representation showing how frequently various colour values occur in the
image. We saw in <a href="02-image-basics.html">the <em>Image
Basics</em> episode</a> that we could use a histogram to visualise the
differences in uncompressed and compressed image formats. If your
project involves detecting colour changes between images, histograms
will prove to be very useful, and histograms are also quite handy as a
preparatory step before performing <a href="07-thresholding.html">thresholding</a>.</p>
</section><section><h2 class="section-heading" id="grayscale-histograms">Grayscale Histograms<a class="anchor" aria-label="anchor" href="#grayscale-histograms"></a>
</h2>
<hr class="half-width">
<p>We will start with grayscale images, and then move on to colour
images. We will use this hematoxylin and DAB stained
immunohistochemistry image as an example: <img src="../data/immunohistochemistry.jpg" alt="HED IHC scikit example image" class="figure"></p>
<p>Here we load the image in grayscale instead of full colour, and
display it:</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="co"># read the immunohistochemistry image as grayscale from the outset</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>hed_image <span class="op">=</span> iio.imread(uri<span class="op">=</span><span class="st">"data/immunohistochemistry.tif"</span>)</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>hed_image <span class="op">=</span> ski.color.rgb2gray(hed_image)</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a><span class="co"># convert the image to float dtype with a value range from 0 to 1</span></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a>hed_image <span class="op">=</span> ski.util.img_as_float(hed_image)</span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a><span class="co"># display the image</span></span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a>plt.imshow(hed_image, cmap<span class="op">=</span><span class="st">"gray"</span>)</span></code></pre>
</div>
<figure><img src="../fig/ihc-grayscale.jpg" alt="grayscale verson of IHC image" class="figure mx-auto d-block"></figure><p>Again, we use the <code>iio.imread()</code> function to load our
image. Then, we convert the grayscale image of integer dtype, with 0-255
range, into a floating-point one with 0-1 range, by calling the function
<code>ski.util.img_as_float</code>. We can also calculate histograms for
8 bit images as we will see in the subsequent exercises.</p>
<p>We now use the function <code>np.histogram</code> to compute the
histogram of our image which, after all, is a NumPy array:</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="co"># create the histogram</span></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>histogram, bin_edges <span class="op">=</span> np.histogram(hed_image, bins<span class="op">=</span><span class="dv">256</span>, <span class="bu">range</span><span class="op">=</span>(<span class="dv">0</span>, <span class="dv">1</span>))</span></code></pre>
</div>
<p>The parameter <code>bins</code> determines the number of “bins” to
use for the histogram. We pass in <code>256</code> because we want to
see the pixel count for each of the 256 possible values in the grayscale
image.</p>
<p>The parameter <code>range</code> is the range of values each of the
pixels in the image can have. Here, we pass 0 and 1, which is the value
range of our input image after conversion to floating-point.</p>
<p>The first output of the <code>np.histogram</code> function is a
one-dimensional NumPy array, with 256 rows and one column, representing
the number of pixels with the intensity value corresponding to the
index. I.e., the first number in the array is the number of pixels found
with intensity value 0, and the final number in the array is the number
of pixels found with intensity value 255. The second output of
<code>np.histogram</code> is an array with the bin edges and one column
and 257 rows (one more than the histogram itself). There are no gaps
between the bins, which means that the end of the first bin, is the
start of the second and so on. For the last bin, the array also has to
contain the stop, so it has one more element, than the histogram.</p>
<p>Next, we turn our attention to displaying the histogram, by taking
advantage of the plotting facilities of the Matplotlib library.</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="co"># configure and draw the histogram figure</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>plt.figure()</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>plt.title(<span class="st">"Grayscale Histogram"</span>)</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>plt.xlabel(<span class="st">"grayscale value"</span>)</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a>plt.ylabel(<span class="st">"pixel count"</span>)</span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a>plt.xlim([<span class="fl">0.0</span>, <span class="fl">1.0</span>])  <span class="co"># &lt;- named arguments do not work here</span></span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a>plt.plot(bin_edges[<span class="dv">0</span>:<span class="op">-</span><span class="dv">1</span>], histogram)  <span class="co"># &lt;- or here</span></span></code></pre>
</div>
<p>We create the plot with <code>plt.figure()</code>, then label the
figure and the coordinate axes with <code>plt.title()</code>,
<code>plt.xlabel()</code>, and <code>plt.ylabel()</code> functions. The
last step in the preparation of the figure is to set the limits on the
values on the x-axis with the <code>plt.xlim([0.0, 1.0])</code> function
call.</p>
<div id="variable-length-argument-lists" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="variable-length-argument-lists" class="callout-inner">
<h3 class="callout-title">Variable-length argument lists</h3>
<div class="callout-content">
<p>Note that we cannot used named parameters for the
<code>plt.xlim()</code> or <code>plt.plot()</code> functions. This is
because these functions are defined to take an arbitrary number of
<em>unnamed</em> arguments. The designers wrote the functions this way
because they are very versatile, and creating named parameters for all
of the possible ways to use them would be complicated.</p>
</div>
</div>
</div>
<p>Finally, we create the histogram plot itself with
<code>plt.plot(bin_edges[0:-1], histogram)</code>. We use the
<strong>left</strong> bin edges as x-positions for the histogram values
by indexing the <code>bin_edges</code> array to ignore the last value
(the <strong>right</strong> edge of the last bin). When we run the
program on the immunohistochemistry image, it produces this
histogram:</p>
<figure><img src="../fig/ihc-grayscale-histogram.png" alt="Grayscale immunohistochemistry histogram" class="figure mx-auto d-block"></figure><div id="histograms-in-matplotlib" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="histograms-in-matplotlib" class="callout-inner">
<h3 class="callout-title">Histograms in Matplotlib</h3>
<div class="callout-content">
<p>Matplotlib provides a dedicated function to compute and display
histograms: <code>plt.hist()</code>. We will not use it in this lesson
in order to understand how to calculate histograms in more detail. In
practice, it is a good idea to use this function, because it visualises
histograms more appropriately than <code>plt.plot()</code>. Here, you
could use it by calling
<code>plt.hist(image.flatten(), bins=256, range=(0, 1))</code> instead
of <code>np.histogram()</code> and <code>plt.plot()</code>
(<code>*.flatten()</code> is a NumPy function that converts our
two-dimensional image into a one-dimensional array).</p>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="colour-histograms">Colour Histograms<a class="anchor" aria-label="anchor" href="#colour-histograms"></a>
</h2>
<hr class="half-width">
<p>We can also create histograms for full colour images, in addition to
grayscale histograms. A program to create colour histograms starts in a
familiar way:</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="co"># read original image, in full color</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>cells <span class="op">=</span> iio.imread(uri<span class="op">=</span><span class="st">"data/hela-cells-8bit.tif"</span>)</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a><span class="co"># display the image</span></span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>plt.imshow(cells)</span></code></pre>
</div>
<p>We read the original image, now in full colour, and display it.</p>
<p>Next, we create the histogram, by calling the
<code>np.histogram</code> function three times, once for each of the
channels. We obtain the individual channels, by slicing the image along
the last axis. For example, we can obtain the red colour channel by
calling <code>r_chan = image[:, :, 0]</code>.</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="co"># tuple to select colors of each channel line</span></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>colors <span class="op">=</span> (<span class="st">"red"</span>, <span class="st">"green"</span>, <span class="st">"blue"</span>)</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a><span class="co"># create the histogram plot, with three lines, one for</span></span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a><span class="co"># each color</span></span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a>plt.figure()</span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a>plt.xlim([<span class="dv">0</span>, <span class="dv">256</span>])</span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a><span class="cf">for</span> channel_id, color <span class="kw">in</span> <span class="bu">enumerate</span>(colors):</span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a>    histogram, bin_edges <span class="op">=</span> np.histogram(</span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a>        cells[:, :, channel_id], bins<span class="op">=</span><span class="dv">256</span>, <span class="bu">range</span><span class="op">=</span>(<span class="dv">0</span>, <span class="dv">256</span>)</span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a>    )</span>
<span id="cb6-12"><a href="#cb6-12" tabindex="-1"></a>    plt.plot(bin_edges[<span class="dv">0</span>:<span class="op">-</span><span class="dv">1</span>], histogram, color<span class="op">=</span>color)</span>
<span id="cb6-13"><a href="#cb6-13" tabindex="-1"></a></span>
<span id="cb6-14"><a href="#cb6-14" tabindex="-1"></a>plt.title(<span class="st">"Color Histogram"</span>)</span>
<span id="cb6-15"><a href="#cb6-15" tabindex="-1"></a>plt.xlabel(<span class="st">"Color value"</span>)</span>
<span id="cb6-16"><a href="#cb6-16" tabindex="-1"></a>plt.ylabel(<span class="st">"Pixel count"</span>)</span></code></pre>
</div>
<p>We will draw the histogram line for each channel in a different
colour, and so we create a tuple of the colours to use for the three
lines with the</p>
<p><code>colors = ("red", "green", "blue")</code></p>
<p>line of code. Then, we limit the range of the x-axis with the
<code>plt.xlim()</code> function call.</p>
<p>Next, we use the <code>for</code> control structure to iterate
through the three channels, plotting an appropriately-coloured histogram
line for each. This may be new Python syntax for you, so we will take a
moment to discuss what is happening in the <code>for</code>
statement.</p>
<p>The Python built-in <code>enumerate()</code> function takes a list
and returns an <em>iterator</em> of <em>tuples</em>, where the first
element of the tuple is the index and the second element is the element
of the list.</p>
<div id="iterators-tuples-and-enumerate" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="iterators-tuples-and-enumerate" class="callout-inner">
<h3 class="callout-title">Iterators, tuples, and
<code>enumerate()</code>
</h3>
<div class="callout-content">
<p>In Python, an <em>iterator</em>, or an <em>iterable object</em>, is
something that can be iterated over with the <code>for</code> control
structure. A <em>tuple</em> is a sequence of objects, just like a list.
However, a tuple cannot be changed, and a tuple is indicated by
parentheses instead of square brackets. The <code>enumerate()</code>
function takes an iterable object, and returns an iterator of tuples
consisting of the 0-based index and the corresponding object.</p>
<p>For example, consider this small Python program:</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="bu">list</span> <span class="op">=</span> (<span class="st">"a"</span>, <span class="st">"b"</span>, <span class="st">"c"</span>, <span class="st">"d"</span>, <span class="st">"e"</span>)</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a><span class="cf">for</span> x <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="bu">list</span>):</span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>    <span class="bu">print</span>(x)</span></code></pre>
</div>
<p>Executing this program would produce the following output:</p>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>(0, 'a')
(1, 'b')
(2, 'c')
(3, 'd')
(4, 'e')</code></pre>
</div>
</div>
</div>
</div>
<p>In our colour histogram program, we are using a tuple,
<code>(channel_id, color)</code>, as the <code>for</code> variable. The
first time through the loop, the <code>channel_id</code> variable takes
the value <code>0</code>, referring to the position of the red colour
channel, and the <code>color</code> variable contains the string
<code>"red"</code>. The second time through the loop the values are the
green channels index <code>1</code> and <code>"green"</code>, and the
third time they are the blue channel index <code>2</code> and
<code>"blue"</code>.</p>
<p>Inside the <code>for</code> loop, our code looks much like it did for
the grayscale example. We calculate the histogram for the current
channel with the</p>
<p><code>histogram, bin_edges = np.histogram(image[:, :, channel_id], bins=256, range=(0, 256))</code></p>
<p>function call, and then add a histogram line of the correct colour to
the plot with the</p>
<p><code>plt.plot(bin_edges[0:-1], histogram, color=color)</code></p>
<p>function call. Note the use of our loop variables,
<code>channel_id</code> and <code>color</code>.</p>
<p>Finally we label our axes and display the histogram, shown here:</p>
<figure><img src="../fig/cells-colour-histogram.png" alt="Colour histogram" class="figure mx-auto d-block"></figure><div id="code-cheatsheet-for-colour-histogram-with-a-mask" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="code-cheatsheet-for-colour-histogram-with-a-mask" class="callout-inner">
<h3 class="callout-title">Code cheatsheet for “Colour histogram with a mask”:</h3>
<div class="callout-content">
<p>Drawing a mask:</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="co"># Create mask where background is zeros</span></span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>mask <span class="op">=</span> np.zeros(shape<span class="op">=</span>image.shape[<span class="dv">0</span>:<span class="dv">2</span>], dtype<span class="op">=</span><span class="st">"bool"</span>)</span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a><span class="co"># Draw a circle with center at (yr, xc) with radius r</span></span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a>circle <span class="op">=</span> ski.draw.disk(center<span class="op">=</span>(yr, xc), radius<span class="op">=</span>r, shape<span class="op">=</span>image.shape[<span class="dv">0</span>:<span class="dv">2</span>])</span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a>mask[circle] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a><span class="co"># Get pixels from image where mask is true (e.g. inside circle)</span></span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a>image[mask]</span></code></pre>
</div>
<p>Histograms:</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="im">import</span> imageio.v3 <span class="im">as</span> iio</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a><span class="im">import</span> ipympl</span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a><span class="im">import</span> skimage <span class="im">as</span> ski</span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a><span class="op">%</span>matplotlib widget</span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a><span class="co"># read original image, in full color, from uri path to image file</span></span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a>image <span class="op">=</span> iio.imread(uri)</span>
<span id="cb10-10"><a href="#cb10-10" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" tabindex="-1"></a><span class="co"># tuple to select colors of each channel line</span></span>
<span id="cb10-12"><a href="#cb10-12" tabindex="-1"></a>colors <span class="op">=</span> (<span class="st">"red"</span>, <span class="st">"green"</span>, <span class="st">"blue"</span>)</span>
<span id="cb10-13"><a href="#cb10-13" tabindex="-1"></a><span class="co"># create the histogram plot, with three lines, one for</span></span>
<span id="cb10-14"><a href="#cb10-14" tabindex="-1"></a><span class="co"># each color</span></span>
<span id="cb10-15"><a href="#cb10-15" tabindex="-1"></a>plt.figure()</span>
<span id="cb10-16"><a href="#cb10-16" tabindex="-1"></a>plt.xlim([<span class="dv">0</span>, <span class="dv">256</span>])</span>
<span id="cb10-17"><a href="#cb10-17" tabindex="-1"></a><span class="cf">for</span> channel_id, color <span class="kw">in</span> <span class="bu">enumerate</span>(colors):</span>
<span id="cb10-18"><a href="#cb10-18" tabindex="-1"></a>    histogram, bin_edges <span class="op">=</span> np.histogram(</span>
<span id="cb10-19"><a href="#cb10-19" tabindex="-1"></a>        image[:, :, channel_id], bins<span class="op">=</span><span class="dv">256</span>, <span class="bu">range</span><span class="op">=</span>(<span class="dv">0</span>, <span class="dv">256</span>)</span>
<span id="cb10-20"><a href="#cb10-20" tabindex="-1"></a>    )</span>
<span id="cb10-21"><a href="#cb10-21" tabindex="-1"></a>    plt.plot(bin_edges[<span class="dv">0</span>:<span class="op">-</span><span class="dv">1</span>], histogram, color<span class="op">=</span>color)</span>
<span id="cb10-22"><a href="#cb10-22" tabindex="-1"></a></span>
<span id="cb10-23"><a href="#cb10-23" tabindex="-1"></a>plt.title(<span class="st">"Color Histogram"</span>)</span>
<span id="cb10-24"><a href="#cb10-24" tabindex="-1"></a>plt.xlabel(<span class="st">"Color value"</span>)</span>
<span id="cb10-25"><a href="#cb10-25" tabindex="-1"></a>plt.ylabel(<span class="st">"Pixel count"</span>)</span></code></pre>
</div>
</div>
</div>
</div>
<div id="colour-histogram-with-a-mask-25-min" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="colour-histogram-with-a-mask-25-min" class="callout-inner">
<h3 class="callout-title">Colour histogram with a mask (25 min)</h3>
<div class="callout-content">
<p>Looking at the histogram above, you will notice that there is a large
number of very dark pixels in each channel. This is not so surprising,
since the image has a mostly black background. What if we want to focus
on a more foreground part of the image, like just one of the cells. This
is where a mask enters the picture!</p>
<p>Hover over the image with your mouse to find the centre of that cell
and the radius (in pixels) of the cell. Then, using techniques from <a href="04-drawing.html">the <em>Drawing and Bitwise Operations</em>
episode</a>, create a circular mask to select only the desired cell.
Then, use that mask to apply the colour histogram operation to that
cell.</p>
<p>Your masked image should look something like this:</p>
<figure><img src="../fig/cells-masked.jpg" alt="Masked cell" class="figure mx-auto d-block"></figure><p>And, the program should produce a colour histogram that looks like
this:</p>
<figure><img src="../fig/cells-masked-histogram.png" alt="Single cell histogram" class="figure mx-auto d-block"></figure>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="co"># create a circular mask to select the lowest cell in the image</span></span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a>mask <span class="op">=</span> np.zeros(shape<span class="op">=</span>cells.shape[<span class="dv">0</span>:<span class="dv">2</span>], dtype<span class="op">=</span><span class="st">"bool"</span>)</span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a>circle <span class="op">=</span> ski.draw.disk(center<span class="op">=</span>(<span class="dv">400</span>, <span class="dv">360</span>), radius<span class="op">=</span><span class="dv">80</span>, shape<span class="op">=</span>cells.shape[<span class="dv">0</span>:<span class="dv">2</span>])</span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a>mask[circle] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a></span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a><span class="co"># just for display:</span></span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a><span class="co"># make a copy of the image, call it masked_image, and</span></span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a><span class="co"># zero values where mask is False</span></span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a>masked_img <span class="op">=</span> np.array(cells)</span>
<span id="cb11-10"><a href="#cb11-10" tabindex="-1"></a>masked_img[<span class="op">~</span>mask] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb11-11"><a href="#cb11-11" tabindex="-1"></a></span>
<span id="cb11-12"><a href="#cb11-12" tabindex="-1"></a><span class="co"># create a new figure and display masked_img, to verify the</span></span>
<span id="cb11-13"><a href="#cb11-13" tabindex="-1"></a><span class="co"># validity of your mask</span></span>
<span id="cb11-14"><a href="#cb11-14" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb11-15"><a href="#cb11-15" tabindex="-1"></a>plt.imshow(masked_img)</span>
<span id="cb11-16"><a href="#cb11-16" tabindex="-1"></a></span>
<span id="cb11-17"><a href="#cb11-17" tabindex="-1"></a><span class="co"># list to select colors of each channel line</span></span>
<span id="cb11-18"><a href="#cb11-18" tabindex="-1"></a>colors <span class="op">=</span> (<span class="st">"red"</span>, <span class="st">"green"</span>, <span class="st">"blue"</span>)</span>
<span id="cb11-19"><a href="#cb11-19" tabindex="-1"></a></span>
<span id="cb11-20"><a href="#cb11-20" tabindex="-1"></a><span class="co"># create the histogram plot, with three lines, one for</span></span>
<span id="cb11-21"><a href="#cb11-21" tabindex="-1"></a><span class="co"># each color</span></span>
<span id="cb11-22"><a href="#cb11-22" tabindex="-1"></a>plt.figure()</span>
<span id="cb11-23"><a href="#cb11-23" tabindex="-1"></a>plt.xlim([<span class="dv">0</span>, <span class="dv">256</span>])</span>
<span id="cb11-24"><a href="#cb11-24" tabindex="-1"></a><span class="cf">for</span> (channel_id, color) <span class="kw">in</span> <span class="bu">enumerate</span>(colors):</span>
<span id="cb11-25"><a href="#cb11-25" tabindex="-1"></a>    <span class="co"># use your circular mask to apply the histogram</span></span>
<span id="cb11-26"><a href="#cb11-26" tabindex="-1"></a>    <span class="co"># operation to the lowest cell of the image</span></span>
<span id="cb11-27"><a href="#cb11-27" tabindex="-1"></a>    histogram, bin_edges <span class="op">=</span> np.histogram(</span>
<span id="cb11-28"><a href="#cb11-28" tabindex="-1"></a>        cells[:, :, channel_id][mask], bins<span class="op">=</span><span class="dv">256</span>, <span class="bu">range</span><span class="op">=</span>(<span class="dv">0</span>, <span class="dv">256</span>)</span>
<span id="cb11-29"><a href="#cb11-29" tabindex="-1"></a>    )</span>
<span id="cb11-30"><a href="#cb11-30" tabindex="-1"></a></span>
<span id="cb11-31"><a href="#cb11-31" tabindex="-1"></a>    plt.plot(histogram, color<span class="op">=</span>color)</span>
<span id="cb11-32"><a href="#cb11-32" tabindex="-1"></a></span>
<span id="cb11-33"><a href="#cb11-33" tabindex="-1"></a>plt.xlabel(<span class="st">"color value"</span>)</span>
<span id="cb11-34"><a href="#cb11-34" tabindex="-1"></a>plt.ylabel(<span class="st">"pixel count"</span>)</span></code></pre>
</div>
</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul>
<li>We can create histograms of images with the
<code>np.histogram</code> function.</li>
<li>We can separate the RGB channels of an image using slicing
operations.</li>
<li>We can display histograms using the <code>matplotlib pyplot</code>
<code>figure()</code>, <code>title()</code>, <code>xlabel()</code>,
<code>ylabel()</code>, <code>xlim()</code>, <code>plot()</code>, and
<code>show()</code> functions.</li>
</ul>
</div>
</div>
</div>
</section></section><section id="aio-06-blurring"><p>Content from <a href="06-blurring.html">Blurring Images</a></p>
<hr>
<p>Last updated on 2024-03-26 |

        <a href="https://github.com/govekk/image-processing/edit/main/episodes/06-blurring.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 60 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How can we apply a low-pass blurring filter to an image?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Explain why applying a low-pass blurring filter to an image is
beneficial.</li>
<li>Apply a Gaussian blur filter to an image using scikit-image.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p>In this episode, we will learn how to use scikit-image functions to
blur images.</p>
<p>When processing an image, we are often interested in identifying
objects represented within it so that we can perform some further
analysis of these objects, e.g., by counting them, measuring their
sizes, etc. An important concept associated with the identification of
objects in an image is that of <em>edges</em>: the lines that represent
a transition from one group of similar pixels in the image to another
different group. One example of an edge is the pixels that represent the
boundaries of an object in an image, where the background of the image
ends and the object begins.</p>
<p>When we blur an image, we make the colour transition from one side of
an edge in the image to another smooth rather than sudden. The effect is
to average out rapid changes in pixel intensity. Blurring is a very
common operation we need to perform before other tasks such as <a href="07-thresholding.html">thresholding</a>. There are several
different blurring functions in the <code>ski.filters</code> module, so
we will focus on just one here, the <em>Gaussian blur</em>.</p>
<div id="filters" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="filters" class="callout-inner">
<h3 class="callout-title">Filters</h3>
<div class="callout-content">
<p>In the day-to-day, macroscopic world, we have physical filters which
separate out objects by size. A filter with small holes allows only
small objects through, leaving larger objects behind. This is a good
analogy for image filters. A high-pass filter will retain the smaller
details in an image, filtering out the larger ones. A low-pass filter
retains the larger features, analogous to what’s left behind by a
physical filter mesh. <em>High-</em> and *low-*pass, here, refer to high
and low <em>spatial frequencies</em> in the image. Details associated
with high spatial frequencies are small, a lot of these features would
fit across an image. Features associated with low spatial frequencies
are large - maybe a couple of big features per image.</p>
</div>
</div>
</div>
<div id="blurring" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="blurring" class="callout-inner">
<h3 class="callout-title">Blurring</h3>
<div class="callout-content">
<p>To blur is to make something less clear or distinct. This could be
interpreted quite broadly in the context of image analysis - anything
that reduces or distorts the detail of an image might apply. Applying a
low-pass filter, which removes detail occurring at high spatial
frequencies, is perceived as a blurring effect. A Gaussian blur is a
filter that makes use of a Gaussian kernel.</p>
</div>
</div>
</div>
<div id="kernels" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="kernels" class="callout-inner">
<h3 class="callout-title">Kernels</h3>
<div class="callout-content">
<p>A kernel can be used to implement a filter on an image. A kernel, in
this context, is a small matrix which is combined with the image using a
mathematical technique: <em>convolution</em>. Different sizes, shapes
and contents of kernel produce different effects. The kernel can be
thought of as a little image in itself, and will favour features of
similar size and shape in the main image. On convolution with an image,
a big, blobby kernel will retain big, blobby, low spatial frequency
features.</p>
</div>
</div>
</div>
<section><h2 class="section-heading" id="gaussian-blur">Gaussian blur<a class="anchor" aria-label="anchor" href="#gaussian-blur"></a>
</h2>
<hr class="half-width">
<p>Consider this image of a cat, in particular the area of the image
outlined by the white square.</p>
<figure><img src="../fig/cat.jpg" alt="Cat image" class="figure mx-auto d-block"></figure><p>Now, zoom in on the area of the cat’s eye, as shown in the left-hand
image below. When we apply a filter, we consider each pixel in the
image, one at a time. In this example, the pixel we are currently
working on is highlighted in red, as shown in the right-hand image.</p>
<figure><img src="../fig/cat-eye-pixels.jpg" alt="Cat eye pixels" class="figure mx-auto d-block"></figure><p>When we apply a filter, we consider rectangular groups of pixels
surrounding each pixel in the image, in turn. The <em>kernel</em> is
another group of pixels (a separate matrix / small image), of the same
dimensions as the rectangular group of pixels in the image, that moves
along with the pixel being worked on by the filter. The width and height
of the kernel must be an odd number, so that the pixel being worked on
is always in its centre. In the example shown above, the kernel is
square, with a dimension of seven pixels.</p>
<p>To apply the kernel to the current pixel, an average of the colour
values of the pixels surrounding it is calculated, weighted by the
values in the kernel. In a Gaussian blur, the pixels nearest the centre
of the kernel are given more weight than those far away from the centre.
The rate at which this weight diminishes is determined by a Gaussian
function, hence the name Gaussian blur.</p>
<p>A Gaussian function maps random variables into a normal distribution
or “Bell Curve”. <img src="../fig/Normal_Distribution_PDF.svg" alt="Gaussian function" class="figure"></p>
<div class="line-block">
<em><a href="https://en.wikipedia.org/wiki/Gaussian_function#/media/File:Normal_Distribution_PDF.svg" class="external-link">https://en.wikipedia.org/wiki/Gaussian_function#/media/File:Normal_Distribution_PDF.svg</a></em>
|</div>
<p>The shape of the function is described by a mean value μ, and a
variance value σ². The mean determines the central point of the bell
curve on the X axis, and the variance describes the spread of the
curve.</p>
<p>In fact, when using Gaussian functions in Gaussian blurring, we use a
2D Gaussian function to account for X and Y dimensions, but the same
rules apply. The mean μ is always 0, and represents the middle of the 2D
kernel. Increasing values of σ² in either dimension increases the amount
of blurring in that dimension.</p>
<figure><img src="../fig/Gaussian_2D.png" alt="2D Gaussian function" class="figure mx-auto d-block"></figure><div class="line-block">
<em><a href="https://commons.wikimedia.org/wiki/File:Gaussian_2D.png" class="external-link">https://commons.wikimedia.org/wiki/File:Gaussian_2D.png</a></em>
|</div>
<p>The averaging is done on a channel-by-channel basis, and the average
channel values become the new value for the pixel in the filtered image.
Larger kernels have more values factored into the average, and this
implies that a larger kernel will blur the image more than a smaller
kernel.</p>
<p>To get an idea of how this works, consider this plot of the
two-dimensional Gaussian function:</p>
<figure><img src="../fig/gaussian-kernel.png" alt="2D Gaussian function" class="figure mx-auto d-block"></figure><p>Imagine that plot laid over the kernel for the Gaussian blur filter.
The height of the plot corresponds to the weight given to the underlying
pixel in the kernel. I.e., the pixels close to the centre become more
important to the filtered pixel colour than the pixels close to the
outer limits of the kernel. The shape of the Gaussian function is
controlled via its standard deviation, or sigma. A large sigma value
results in a flatter shape, while a smaller sigma value results in a
more pronounced peak. The mathematics involved in the Gaussian blur
filter are not quite that simple, but this explanation gives you the
basic idea.</p>
<p>To illustrate the blurring process, consider the blue channel colour
values from the seven-by-seven region of the cat image above:</p>
<figure><img src="../fig/cat-corner-blue.png" alt="Image corner pixels" class="figure mx-auto d-block"></figure><p>The filter is going to determine the new blue channel value for the
centre pixel – the one that currently has the value 86. The filter
calculates a weighted average of all the blue channel values in the
kernel giving higher weight to the pixels near the centre of the
kernel.</p>
<figure><img src="../fig/combination.png" alt="Image multiplication" class="figure mx-auto d-block"></figure><p>This weighted average, the sum of the multiplications, becomes the
new value for the centre pixel (3, 3). The same process would be used to
determine the green and red channel values, and then the kernel would be
moved over to apply the filter to the next pixel in the image.</p>
<div id="accordionInstructor1" class="accordion instructor-note accordion-flush">
<div class="accordion-item">
<button class="accordion-button instructor-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseInstructor1" aria-expanded="false" aria-controls="collapseInstructor1">
  <h3 class="accordion-header" id="headingInstructor1">  <div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="edit-2"></i></div> Terminology about image boundaries </h3>
</button>
<div id="collapseInstructor1" class="accordion-collapse collapse" aria-labelledby="headingInstructor1" data-bs-parent="#accordionInstructor1">
<div class="accordion-body">
<p>Take care to avoid mixing up the term “edge” to describe the edges of
objects <em>within</em> an image and the outer boundaries of the images
themselves. Lack of a clear distinction here may be confusing for
learners.</p>
</div>
</div>
</div>
</div>
<div id="image-edges" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="image-edges" class="callout-inner">
<h3 class="callout-title">Image edges</h3>
<div class="callout-content">
<p>Something different needs to happen for pixels near the outer limits
of the image, since the kernel for the filter may be partially off the
image. For example, what happens when the filter is applied to the
upper-left pixel of the image? Here are the blue channel pixel values
for the upper-left pixel of the cat image, again assuming a
seven-by-seven kernel:</p>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>  x   x   x   x   x   x   x
  x   x   x   x   x   x   x
  x   x   x   x   x   x   x
  x   x   x   4   5   9   2
  x   x   x   5   3   6   7
  x   x   x   6   5   7   8
  x   x   x   5   4   5   3</code></pre>
</div>
<p>The upper-left pixel is the one with value 4. Since the pixel is at
the upper-left corner, there are no pixels underneath much of the
kernel; here, this is represented by x’s. So, what does the filter do in
that situation?</p>
<p>The default mode is to fill in the <em>nearest</em> pixel value from
the image. For each of the missing x’s the image value closest to the x
is used. If we fill in a few of the missing pixels, you will see how
this works:</p>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>  x   x   x   4   x   x   x
  x   x   x   4   x   x   x
  x   x   x   4   x   x   x
  4   4   4   4   5   9   2
  x   x   x   5   3   6   7
  x   x   x   6   5   7   8
  x   x   x   5   4   5   3</code></pre>
</div>
<p>Another strategy to fill those missing values is to <em>reflect</em>
the pixels that are in the image to fill in for the pixels that are
missing from the kernel.</p>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>  x   x   x   5   x   x   x
  x   x   x   6   x   x   x
  x   x   x   5   x   x   x
  2   9   5   4   5   9   2
  x   x   x   5   3   6   7
  x   x   x   6   5   7   8
  x   x   x   5   4   5   3</code></pre>
</div>
<p>A similar process would be used to fill in all of the other missing
pixels from the kernel. Other <em>border modes</em> are available; you
can learn more about them in <a href="https://scikit-image.org/docs/dev/user_guide" class="external-link">the scikit-image
documentation</a>.</p>
</div>
</div>
</div>
<p>This animation shows how the blur kernel moves along in the original
image in order to calculate the colour channel values for the blurred
image.</p>
<figure><img src="../fig/blur-demo.gif" alt="Blur demo animation" class="figure mx-auto d-block"></figure><p>scikit-image has built-in functions to perform blurring for us, so we
do not have to perform all of these mathematical operations ourselves.
Let’s work through an example of blurring an image with the scikit-image
Gaussian blur function.</p>
<p>First, import the packages needed for this episode:</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="im">import</span> imageio.v3 <span class="im">as</span> iio</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="im">import</span> ipympl</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a><span class="im">import</span> skimage <span class="im">as</span> ski</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a><span class="op">%</span>matplotlib widget</span></code></pre>
</div>
<p>Then, we load the image, and display it:</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>image <span class="op">=</span> iio.imread(uri<span class="op">=</span><span class="st">"data/gaussian-original.png"</span>)</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a><span class="co"># display the image</span></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>plt.imshow(image)</span></code></pre>
</div>
<figure><img src="../data/gaussian-original.png" alt="Original image" class="figure mx-auto d-block"></figure><p>Next, we apply the gaussian blur:</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>sigma <span class="op">=</span> <span class="fl">3.0</span></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a><span class="co"># apply Gaussian blur, creating a new image</span></span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a>blurred <span class="op">=</span> ski.filters.gaussian(</span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a>    image, sigma<span class="op">=</span>(sigma, sigma), truncate<span class="op">=</span><span class="fl">3.5</span>, channel_axis<span class="op">=-</span><span class="dv">1</span>)</span></code></pre>
</div>
<p>Full information on the parameters of this function are available in
<a href="https://scikit-image.org/docs/stable/api/skimage.filters.html#skimage.filters.gaussian" class="external-link">the
scikit-image documentation on filters</a>.</p>
<p>The first two arguments to <code>ski.filters.gaussian()</code> are
the image to blur, <code>image</code>, and a tuple defining the sigma to
use in ry- and cx-direction, <code>(sigma, sigma)</code>. The third
parameter <code>truncate</code> is meant to pass the radius of the
kernel in number of sigmas. A Gaussian function is defined from
-infinity to +infinity, but our kernel (which must have a finite,
smaller size) can only approximate the real function. Therefore, we must
choose a certain distance from the centre of the function where we stop
this approximation, and set the final size of our kernel. In the above
example, we set <code>truncate</code> to 3.5, which means the kernel
size will be 2 * sigma * 3.5. For example, for a <code>sigma</code> of
1.0 the resulting kernel size would be 7, while for a <code>sigma</code>
of 2.0 the kernel size would be 14. The default value for
<code>truncate</code> in scikit-image is 4.0.</p>
<p>The last argument we passed to <code>ski.filters.gaussian()</code> is
used to specify the dimension which contains the (colour) channels.
Here, it is the last dimension; recall that, in Python, the
<code>-1</code> index refers to the last position. In this case, the
last dimension is the third dimension (index <code>2</code>), since our
image has three dimensions:</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="bu">print</span>(image.ndim)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code><span><span class="fl">3</span></span></code></pre>
</div>
<p>Finally, we display the blurred image:</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="co"># display blurred image</span></span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a>plt.imshow(blurred)</span></code></pre>
</div>
<figure><img src="../fig/gaussian-blurred.png" alt="Blurred image" class="figure mx-auto d-block"></figure></section><section><h2 class="section-heading" id="visualising-blurring">Visualising Blurring<a class="anchor" aria-label="anchor" href="#visualising-blurring"></a>
</h2>
<hr class="half-width">
<p>Somebody said once “an image is worth a thousand words”. What is
actually happening to the image pixels when we apply blurring may be
difficult to grasp. Let’s now visualise the effects of blurring from a
different perspective.</p>
<p>Let’s use the petri-dish image from previous episodes:</p>
<figure><img src="../fig/petri-dish.png" alt="Bacteria colony" class="figure mx-auto d-block"><div class="figcaption">Graysacle version of the Petri dish image</div>
</figure><p>What we want to see here is the pixel intensities from a lateral
perspective: we want to see the profile of intensities. For instance,
let’s look for the intensities of the pixels along the horizontal line
at <code>Y=150</code>:</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="co"># read colonies color image and convert to grayscale</span></span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>image <span class="op">=</span> iio.imread(<span class="st">'data/colonies-01.tif'</span>)</span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a>image_gray <span class="op">=</span> ski.color.rgb2gray(image)</span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a><span class="co"># define the pixels for which we want to view the intensity (profile)</span></span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a>xmin, xmax <span class="op">=</span> (<span class="dv">0</span>, image_gray.shape[<span class="dv">1</span>])</span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a>Y <span class="op">=</span> ymin <span class="op">=</span> ymax <span class="op">=</span> <span class="dv">150</span></span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a></span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a><span class="co"># view the image indicating the profile pixels position</span></span>
<span id="cb10-10"><a href="#cb10-10" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb10-11"><a href="#cb10-11" tabindex="-1"></a>ax.imshow(image_gray, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb10-12"><a href="#cb10-12" tabindex="-1"></a>ax.plot([xmin, xmax], [ymin, ymax], color<span class="op">=</span><span class="st">'red'</span>)</span></code></pre>
</div>
<figure><img src="../fig/petri-selected-pixels-marker.png" alt="Bacteria colony image with selected pixels marker" class="figure mx-auto d-block"><div class="figcaption">Grayscale Petri dish image marking selected
pixels for profiling</div>
</figure><p>The intensity of those pixels we can see with a simple line plot:</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="co"># select the vector of pixels along "Y"</span></span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a>image_gray_pixels_slice <span class="op">=</span> image_gray[Y, :]</span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a><span class="co"># guarantee the intensity values are in the [0:255] range (unsigned integers)</span></span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a>image_gray_pixels_slice <span class="op">=</span> ski.img_as_ubyte(image_gray_pixels_slice)</span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a>fig <span class="op">=</span> plt.figure()</span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a>ax <span class="op">=</span> fig.add_subplot()</span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a></span>
<span id="cb11-10"><a href="#cb11-10" tabindex="-1"></a>ax.plot(image_gray_pixels_slice, color<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb11-11"><a href="#cb11-11" tabindex="-1"></a>ax.set_ylim(<span class="dv">255</span>, <span class="dv">0</span>)</span>
<span id="cb11-12"><a href="#cb11-12" tabindex="-1"></a>ax.set_ylabel(<span class="st">'L'</span>)</span>
<span id="cb11-13"><a href="#cb11-13" tabindex="-1"></a>ax.set_xlabel(<span class="st">'X'</span>)</span></code></pre>
</div>
<figure><img src="../fig/petri-original-intensities-plot.png" alt="Pixel intensities profile in original image" class="figure mx-auto d-block"><div class="figcaption">Intensities profile line plot of pixels along
Y=150 in original image</div>
</figure><p>And now, how does the same set of pixels look in the corresponding
<em>blurred</em> image:</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="co"># first, create a blurred version of (grayscale) image</span></span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a>image_blur <span class="op">=</span> ski.filters.gaussian(image_gray, sigma<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a><span class="co"># visualize which pixels we are selecting</span></span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a>ax.imshow(image_gray, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb12-7"><a href="#cb12-7" tabindex="-1"></a>ax.plot([xmin, xmax], [ymin, ymax], color<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb12-8"><a href="#cb12-8" tabindex="-1"></a></span>
<span id="cb12-9"><a href="#cb12-9" tabindex="-1"></a><span class="co"># like before, plot the pixels profile along "Y"</span></span>
<span id="cb12-10"><a href="#cb12-10" tabindex="-1"></a>image_blur_pixels_slice <span class="op">=</span> image_blur[Y, :]</span>
<span id="cb12-11"><a href="#cb12-11" tabindex="-1"></a>image_blur_pixels_slice <span class="op">=</span> ski.img_as_ubyte(image_blur_pixels_slice)</span>
<span id="cb12-12"><a href="#cb12-12" tabindex="-1"></a></span>
<span id="cb12-13"><a href="#cb12-13" tabindex="-1"></a>fig <span class="op">=</span> plt.figure()</span>
<span id="cb12-14"><a href="#cb12-14" tabindex="-1"></a>ax <span class="op">=</span> fig.add_subplot()</span>
<span id="cb12-15"><a href="#cb12-15" tabindex="-1"></a></span>
<span id="cb12-16"><a href="#cb12-16" tabindex="-1"></a>ax.plot(image_blur_pixels_slice, <span class="st">'red'</span>)</span>
<span id="cb12-17"><a href="#cb12-17" tabindex="-1"></a>ax.set_ylim(<span class="dv">255</span>, <span class="dv">0</span>)</span>
<span id="cb12-18"><a href="#cb12-18" tabindex="-1"></a>ax.set_ylabel(<span class="st">'L'</span>)</span>
<span id="cb12-19"><a href="#cb12-19" tabindex="-1"></a>ax.set_xlabel(<span class="st">'X'</span>)</span></code></pre>
</div>
<figure><img src="../fig/petri-blurred-selected-pixels-marker.png" alt="Blurred bacteria colony image with selected pixels marker" class="figure mx-auto d-block"><div class="figcaption">Grayscale Petri dish image marking selected
pixels for profiling</div>
</figure><figure><img src="../fig/petri-blurred-intensities-plot.png" alt="Pixel intensities profile in blurred image" class="figure mx-auto d-block"><div class="figcaption">Intensities profile of pixels along Y=150 in
<em>blurred</em> image</div>
</figure><p>And that is why <em>blurring</em> is also called <em>smoothing</em>.
This is how low-pass filters affect neighbouring pixels.</p>
<p>Now that we have seen the effects of blurring an image from two
different perspectives, front and lateral, let’s take yet another look
using a 3D visualisation.</p>
<div id="d-plots-with-matplotlib" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="d-plots-with-matplotlib" class="callout-inner">
<h3 class="callout-title">3D Plots with matplotlib</h3>
<div class="callout-content">
<p>The code to generate these 3D plots is outside the scope of this
lesson but can be viewed by following the links in the captions.</p>
</div>
</div>
</div>
<figure><img src="../fig/3D_petri_before_blurring.png" alt="3D surface plot showing pixel intensities across the whole example Petri dish image before blurring" class="figure mx-auto d-block"><div class="figcaption">A 3D plot of pixel intensities across the whole
Petri dish image before blurring. <a href="https://gist.github.com/chbrandt/63ba38142630a0586ba2a13eabedf94b" class="external-link">Explore
how this plot was created with matplotlib</a>. Image credit: <a href="https://github.com/chbrandt/" class="external-link">Carlos H Brandt</a>.</div>
</figure><figure><img src="../fig/3D_petri_after_blurring.png" alt="3D surface plot illustrating the smoothing effect on pixel intensities across the whole example Petri dish image after blurring" class="figure mx-auto d-block"><div class="figcaption">A 3D plot of pixel intensities after Gaussian
blurring of the Petri dish image. Note the ‘smoothing’ effect on the
pixel intensities of the colonies in the image, and the ‘flattening’ of
the background noise at relatively low pixel intensities throughout the
image. <a href="https://gist.github.com/chbrandt/63ba38142630a0586ba2a13eabedf94b" class="external-link">Explore
how this plot was created with matplotlib</a>. Image credit: <a href="https://github.com/chbrandt/" class="external-link">Carlos H Brandt</a>.</div>
</figure><div id="code-cheatsheet-for-experimenting-with-sigma-values" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="code-cheatsheet-for-experimenting-with-sigma-values" class="callout-inner">
<h3 class="callout-title">Code cheatsheet for “Experimenting with sigma values”:</h3>
<div class="callout-content">
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="im">import</span> imageio.v3 <span class="im">as</span> iio</span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a><span class="im">import</span> ipympl</span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a><span class="im">import</span> skimage <span class="im">as</span> ski</span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a><span class="op">%</span>matplotlib widget</span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a></span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a><span class="co"># Read image</span></span>
<span id="cb13-9"><a href="#cb13-9" tabindex="-1"></a>image <span class="op">=</span> iio.imread(uri<span class="op">=</span><span class="st">"data/gaussian-original.png"</span>)</span>
<span id="cb13-10"><a href="#cb13-10" tabindex="-1"></a></span>
<span id="cb13-11"><a href="#cb13-11" tabindex="-1"></a><span class="co"># display the image</span></span>
<span id="cb13-12"><a href="#cb13-12" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb13-13"><a href="#cb13-13" tabindex="-1"></a>plt.imshow(image)</span>
<span id="cb13-14"><a href="#cb13-14" tabindex="-1"></a></span>
<span id="cb13-15"><a href="#cb13-15" tabindex="-1"></a><span class="co"># apply Gaussian blur, creating a new image, with given sigma value</span></span>
<span id="cb13-16"><a href="#cb13-16" tabindex="-1"></a>blurred <span class="op">=</span> ski.filters.gaussian(image, sigma<span class="op">=</span>sigma, channel_axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb13-17"><a href="#cb13-17" tabindex="-1"></a></span>
<span id="cb13-18"><a href="#cb13-18" tabindex="-1"></a><span class="co"># display blurred image</span></span>
<span id="cb13-19"><a href="#cb13-19" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb13-20"><a href="#cb13-20" tabindex="-1"></a>plt.imshow(blurred)</span></code></pre>
</div>
</div>
</div>
</div>
<div id="experimenting-with-sigma-values-10-min" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="experimenting-with-sigma-values-10-min" class="callout-inner">
<h3 class="callout-title">Experimenting with sigma values (10 min)</h3>
<div class="callout-content">
<p>The size and shape of the kernel used to blur an image can have a
significant effect on the result of the blurring and any downstream
analysis carried out on the blurred image. The next two exercises ask
you to experiment with the sigma values of the kernel, which is a good
way to develop your understanding of how the choice of kernel can
influence the result of blurring.</p>
<p>First, try running the code above with a range of smaller and larger
sigma values. Generally speaking, what effect does the sigma value have
on the blurred image?</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<p>Generally speaking, the larger the sigma value, the more blurry the
result. A larger sigma will tend to get rid of more noise in the image,
which will help for other operations we will cover soon, such as
thresholding. However, a larger sigma also tends to eliminate some of
the detail from the image. So, we must strike a balance with the sigma
value used for blur filters.</p>
</div>
</div>
</div>
</div>
<div id="experimenting-with-kernel-shape-10-min---optional-not-included-in-timing" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="experimenting-with-kernel-shape-10-min---optional-not-included-in-timing" class="callout-inner">
<h3 class="callout-title">Experimenting with kernel shape (10 min - optional, not included in timing)</h3>
<div class="callout-content">
<p>Now, what is the effect of applying an asymmetric kernel to blurring
an image? Try running the code above with different sigmas in the ry and
cx direction. For example, a sigma of 1.0 in the ry direction, and 6.0
in the cx direction.</p>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" aria-labelledby="headingSolution2" data-bs-parent="#accordionSolution2">
<div class="accordion-body">
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="co"># apply Gaussian blur, with a sigma of 1.0 in the ry direction, and 6.0 in the cx direction</span></span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a>blurred <span class="op">=</span> ski.filters.gaussian(</span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a>    image, sigma<span class="op">=</span>(<span class="fl">1.0</span>, <span class="fl">6.0</span>), truncate<span class="op">=</span><span class="fl">3.5</span>, channel_axis<span class="op">=-</span><span class="dv">1</span></span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a>)</span>
<span id="cb14-5"><a href="#cb14-5" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" tabindex="-1"></a><span class="co"># display blurred image</span></span>
<span id="cb14-7"><a href="#cb14-7" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb14-8"><a href="#cb14-8" tabindex="-1"></a>plt.imshow(blurred)</span></code></pre>
</div>
<figure><img src="../fig/rectangle-gaussian-blurred.png" alt="Rectangular kernel blurred image" class="figure mx-auto d-block"></figure><p>These unequal sigma values produce a kernel that is rectangular
instead of square. The result is an image that is much more blurred in
the X direction than in the Y direction. For most use cases, a uniform
blurring effect is desirable and this kind of asymmetric blurring should
be avoided. However, it can be helpful in specific circumstances, e.g.,
when noise is present in your image in a particular pattern or
orientation, such as vertical lines, or when you want to <a href="https://www.researchgate.net/publication/228567435_An_edge_detection_algorithm_based_on_rectangular_Gaussian_kernels_for_machine_vision_applications" class="external-link">remove
uniform noise without blurring edges present in the image in a
particular orientation</a>.</p>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="other-methods-of-blurring">Other methods of blurring<a class="anchor" aria-label="anchor" href="#other-methods-of-blurring"></a>
</h2>
<hr class="half-width">
<p>The Gaussian blur is a way to apply a low-pass filter in
scikit-image. It is often used to remove Gaussian (i.e., random) noise
in an image. For other kinds of noise, e.g., “salt and pepper”, a median
filter is typically used. See <a href="https://scikit-image.org/docs/dev/api/skimage.filters.html#module-skimage.filters" class="external-link">the
<code>skimage.filters</code> documentation</a> for a list of available
filters.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul>
<li>Applying a low-pass blurring filter smooths edges and removes noise
from an image.</li>
<li>Blurring is often used as a first step before we perform
thresholding or edge detection.</li>
<li>The Gaussian blur can be applied to an image with the
<code>ski.filters.gaussian()</code> function.</li>
<li>Larger sigma values may remove more noise, but they will also remove
detail from an image.</li>
</ul>
</div>
</div>
</div>
</section></section><section id="aio-07-thresholding"><p>Content from <a href="07-thresholding.html">Thresholding</a></p>
<hr>
<p>Last updated on 2024-03-26 |

        <a href="https://github.com/govekk/image-processing/edit/main/episodes/07-thresholding.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 110 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How can we use thresholding to produce a binary image?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Explain what thresholding is and how it can be used.</li>
<li>Use histograms to determine appropriate threshold values to use for
the thresholding process.</li>
<li>Apply simple, fixed-level binary thresholding to an image.</li>
<li>Explain the difference between using the operator <code>&gt;</code>
or the operator <code>&lt;</code> to threshold an image represented by a
NumPy array.</li>
<li>Describe the shape of a binary image produced by thresholding via
<code>&gt;</code> or <code>&lt;</code>.</li>
<li>Explain when Otsu’s method for automatic thresholding is
appropriate.</li>
<li>Apply automatic thresholding to an image using Otsu’s method.</li>
<li>Use the <code>np.count_nonzero()</code> function to count the number
of non-zero pixels in an image.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p>In this episode, we will learn how to use scikit-image functions to
apply thresholding to an image. Thresholding is a type of <em>image
segmentation</em>, where we change the pixels of an image to make the
image easier to analyze. In thresholding, we convert an image from
colour or grayscale into a <em>binary image</em>, i.e., one that is
simply black and white. Most frequently, we use thresholding as a way to
select areas of interest of an image, while ignoring the parts we are
not concerned with. In this episode, we will learn how to use
scikit-image functions to perform thresholding. Then, we will use the
masks returned by these functions to select the parts of an image we are
interested in.</p>
<section><h2 class="section-heading" id="first-import-the-packages-needed-for-this-episode">First, import the packages needed for this episode<a class="anchor" aria-label="anchor" href="#first-import-the-packages-needed-for-this-episode"></a>
</h2>
<hr class="half-width">
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">import</span> glob</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">import</span> imageio.v3 <span class="im">as</span> iio</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">import</span> ipympl</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="im">import</span> skimage <span class="im">as</span> ski</span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a><span class="op">%</span>matplotlib widget</span></code></pre>
</div>
</section><section><h2 class="section-heading" id="simple-thresholding">Simple thresholding<a class="anchor" aria-label="anchor" href="#simple-thresholding"></a>
</h2>
<hr class="half-width">
<p>Consider the hematoxylin and DAB stained immunohistochemistry image
that we saved from the scikit example data in <a href="03-skimage-images.html">the <em>Working with scikit-image</em>
episode</a>.</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="co"># load the image</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>hed_image <span class="op">=</span> iio.imread(uri<span class="op">=</span><span class="st">"data/immunohistochemistry.tif"</span>)</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>plt.imshow(hed_image)</span></code></pre>
</div>
<figure><img src="../data/immunohistochemistry.jpg" alt="HED IHC scikit example image" class="figure mx-auto d-block"></figure><p>Now suppose we want to select only the stained portion of the image.
In other words, we want to leave the pixels belonging to the stained
tissue “on,” while turning the rest of the pixels “off,” by setting
their colour channel values to zeros. The scikit-image library has
several different methods of thresholding. We will start with the
simplest version, which involves an important step of human input.
Specifically, in this simple, <em>fixed-level thresholding</em>, we have
to provide a threshold value <code>t</code>.</p>
<p>The process works like this. First, we will load the original image,
convert it to grayscale, and de-noise it as in <a href="06-blurring.html">the <em>Blurring Images</em> episode</a>.</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="co"># convert the image to grayscale</span></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>hed_gray <span class="op">=</span> ski.color.rgb2gray(hed_image)</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a><span class="co"># blur the image to denoise</span></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a>hed_blurred <span class="op">=</span> ski.filters.gaussian(hed_gray, sigma<span class="op">=</span><span class="fl">1.0</span>)</span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a>plt.imshow(hed_blurred, cmap<span class="op">=</span><span class="st">"gray"</span>)</span></code></pre>
</div>
<figure><img src="../fig/ihc-grayscale-blurred.jpg" alt="Grayscale and blurred ihc image" class="figure mx-auto d-block"></figure><div id="denoising-an-image-before-thresholding" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="denoising-an-image-before-thresholding" class="callout-inner">
<h3 class="callout-title">Denoising an image before thresholding</h3>
<div class="callout-content">
<p>In practice, it is often necessary to denoise the image before
thresholding, which can be done with one of the methods from <a href="06-blurring.html">the <em>Blurring Images</em> episode</a>.</p>
<p>It may also be helpful to perform other types of denoising or
background subtraction, such as <a href="https://scikit-image.org/docs/stable/api/skimage.restoration.html#skimage.restoration.rolling_ball" class="external-link">rolling
ball</a> or <a href="https://scikit-image.org/docs/stable/api/skimage.morphology.html#skimage.morphology.black_tophat" class="external-link">tophat
transforms</a>.</p>
</div>
</div>
</div>
<p>Next, we would like to apply the threshold <code>t</code> such that
pixels with grayscale values on one side of <code>t</code> will be
turned “on”, while pixels with grayscale values on the other side will
be turned “off”. How might we do that? Remember that grayscale images
contain pixel values in the range from 0 to 1, so we are looking for a
threshold <code>t</code> in the closed range [0.0, 1.0]. We see in the
image that the stained tissue is “darker” than the white background but
there is also some light gray noise on the background. One way to
determine a “good” value for <code>t</code> is to look at the grayscale
histogram of the image and try to identify what grayscale ranges
correspond to the staining in the image or the background.</p>
<p>The histogram can be produced as in <a href="05-creating-histograms.html">the <em>Creating Histograms</em>
episode</a>.</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="co"># create a histogram of the blurred grayscale image</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>histogram, bin_edges <span class="op">=</span> np.histogram(hed_blurred, bins<span class="op">=</span><span class="dv">256</span>, <span class="bu">range</span><span class="op">=</span>(<span class="fl">0.0</span>, <span class="fl">1.0</span>))</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a>plt.plot(bin_edges[<span class="dv">0</span>:<span class="op">-</span><span class="dv">1</span>], histogram)</span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a>plt.title(<span class="st">"Grayscale Histogram"</span>)</span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a>plt.xlabel(<span class="st">"grayscale value"</span>)</span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a>plt.ylabel(<span class="st">"pixels"</span>)</span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a>plt.xlim(<span class="dv">0</span>, <span class="fl">1.0</span>)</span></code></pre>
</div>
<figure><img src="../fig/ihc-blurred-grayscale-histogram.png" alt="Grayscale histogram of the blurred ihc image" class="figure mx-auto d-block"></figure><p>Since the image has a white background, most of the pixels in the
image are almost-white. This corresponds nicely to what we see in the
histogram: there is a peak above 0.8. If we want to select the stained
tissue and not the background, we want to turn off the white background
pixels, while leaving the pixels for the staining turned on. So, we
should choose a value of <code>t</code> somewhere before the large peak
and turn pixels above that value “off”. Let us choose
<code>t=0.7</code>.</p>
<p>To apply the threshold <code>t</code>, we can use the NumPy
comparison operators to create a mask. Here, we want to turn “on” all
pixels which have values smaller than the threshold, so we use the less
operator <code>&lt;</code> to compare the <code>blurred_image</code> to
the threshold <code>t</code>. The operator returns a mask, that we
capture in the variable <code>binary_mask</code>. It has only one
channel, and each of its values is either 0 or 1. The binary mask
created by the thresholding operation can be shown with
<code>plt.imshow</code>, where the <code>False</code> entries are shown
as black pixels (0-valued) and the <code>True</code> entries are shown
as white pixels (1-valued).</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="co"># create a mask based on the threshold</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>t <span class="op">=</span> <span class="fl">0.7</span></span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>binary_mask <span class="op">=</span> hed_blurred <span class="op">&lt;</span> t</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>plt.imshow(binary_mask, cmap<span class="op">=</span><span class="st">"gray"</span>)</span></code></pre>
</div>
<figure><img src="../fig/ihc-mask.jpg" alt="Binary mask of the stained tissue created by thresholding" class="figure mx-auto d-block"></figure><p>You can see that the areas where the staining was in the original
area are now white, while the rest of the mask image is black.</p>
<div id="what-makes-a-good-threshold" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="what-makes-a-good-threshold" class="callout-inner">
<h3 class="callout-title">What makes a good threshold?</h3>
<div class="callout-content">
<p>As is often the case, the answer to this question is “it depends”. In
the example above, we could have just switched off all the white
background pixels by choosing <code>t=1.0</code>, but this would leave
us with some background noise in the mask image. On the other hand, if
we choose too low a value for the threshold, we could lose some of the
staining that as too light. You can experiment with the threshold by
re-running the above code lines with different values for
<code>t</code>. In practice, it is a matter of domain knowledge and
experience to interpret the peaks in the histogram so to determine an
appropriate threshold. The process often involves trial and error, which
is a drawback of the simple thresholding method. Below we will introduce
automatic thresholding, which uses a quantitative, mathematical
definition for a good threshold that allows us to determine the value of
<code>t</code> automatically. It is worth noting that the principle for
simple and automatic thresholding can also be used for images with pixel
ranges other than [0.0, 1.0]. For example, we could perform thresholding
on pixel intensity values in the range [0, 255] as we have already seen
in <a href="03-skimage-images.html">the <em>Working with
scikit-image</em> episode</a>.</p>
</div>
</div>
</div>
<p>We can now apply the <code>binary_mask</code> to the original
coloured image as we have learned in <a href="04-drawing.html">the
<em>Drawing and Bitwise Operations</em> episode</a>. What we are left
with is only the stained tissue from the original.</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="co"># use the binary_mask to select the "interesting" part of the image</span></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>foreground <span class="op">=</span> hed_image.copy()</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>foreground[<span class="op">~</span>binary_mask] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a>plt.imshow(foreground)</span></code></pre>
</div>
<figure><img src="../fig/ihc-foreground.jpg" alt="Selected foreground after applying binary mask" class="figure mx-auto d-block"></figure><div id="code-cheatsheet-for-more-practice-with-simple-thresholding" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="code-cheatsheet-for-more-practice-with-simple-thresholding" class="callout-inner">
<h3 class="callout-title">Code cheatsheet for “More practice with simple thresholding”:</h3>
<div class="callout-content">
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="im">import</span> imageio.v3 <span class="im">as</span> iio</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a><span class="im">import</span> ipympl</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a><span class="im">import</span> skimage <span class="im">as</span> ski</span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a><span class="op">%</span>matplotlib widget</span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a><span class="co"># Read in image (from the uri path to the image file)</span></span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a>image <span class="op">=</span> iio.imread(uri)</span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a><span class="co"># Select single channel (where c is the index of the channel)</span></span>
<span id="cb7-11"><a href="#cb7-11" tabindex="-1"></a>channel <span class="op">=</span> image[:,:,c]</span>
<span id="cb7-12"><a href="#cb7-12" tabindex="-1"></a><span class="co"># Blur image</span></span>
<span id="cb7-13"><a href="#cb7-13" tabindex="-1"></a>blurred_image <span class="op">=</span> skimage.filters.gaussian(channel, sigma<span class="op">=</span><span class="fl">1.0</span>)</span>
<span id="cb7-14"><a href="#cb7-14" tabindex="-1"></a></span>
<span id="cb7-15"><a href="#cb7-15" tabindex="-1"></a><span class="co"># Create and display image</span></span>
<span id="cb7-16"><a href="#cb7-16" tabindex="-1"></a>histogram, bin_edges <span class="op">=</span> np.histogram(blurred_image, bins<span class="op">=</span><span class="dv">256</span>, <span class="bu">range</span><span class="op">=</span>(<span class="fl">0.0</span>,<span class="fl">1.0</span>))</span>
<span id="cb7-17"><a href="#cb7-17" tabindex="-1"></a>fig,ax <span class="op">=</span> plt.subplots()</span>
<span id="cb7-18"><a href="#cb7-18" tabindex="-1"></a>plt.plot(bin_edges[<span class="dv">0</span>:<span class="op">-</span><span class="dv">1</span>], histogram)</span>
<span id="cb7-19"><a href="#cb7-19" tabindex="-1"></a>plt.title(<span class="st">"Channel histogram"</span>)</span>
<span id="cb7-20"><a href="#cb7-20" tabindex="-1"></a>plt.xlabel(<span class="st">"pixel value"</span>)</span>
<span id="cb7-21"><a href="#cb7-21" tabindex="-1"></a>plt.ylabel(<span class="st">"pixels"</span>)</span>
<span id="cb7-22"><a href="#cb7-22" tabindex="-1"></a>plt.xlim(<span class="dv">0</span>, <span class="fl">1.0</span>)</span>
<span id="cb7-23"><a href="#cb7-23" tabindex="-1"></a></span>
<span id="cb7-24"><a href="#cb7-24" tabindex="-1"></a><span class="co"># Threshold image, keeping pixels with value &gt; t</span></span>
<span id="cb7-25"><a href="#cb7-25" tabindex="-1"></a>binary_mask <span class="op">=</span> blurred_image <span class="op">&gt;</span> t</span>
<span id="cb7-26"><a href="#cb7-26" tabindex="-1"></a></span>
<span id="cb7-27"><a href="#cb7-27" tabindex="-1"></a><span class="co"># Plot threshold image</span></span>
<span id="cb7-28"><a href="#cb7-28" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb7-29"><a href="#cb7-29" tabindex="-1"></a>plt.imshow(binary_mask, cmap<span class="op">=</span><span class="st">"gray"</span>)</span>
<span id="cb7-30"><a href="#cb7-30" tabindex="-1"></a></span>
<span id="cb7-31"><a href="#cb7-31" tabindex="-1"></a><span class="co"># Copy image so we don't change the original</span></span>
<span id="cb7-32"><a href="#cb7-32" tabindex="-1"></a>foreground <span class="op">=</span> image.copy()</span>
<span id="cb7-33"><a href="#cb7-33" tabindex="-1"></a></span>
<span id="cb7-34"><a href="#cb7-34" tabindex="-1"></a><span class="co"># Turn off all the pixels that are not our thresholded foreground</span></span>
<span id="cb7-35"><a href="#cb7-35" tabindex="-1"></a>foreground[<span class="op">~</span>binary_mask] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb7-36"><a href="#cb7-36" tabindex="-1"></a></span>
<span id="cb7-37"><a href="#cb7-37" tabindex="-1"></a><span class="co"># Display the image with only foreground pixels</span></span>
<span id="cb7-38"><a href="#cb7-38" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb7-39"><a href="#cb7-39" tabindex="-1"></a>plt.imshow(foreground)</span></code></pre>
</div>
</div>
</div>
</div>
<div id="more-practice-with-simple-thresholding-20-min" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="more-practice-with-simple-thresholding-20-min" class="callout-inner">
<h3 class="callout-title">More practice with simple thresholding (20 min)</h3>
<div class="callout-content">
<p>Now, it is your turn to practice. Suppose we want to use simple
thresholding to select only the nuclei from the image
<code>data/hela-cells-8bit.tif</code>:</p>
<figure><img src="../fig/hela-cells-8bit.jpg" alt="HeLa cells color image" class="figure mx-auto d-block"></figure><p>Since the nuclei are marked in this multichannel image by high values
of the blue channel, there are a few differences. Instead of using the
grayscale image, select the blue channel using
<code>image[:,:,2]</code>. This will act as your grayscale image, since
it also has only one value per pixel.</p>
<figure><img src="../fig/cells-nuclei-gray.jpg" alt="HeLa cells gray nuclei" class="figure mx-auto d-block"></figure>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<p>The histogram for the blue channel of
<code>data/hela-cells-8bit.tif</code> image can be shown with</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a>cells <span class="op">=</span> iio.imread(uri<span class="op">=</span><span class="st">"data/hela-cells-8bit.tif"</span>)</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>blue_channel <span class="op">=</span> cells[:,:,<span class="dv">2</span>]</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>blurred_image <span class="op">=</span> skimage.filters.gaussian(blue_channel, sigma<span class="op">=</span><span class="fl">1.0</span>)</span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a>histogram, bin_edges <span class="op">=</span> np.histogram(blurred_image, bins<span class="op">=</span><span class="dv">256</span>, <span class="bu">range</span><span class="op">=</span>(<span class="fl">0.0</span>,<span class="fl">1.0</span>))</span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a>fig,ax <span class="op">=</span> plt.subplots()</span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a>plt.plot(bin_edges[<span class="dv">0</span>:<span class="op">-</span><span class="dv">1</span>], histogram)</span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a>plt.title(<span class="st">"Blue (nuclei) channel histogram"</span>)</span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a>plt.xlabel(<span class="st">"pixel value"</span>)</span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a>plt.ylabel(<span class="st">"pixels"</span>)</span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a>plt.xlim(<span class="dv">0</span>, <span class="fl">1.0</span>)</span></code></pre>
</div>
<figure><img src="../fig/cells-blue-histogram.png" alt="Histogram of the blue channel from the HeLa cells image" class="figure mx-auto d-block"></figure><p>We can see a large spike around 0, and a very low bump around 0.3.
The spike near 0 represents the darker background, and the bump around
0.3 represents the nuclei signal. So it seems like a value between the
two would be a good choice. Let’s choose <code>t=0.1</code>.</p>
</div>
</div>
</div>
</div>
<div id="more-practice-with-simple-thresholding-20-min" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="more-practice-with-simple-thresholding-20-min" class="callout-inner">
<h3 class="callout-title">More practice with simple thresholding (20
min)<em> (continued)</em>
</h3>
<div class="callout-content">
<p>Next, create a mask to turn the pixels above the threshold
<code>t</code> on and pixels below the threshold <code>t</code> off.
Note that unlike the image with a white background we used above, here
the peak for the background colour is darker than the foreground objects
or nuclei. Therefore, change the comparison operator less
<code>&lt;</code> to greater <code>&gt;</code> to create the appropriate
mask. Then apply the mask to the image and view the thresholded image.
If everything works as it should, your output should show only the
coloured nuclei on a black background.</p>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" data-bs-parent="#accordionSolution2" aria-labelledby="headingSolution2">
<div class="accordion-body">
<p>Here are the commands to create and view the binary mask</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a>t <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>binary_mask <span class="op">=</span> blurred_image <span class="op">&gt;</span> t</span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a>plt.imshow(binary_mask, cmap<span class="op">=</span><span class="st">"gray"</span>)</span></code></pre>
</div>
<figure><img src="../fig/cells-mask.jpg" alt="Binary mask created by thresholding the HeLa cells image" class="figure mx-auto d-block"></figure><p>And here are the commands to apply the mask and view the thresholded
image</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a>nuclei_only <span class="op">=</span> cells.copy()</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>nuclei_only[<span class="op">~</span>binary_mask] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a>plt.imshow(nuclei_only)</span></code></pre>
</div>
<figure><img src="../fig/nuclei-selected.jpg" alt="Selected nuclei after applying binary mask to the HeLa cells image" class="figure mx-auto d-block"></figure>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="automatic-thresholding">Automatic thresholding<a class="anchor" aria-label="anchor" href="#automatic-thresholding"></a>
</h2>
<hr class="half-width">
<p>The downside of the simple thresholding technique is that we have to
make an educated guess about the threshold <code>t</code> by inspecting
the histogram. There are also <em>automatic thresholding</em> methods
that can determine the threshold automatically for us. One such method
is <em><a href="https://en.wikipedia.org/wiki/Otsu%27s_method" class="external-link">Otsu’s
method</a></em>. It is particularly useful for situations where the
grayscale histogram of an image has two peaks that correspond to
background and objects of interest. Other automated methods might work
better depending on the shape of the histogram.</p>
<p>Let’s apply automated thresholding methods to identify the nuclei in
the HeLa cells image:</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a>cells <span class="op">=</span> iio.imread(uri<span class="op">=</span><span class="st">"data/hela-cells-8bit.tif"</span>)</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a><span class="co"># select only the nuclei channel</span></span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a>blue_channel <span class="op">=</span> cells[:,:,<span class="dv">2</span>]</span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a></span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a><span class="co"># blur the image to denoise</span></span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a>blurred_image <span class="op">=</span> ski.filters.gaussian(blue_channel, sigma<span class="op">=</span><span class="fl">1.0</span>)</span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a></span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a><span class="co"># show the histogram of the blurred image</span></span>
<span id="cb11-10"><a href="#cb11-10" tabindex="-1"></a>histogram, bin_edges <span class="op">=</span> np.histogram(blurred_image, bins<span class="op">=</span><span class="dv">256</span>, <span class="bu">range</span><span class="op">=</span>(<span class="fl">0.0</span>, <span class="fl">1.0</span>))</span>
<span id="cb11-11"><a href="#cb11-11" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb11-12"><a href="#cb11-12" tabindex="-1"></a>plt.plot(bin_edges[<span class="dv">0</span>:<span class="op">-</span><span class="dv">1</span>], histogram)</span>
<span id="cb11-13"><a href="#cb11-13" tabindex="-1"></a>plt.title(<span class="st">"Blue (nuclei) channel histogram"</span>)</span>
<span id="cb11-14"><a href="#cb11-14" tabindex="-1"></a>plt.xlabel(<span class="st">"pixel value"</span>)</span>
<span id="cb11-15"><a href="#cb11-15" tabindex="-1"></a>plt.ylabel(<span class="st">"pixel count"</span>)</span>
<span id="cb11-16"><a href="#cb11-16" tabindex="-1"></a>plt.xlim(<span class="dv">0</span>, <span class="fl">1.0</span>)</span></code></pre>
</div>
<figure><img src="../fig/cells-blue-histogram.png" alt="Histogram of the blue channel on the HeLa cells image" class="figure mx-auto d-block"></figure><p>The histogram has a significant peak around 0 and then a broader
“hill” around 0.3. Looking at the grayscale image, we can identify the
peak at 0 with the background and the broader hill around 0.3 with the
foreground. The mathematical details of how automated thresholders work
are complicated (see <a href="https://scikit-image.org/docs/dev/api/skimage.filters.html#threshold-otsu" class="external-link">the
scikit-image documentation</a> if you are interested), but the outcome
is that Otsu’s method finds a threshold value between the two peaks of a
grayscale histogram which might correspond well to the foreground and
background depending on the data and application.</p>
<div id="accordionInstructor1" class="accordion instructor-note accordion-flush">
<div class="accordion-item">
<button class="accordion-button instructor-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseInstructor1" aria-expanded="false" aria-controls="collapseInstructor1">
  <h3 class="accordion-header" id="headingInstructor1">  <div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="edit-2"></i></div> Instructor Note </h3>
</button>
<div id="collapseInstructor1" class="accordion-collapse collapse" data-bs-parent="#accordionInstructor1" aria-labelledby="headingInstructor1">
<div class="accordion-body">
<p>The histogram may prompt questions from learners about the
interpretation of the peaks and the broader region. The focus here is on
the separation of background and foreground pixel values. We note that
Otsu’s method does not work very well as the foreground pixel values are
more distributed. These examples could be augmented with a discussion of
unimodal, bimodal, and multimodal histograms. While these points can
lead to fruitful considerations, the text in this episode attempts to
reduce cognitive load and deliberately simplifies the discussion.</p>
</div>
</div>
</div>
</div>
<p>The <code>ski.filters.threshold_otsu()</code> function can be used to
determine the threshold automatically via Otsu’s method. Then NumPy
comparison operators can be used to apply it as before. Here are the
Python commands to determine the threshold <code>t</code> with Otsu’s
method.</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="co"># perform automatic thresholding</span></span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a>t <span class="op">=</span> ski.filters.threshold_otsu(blurred_image)</span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Found automatic threshold t = </span><span class="sc">{}</span><span class="st">."</span>.<span class="bu">format</span>(t))</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Found automatic threshold t = 0.4172454549881862.</code></pre>
</div>
<p>For this image, after blurring with the chosen sigma of 1.0, the
computed threshold value is 0.21. Now we can create a binary mask with
the comparison operator <code>&gt;</code>. As we have seen before,
pixels above the threshold value will be turned on, those below the
threshold will be turned off.</p>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="co"># create a binary mask with the threshold found by Otsu's method</span></span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a>binary_mask <span class="op">=</span> blurred_image <span class="op">&gt;</span> t</span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb14-5"><a href="#cb14-5" tabindex="-1"></a>plt.imshow(binary_mask, cmap<span class="op">=</span><span class="st">"gray"</span>)</span></code></pre>
</div>
<figure><img src="../fig/cells-otsu-mask.jpg" alt="Binary mask of nuclei using otsu thresholding" class="figure mx-auto d-block"></figure><p>Otsu’s method generates a fairly conservative mask on this image,
meaning that the threshold was fairly high and less of the foreground is
kept by the mask. There may be other automated thresholders that work
better in this application. Scikit image provides a method that can give
a visual test of all of them at once.</p>
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a>fig, ax <span class="op">=</span> ski.filters.try_all_threshold(blurred_image, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>), verbose<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="../fig/cells-thresholder-test.png" alt="Overview test of all automated thresholders in scikit image" class="figure mx-auto d-block"></figure></section><section><h2 class="section-heading" id="measuring-thresholded-areas">Measuring thresholded areas<a class="anchor" aria-label="anchor" href="#measuring-thresholded-areas"></a>
</h2>
<hr class="half-width">
<p>There are many reasons why we might want to measure the percentage or
size of a thresholded foreground in an image, for instance to assess
tumor percentage in a tissue section or confluence of a cell culture.
Here we will use it to compare the results of different automated
thresholding methods.</p>
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="co"># Load and denoise the image</span></span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a>hed_image <span class="op">=</span> iio.imread(uri<span class="op">=</span><span class="st">"data/immunohistochemistry.tif"</span>)</span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a>gray_image <span class="op">=</span> skimage.color.rgb2gray(hed_image)</span>
<span id="cb16-4"><a href="#cb16-4" tabindex="-1"></a>blurred_image <span class="op">=</span> skimage.filters.gaussian(gray_image, sigma<span class="op">=</span><span class="fl">1.0</span>)</span>
<span id="cb16-5"><a href="#cb16-5" tabindex="-1"></a></span>
<span id="cb16-6"><a href="#cb16-6" tabindex="-1"></a><span class="co"># Visually compare automated thresholding methods</span></span>
<span id="cb16-7"><a href="#cb16-7" tabindex="-1"></a>fig, ax <span class="op">=</span> ski.filters.try_all_threshold(blurred_image, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>), verbose<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb16-8"><a href="#cb16-8" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<p>Write a function to calculate the percentage of thresholded
foreground in the image by counting the number of nonzero (or true)
pixels in the binary mask and dividing by the total count of pixels.</p>
<div class="codewrapper sourceCode" id="cb17">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a><span class="kw">def</span> measure_foreground(blurred_image, t):</span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a>    binary_mask <span class="op">=</span> blurred_image <span class="op">&lt;</span> t</span>
<span id="cb17-3"><a href="#cb17-3" tabindex="-1"></a>    foreground_pixels <span class="op">=</span> np.count_nonzero(binary_mask)</span>
<span id="cb17-4"><a href="#cb17-4" tabindex="-1"></a>    w <span class="op">=</span> binary_mask.shape[<span class="dv">1</span>]</span>
<span id="cb17-5"><a href="#cb17-5" tabindex="-1"></a>    h <span class="op">=</span> binary_mask.shape[<span class="dv">0</span>]</span>
<span id="cb17-6"><a href="#cb17-6" tabindex="-1"></a>    percentage <span class="op">=</span> foreground_pixels <span class="op">/</span> (w <span class="op">*</span> h) <span class="op">*</span> <span class="dv">100</span></span>
<span id="cb17-7"><a href="#cb17-7" tabindex="-1"></a>    <span class="cf">return</span>(percentage)</span></code></pre>
</div>
<p>Calculate the percentage pixels kept by the Otsu thresholding
method</p>
<div class="codewrapper sourceCode" id="cb18">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a>t_otsu <span class="op">=</span> ski.filters.threshold_otsu(blurred_image)</span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a>percentage_otsu <span class="op">=</span> measure_foreground(blurred_image, t_otsu)</span>
<span id="cb18-3"><a href="#cb18-3" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Otsu thresholding: </span><span class="sc">{:.2f}</span><span class="st">%"</span>.<span class="bu">format</span>(percentage_otsu))</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Otsu thresholding: 57.96%</code></pre>
</div>
<div id="measure-results-of-automated-threshold-methods" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="measure-results-of-automated-threshold-methods" class="callout-inner">
<h3 class="callout-title">Measure results of automated threshold methods</h3>
<div class="callout-content">
<p>Following the pipeline from above, measure the percentage of pixels
kept by two different automated threshold methods.</p>
</div>
</div>
</div>
<div id="accordionSolution3" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution3" aria-expanded="false" aria-controls="collapseSolution3">
  <h4 class="accordion-header" id="headingSolution3"> Solution with Triangle and Yen thresholding methods </h4>
</button>
<div id="collapseSolution3" class="accordion-collapse collapse" data-bs-parent="#accordionSolution3" aria-labelledby="headingSolution3">
<div class="accordion-body">
<div class="codewrapper sourceCode" id="cb20">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a>t_triangle <span class="op">=</span> ski.filters.threshold_triangle(blurred_image)</span>
<span id="cb20-2"><a href="#cb20-2" tabindex="-1"></a>percentage_triangle <span class="op">=</span> measure_foreground(blurred_image, t_triangle)</span>
<span id="cb20-3"><a href="#cb20-3" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Triangle thresholding: </span><span class="sc">{:.2f}</span><span class="st">%"</span>.<span class="bu">format</span>(percentage_triangle))</span>
<span id="cb20-4"><a href="#cb20-4" tabindex="-1"></a></span>
<span id="cb20-5"><a href="#cb20-5" tabindex="-1"></a>t_yen <span class="op">=</span> ski.filters.threshold_yen(blurred_image)</span>
<span id="cb20-6"><a href="#cb20-6" tabindex="-1"></a>percentage_yen <span class="op">=</span> measure_foreground(blurred_image, t_yen)</span>
<span id="cb20-7"><a href="#cb20-7" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Yen thresholding: </span><span class="sc">{:.2f}</span><span class="st">%"</span>.<span class="bu">format</span>(percentage_yen))</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Triangle thresholding: 96.88%
Yen thresholding: 48.77%</code></pre>
</div>
</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul>
<li>Thresholding produces a binary image, where all pixels with
intensities above (or below) a threshold value are turned on, while all
other pixels are turned off.</li>
<li>The binary images produced by thresholding are held in
two-dimensional NumPy arrays, since they have only one colour value
channel. They are boolean, hence they contain the values 0 (off) and 1
(on).</li>
<li>Thresholding can be used to create masks that select only the
interesting parts of an image, or as the first step before edge
detection or finding contours.</li>
</ul>
</div>
</div>
</div>
</section></section><section id="aio-08-connected-components"><p>Content from <a href="08-connected-components.html">Connected Component Analysis</a></p>
<hr>
<p>Last updated on 2024-03-26 |

        <a href="https://github.com/govekk/image-processing/edit/main/episodes/08-connected-components.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 125 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How to extract separate objects from an image and describe these
objects quantitatively.</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Understand the term object in the context of images.</li>
<li>Learn about pixel connectivity.</li>
<li>Learn how Connected Component Analysis (CCA) works.</li>
<li>Use CCA to produce an image that highlights every object in a
different colour.</li>
<li>Characterise each object with numbers that describe its
appearance.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="objects">Objects<a class="anchor" aria-label="anchor" href="#objects"></a>
</h2>
<hr class="half-width">
<p>In <a href="07-thresholding.html">the <em>Thresholding</em>
episode</a> we have covered dividing an image into foreground and
background pixels. In the HeLa cells example image blue channel, we
considered the coloured nuclei as foreground <em>objects</em> on a black
background.</p>
<figure><img src="../fig/cells-nuclei-gray.jpg" alt="Nuclei channel of HeLa cells" class="figure mx-auto d-block"></figure><p>In thresholding we went from the original image to this version:</p>
<figure><img src="../fig/cells-mask.jpg" alt="Mask created by thresholding" class="figure mx-auto d-block"></figure><p>Here, we created a mask that only highlights the parts of the image
that we find interesting, the <em>objects</em>. All objects have pixel
value of <code>True</code> while the background pixels are
<code>False</code>.</p>
<p>By looking at the mask image, one can count the objects that are
present in the image. But how did we actually do that, how did we decide
which lump of pixels constitutes a single object?</p>
</section><section><h2 class="section-heading" id="pixel-neighborhoods">Pixel Neighborhoods<a class="anchor" aria-label="anchor" href="#pixel-neighborhoods"></a>
</h2>
<hr class="half-width">
<p>In order to decide which pixels belong to the same object, one can
exploit their neighborhood: pixels that are directly next to each other
and belong to the foreground class can be considered to belong to the
same object.</p>
<p>Let’s discuss the concept of pixel neighborhoods in more detail.
Consider the following mask “image” with 8 rows, and 8 columns. For the
purpose of illustration, the digit <code>0</code> is used to represent
background pixels, and the letter <code>X</code> is used to represent
object pixels foreground).</p>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>0 0 0 0 0 0 0 0
0 X X 0 0 0 0 0
0 X X 0 0 0 0 0
0 0 0 X X X 0 0
0 0 0 X X X X 0
0 0 0 0 0 0 0 0</code></pre>
</div>
<p>The pixels are organised in a rectangular grid. In order to
understand pixel neighborhoods we will introduce the concept of “jumps”
between pixels. The jumps follow two rules: First rule is that one jump
is only allowed along the column, or the row. Diagonal jumps are not
allowed. So, from a centre pixel, denoted with <code>o</code>, only the
pixels indicated with a <code>1</code> are reachable:</p>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>- 1 -
1 o 1
- 1 -</code></pre>
</div>
<p>The pixels on the diagonal (from <code>o</code>) are not reachable
with a single jump, which is denoted by the <code>-</code>. The pixels
reachable with a single jump form the <strong>1-jump</strong>
neighborhood.</p>
<p>The second rule states that in a sequence of jumps, one may only jump
in row and column direction once -&gt; they have to be
<em>orthogonal</em>. An example of a sequence of orthogonal jumps is
shown below. Starting from <code>o</code> the first jump goes along the
row to the right. The second jump then goes along the column direction
up. After this, the sequence cannot be continued as a jump has already
been made in both row and column direction.</p>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>- - 2
- o 1
- - -</code></pre>
</div>
<p>All pixels reachable with one, or two jumps form the
<strong>2-jump</strong> neighborhood. The grid below illustrates the
pixels reachable from the centre pixel <code>o</code> with a single
jump, highlighted with a <code>1</code>, and the pixels reachable with 2
jumps with a <code>2</code>.</p>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>2 1 2
1 o 1
2 1 2</code></pre>
</div>
<p>We want to revisit our example image mask from above and apply the
two different neighborhood rules. With a single jump connectivity for
each pixel, we get two resulting objects, highlighted in the image with
<code>A</code>’s and <code>B</code>’s.</p>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>0 0 0 0 0 0 0 0
0 A A 0 0 0 0 0
0 A A 0 0 0 0 0
0 0 0 B B B 0 0
0 0 0 B B B B 0
0 0 0 0 0 0 0 0</code></pre>
</div>
<p>In the 1-jump version, only pixels that have direct neighbors along
rows or columns are considered connected. Diagonal connections are not
included in the 1-jump neighborhood. With two jumps, however, we only
get a single object <code>A</code> because pixels are also considered
connected along the diagonals.</p>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>0 0 0 0 0 0 0 0
0 A A 0 0 0 0 0
0 A A 0 0 0 0 0
0 0 0 A A A 0 0
0 0 0 A A A A 0
0 0 0 0 0 0 0 0</code></pre>
</div>
<div id="object-counting-optional-not-included-in-timing" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="object-counting-optional-not-included-in-timing" class="callout-inner">
<h3 class="callout-title">Object counting (optional, not included in timing)</h3>
<div class="callout-content">
<p>How many objects with 1 orthogonal jump, how many with 2 orthogonal
jumps?</p>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>0 0 0 0 0 0 0 0
0 X 0 0 0 X X 0
0 0 X 0 0 0 0 0
0 X 0 X X X 0 0
0 X 0 X X 0 0 0
0 0 0 0 0 0 0 0</code></pre>
</div>
<p>1 jump</p>
<ol style="list-style-type: lower-alpha">
<li>1</li>
<li>5</li>
<li>2</li>
</ol>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<ol start="2" style="list-style-type: lower-alpha">
<li>5</li>
</ol>
</div>
</div>
</div>
</div>
<div id="object-counting-optional-not-included-in-timing" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="object-counting-optional-not-included-in-timing" class="callout-inner">
<h3 class="callout-title">Object counting (optional, not included in
timing)<em> (continued)</em>
</h3>
<div class="callout-content">
<p>2 jumps</p>
<ol style="list-style-type: lower-alpha">
<li>2</li>
<li>3</li>
<li>5</li>
</ol>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" data-bs-parent="#accordionSolution2" aria-labelledby="headingSolution2">
<div class="accordion-body">
<ol style="list-style-type: lower-alpha">
<li>2</li>
</ol>
</div>
</div>
</div>
</div>
<div id="jumps-and-neighborhoods" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="jumps-and-neighborhoods" class="callout-inner">
<h3 class="callout-title">Jumps and neighborhoods</h3>
<div class="callout-content">
<p>We have just introduced how you can reach different neighboring
pixels by performing one or more orthogonal jumps. We have used the
terms 1-jump and 2-jump neighborhood. There is also a different way of
referring to these neighborhoods: the 4- and 8-neighborhood. With a
single jump you can reach four pixels from a given starting pixel.
Hence, the 1-jump neighborhood corresponds to the 4-neighborhood. When
two orthogonal jumps are allowed, eight pixels can be reached, so the
2-jump neighborhood corresponds to the 8-neighborhood.</p>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="connected-component-analysis">Connected Component Analysis<a class="anchor" aria-label="anchor" href="#connected-component-analysis"></a>
</h2>
<hr class="half-width">
<p>In order to find the objects in an image, we want to employ an
operation that is called Connected Component Analysis (CCA). This
operation takes a binary image as an input. Usually, the
<code>False</code> value in this image is associated with background
pixels, and the <code>True</code> value indicates foreground, or object
pixels. Such an image can be produced, e.g., with thresholding. Given a
thresholded image, the connected component analysis produces a new
<em>labeled</em> image with integer pixel values. Pixels with the same
value, belong to the same object. scikit-image provides connected
component analysis in the function <code>ski.measure.label()</code>. Let
us add this function to the already familiar steps of thresholding an
image.</p>
<p>First, import the packages needed for this episode:</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="im">import</span> imageio.v3 <span class="im">as</span> iio</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a><span class="im">import</span> ipympl</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a><span class="im">import</span> skimage <span class="im">as</span> ski</span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a><span class="op">%</span>matplotlib widget</span></code></pre>
</div>
<p>In this episode, we will use the <code>ski.measure.label</code>
function to perform the CCA.</p>
<p>Next, we define a reusable Python function
<code>segment_multichannel</code>, for finding connected components
within a fluorescent (dark background, light objects) multichannel
image:</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="kw">def</span> segment_multichannel(filename, channel<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="fl">1.0</span>, t<span class="op">=</span><span class="fl">0.5</span>, connectivity<span class="op">=</span><span class="dv">2</span>):</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>    <span class="co"># load the image</span></span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a>    image <span class="op">=</span> iio.imread(filename)</span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a>    <span class="co"># convert the image to grayscale</span></span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a>    channel_image <span class="op">=</span> image[:,:,channel]</span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a>    <span class="co"># denoise the image with a Gaussian filter</span></span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a>    blurred_image <span class="op">=</span> ski.filters.gaussian(channel_image, sigma<span class="op">=</span>sigma)</span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a>    <span class="co"># mask the image according to threshold</span></span>
<span id="cb9-9"><a href="#cb9-9" tabindex="-1"></a>    binary_mask <span class="op">=</span> blurred_image <span class="op">&gt;</span> t</span>
<span id="cb9-10"><a href="#cb9-10" tabindex="-1"></a>    <span class="co"># perform connected component analysis</span></span>
<span id="cb9-11"><a href="#cb9-11" tabindex="-1"></a>    labeled_image, count <span class="op">=</span> ski.measure.label(binary_mask,</span>
<span id="cb9-12"><a href="#cb9-12" tabindex="-1"></a>                                                 connectivity<span class="op">=</span>connectivity, return_num<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb9-13"><a href="#cb9-13" tabindex="-1"></a>    <span class="cf">return</span> labeled_image, count</span></code></pre>
</div>
<p>The first four lines of code are familiar from <a href="07-thresholding.html">the <em>Thresholding</em> episode</a>.</p>
<p>Then we call the <code>ski.measure.label</code> function. This
function has one positional argument where we pass the
<code>binary_mask</code>, i.e., the binary image to work on. With the
optional argument <code>connectivity</code>, we specify the neighborhood
in units of orthogonal jumps. For example, by setting
<code>connectivity=2</code> we will consider the 2-jump neighborhood
introduced above. The function returns a <code>labeled_image</code>
where each pixel has a unique value corresponding to the object it
belongs to. In addition, we pass the optional parameter
<code>return_num=True</code> to return the maximum label index as
<code>count</code>.</p>
<div id="optional-parameters-and-return-values" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="optional-parameters-and-return-values" class="callout-inner">
<h3 class="callout-title">Optional parameters and return values</h3>
<div class="callout-content">
<p>The optional parameter <code>return_num</code> changes the data type
that is returned by the function <code>ski.measure.label</code>. The
number of labels is only returned if <code>return_num</code> is
<em>True</em>. Otherwise, the function only returns the labeled image.
This means that we have to pay attention when assigning the return value
to a variable. If we omit the optional parameter <code>return_num</code>
or pass <code>return_num=False</code>, we can call the function as</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a>labeled_image <span class="op">=</span> ski.measure.label(binary_mask)</span></code></pre>
</div>
<p>If we pass <code>return_num=True</code>, the function returns a tuple
and we can assign it as</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a>labeled_image, count <span class="op">=</span> ski.measure.label(binary_mask, return_num<span class="op">=</span><span class="va">True</span>)</span></code></pre>
</div>
<p>If we used the same assignment as in the first case, the variable
<code>labeled_image</code> would become a tuple, in which
<code>labeled_image[0]</code> is the image and
<code>labeled_image[1]</code> is the number of labels. This could cause
confusion if we assume that <code>labeled_image</code> only contains the
image and pass it to other functions. If you get an
<code>AttributeError: 'tuple' object has no attribute 'shape'</code> or
similar, check if you have assigned the return values consistently with
the optional parameters.</p>
</div>
</div>
</div>
<p>We can call the above function <code>segment_multichannel</code> and
display the labeled image like so:</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a>labeled_image, count <span class="op">=</span> segment_multichannel(filename<span class="op">=</span><span class="st">"data/hela-cells-8bit.tif"</span>, channel<span class="op">=</span><span class="dv">2</span>, sigma<span class="op">=</span><span class="fl">2.0</span>, t<span class="op">=</span><span class="fl">0.1</span>, connectivity<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a>plt.imshow(labeled_image)</span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a>plt.axis(<span class="st">"off"</span>)<span class="op">;</span></span></code></pre>
</div>
<div id="accordionSpoiler1" class="accordion spoiler-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button spoiler-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSpoiler1" aria-expanded="false" aria-controls="collapseSpoiler1">
  <h3 class="accordion-header" id="headingSpoiler1">  <div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="eye"></i></div> Do you see an empty image? </h3>
</button>
<div id="collapseSpoiler1" class="accordion-collapse collapse" data-bs-parent="#accordionSpoiler1" aria-labelledby="headingSpoiler1">
<div class="accordion-body">
<p>If you are using an older version of Matplotlib you might get a
warning
<code>UserWarning: Low image data range; displaying image with stretched contrast.</code>
or just see a visually empty image.</p>
<p>What went wrong? When you hover over the image, the pixel values are
shown as numbers in the lower corner of the viewer. You can see that
some pixels have values different from <code>0</code>, so they are not
actually all the same value. Let’s find out more by examining
<code>labeled_image</code>. Properties that might be interesting in this
context are <code>dtype</code>, the minimum and maximum value. We can
print them with the following lines:</p>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"dtype:"</span>, labeled_image.dtype)</span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"min:"</span>, np.<span class="bu">min</span>(labeled_image))</span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"max:"</span>, np.<span class="bu">max</span>(labeled_image))</span></code></pre>
</div>
<p>Examining the output can give us a clue why the image appears
empty.</p>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code><span><span class="va">dtype</span><span class="op">:</span> <span class="va">int32</span></span>
<span><span class="va">min</span><span class="op">:</span> <span class="fl">0</span></span>
<span><span class="va">max</span><span class="op">:</span> <span class="fl">11</span></span></code></pre>
</div>
<p>The <code>dtype</code> of <code>labeled_image</code> is
<code>int32</code>. This means that values in this image range from
<code>-2 ** 31</code> to <code>2 ** 31 - 1</code>. Those are really big
numbers. From this available space we only use the range from
<code>0</code> to <code>11</code>. When showing this image in the
viewer, it may squeeze the complete range into 256 gray values.
Therefore, the range of our numbers does not produce any visible
variation. One way to rectify this is to explicitly specify the data
range we want the colormap to cover:</p>
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a>plt.imshow(labeled_image, vmin<span class="op">=</span>np.<span class="bu">min</span>(labeled_image), vmax<span class="op">=</span>np.<span class="bu">max</span>(labeled_image))</span></code></pre>
</div>
<p>Note this is the default behaviour for newer versions of
<code>matplotlib.pyplot.imshow</code>. Alternatively we could convert
the image to RGB and then display it.</p>
</div>
</div>
</div>
</div>
<div id="suppressing-outputs-in-jupyter-notebooks" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="suppressing-outputs-in-jupyter-notebooks" class="callout-inner">
<h3 class="callout-title">Suppressing outputs in Jupyter Notebooks</h3>
<div class="callout-content">
<p>We just used <code>plt.axis("off");</code> to hide the axis from the
image for a visually cleaner figure. The semicolon is added to supress
the output(s) of the statement, in this <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.axis.html" class="external-link">case</a>
the axis limits. This is specific to Jupyter Notebooks.</p>
</div>
</div>
</div>
<p>We can use the function <code>ski.color.label2rgb()</code> to convert
the 32-bit grayscale labeled image to standard RGB colour (recall that
we already used the <code>ski.color.rgb2gray()</code> function to
convert to grayscale). With <code>ski.color.label2rgb()</code>, all
objects are coloured according to a list of colours that can be
customised. We can use the following commands to convert and show the
image:</p>
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="co"># convert the label image to color image</span></span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a>colored_label_image <span class="op">=</span> ski.color.label2rgb(labeled_image, bg_label<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb16-5"><a href="#cb16-5" tabindex="-1"></a>plt.imshow(colored_label_image)</span>
<span id="cb16-6"><a href="#cb16-6" tabindex="-1"></a>plt.axis(<span class="st">"off"</span>)<span class="op">;</span></span></code></pre>
</div>
<figure><img src="../fig/cells-labeled.jpg" alt="Labeled objects" class="figure mx-auto d-block"></figure><div id="code-cheatsheet-for-how-does-parameter-choice-change-how-many-objects-are-in-the-image" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="code-cheatsheet-for-how-does-parameter-choice-change-how-many-objects-are-in-the-image" class="callout-inner">
<h3 class="callout-title">Code cheatsheet for “How does parameter choice change how many objects are in the image?”</h3>
<div class="callout-content">
<div class="codewrapper sourceCode" id="cb17">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a><span class="im">import</span> imageio.v3 <span class="im">as</span> iio</span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a><span class="im">import</span> ipympl</span>
<span id="cb17-3"><a href="#cb17-3" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb17-4"><a href="#cb17-4" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb17-5"><a href="#cb17-5" tabindex="-1"></a><span class="im">import</span> skimage <span class="im">as</span> ski</span>
<span id="cb17-6"><a href="#cb17-6" tabindex="-1"></a><span class="op">%</span>matplotlib widget</span>
<span id="cb17-7"><a href="#cb17-7" tabindex="-1"></a></span>
<span id="cb17-8"><a href="#cb17-8" tabindex="-1"></a><span class="kw">def</span> segment_multichannel(filename, channel<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="fl">1.0</span>, t<span class="op">=</span><span class="fl">0.5</span>, connectivity<span class="op">=</span><span class="dv">2</span>):</span>
<span id="cb17-9"><a href="#cb17-9" tabindex="-1"></a>    <span class="co"># load the image</span></span>
<span id="cb17-10"><a href="#cb17-10" tabindex="-1"></a>    image <span class="op">=</span> iio.imread(filename)</span>
<span id="cb17-11"><a href="#cb17-11" tabindex="-1"></a>    <span class="co"># convert the image to grayscale</span></span>
<span id="cb17-12"><a href="#cb17-12" tabindex="-1"></a>    channel_image <span class="op">=</span> image[:,:,channel]</span>
<span id="cb17-13"><a href="#cb17-13" tabindex="-1"></a>    <span class="co"># denoise the image with a Gaussian filter</span></span>
<span id="cb17-14"><a href="#cb17-14" tabindex="-1"></a>    blurred_image <span class="op">=</span> ski.filters.gaussian(channel_image, sigma<span class="op">=</span>sigma)</span>
<span id="cb17-15"><a href="#cb17-15" tabindex="-1"></a>    <span class="co"># mask the image according to threshold</span></span>
<span id="cb17-16"><a href="#cb17-16" tabindex="-1"></a>    binary_mask <span class="op">=</span> blurred_image <span class="op">&gt;</span> t</span>
<span id="cb17-17"><a href="#cb17-17" tabindex="-1"></a>    <span class="co"># perform connected component analysis</span></span>
<span id="cb17-18"><a href="#cb17-18" tabindex="-1"></a>    labeled_image, count <span class="op">=</span> ski.measure.label(binary_mask,</span>
<span id="cb17-19"><a href="#cb17-19" tabindex="-1"></a>                                                 connectivity<span class="op">=</span>connectivity, return_num<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb17-20"><a href="#cb17-20" tabindex="-1"></a>    <span class="cf">return</span> labeled_image, count</span>
<span id="cb17-21"><a href="#cb17-21" tabindex="-1"></a></span>
<span id="cb17-22"><a href="#cb17-22" tabindex="-1"></a><span class="co"># Call segmentation function on HeLa cells image file, nuclei channel</span></span>
<span id="cb17-23"><a href="#cb17-23" tabindex="-1"></a>labeled_image, count <span class="op">=</span> segment_multichannel(filename<span class="op">=</span><span class="st">"data/hela-cells-8bit.tif"</span>, channel<span class="op">=</span><span class="dv">2</span>, sigma<span class="op">=</span><span class="fl">2.0</span>, t<span class="op">=</span><span class="fl">0.1</span>, connectivity<span class="op">=</span><span class="dv">2</span>)</span></code></pre>
</div>
</div>
</div>
</div>
<div id="how-does-parameter-choice-change-how-many-objects-are-in-the-image-15-min" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="how-does-parameter-choice-change-how-many-objects-are-in-the-image-15-min" class="callout-inner">
<h3 class="callout-title">How does parameter choice change how many objects are in the image? (15 min)</h3>
<div class="callout-content">
<p>Now, it is your turn to practice. Using the function
<code>segment_multichannel</code>, print out the value
<code>count</code> to see how many objects were found in the image.</p>
<p>What number of objects would you expect to get?</p>
<p>How does changing the <code>sigma</code> and <code>threshold</code>
values influence the result?</p>
</div>
</div>
</div>
<div id="accordionSolution3" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution3" aria-expanded="false" aria-controls="collapseSolution3">
  <h4 class="accordion-header" id="headingSolution3"> Show me the solution </h4>
</button>
<div id="collapseSolution3" class="accordion-collapse collapse" data-bs-parent="#accordionSolution3" aria-labelledby="headingSolution3">
<div class="accordion-body">
<p>As you might have guessed, the return value <code>count</code>
already contains the number of objects found in the image. So it can
simply be printed with</p>
<div class="codewrapper sourceCode" id="cb18">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Found"</span>, count, <span class="st">"objects in the image."</span>)</span></code></pre>
</div>
<p>But there is also a way to obtain the number of found objects from
the labeled image itself. Recall that all pixels that belong to a single
object are assigned the same integer value. The connected component
algorithm produces consecutive numbers. The background gets the value
<code>0</code>, the first object gets the value <code>1</code>, the
second object the value <code>2</code>, and so on. This means that by
finding the object with the maximum value, we also know how many objects
there are in the image. We can thus use the <code>np.max</code> function
from NumPy to find the maximum value that equals the number of found
objects:</p>
<div class="codewrapper sourceCode" id="cb19">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a>num_objects <span class="op">=</span> np.<span class="bu">max</span>(labeled_image)</span>
<span id="cb19-2"><a href="#cb19-2" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Found"</span>, num_objects, <span class="st">"objects in the image."</span>)</span></code></pre>
</div>
<p>Invoking the function with <code>sigma=1.0</code>, and
<code>threshold=0.1</code>, both methods will print</p>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Found 6 objects in the image.</code></pre>
</div>
<div class="section level2">
<h2 id="how-do-parameters-affect-output">How do parameters affect output?<a class="anchor" aria-label="anchor" href="#how-do-parameters-affect-output"></a>
</h2>
<p>Raising the threshold will result in fewer objects. The lower the
threshold is set, the more objects are found. More and more background
noise gets picked up as objects. Larger sigmas produce binary masks with
less noise and hence a smaller number of objects. Setting sigma too high
bears the danger of merging objects.</p>
</div>
</div>
</div>
</div>
</div>
<p>You might wonder why the connected component analysis with
<code>sigma=1.0</code>, and <code>threshold=0.1</code> finds 6 objects,
whereas we would expect only 4 objects. Where are the two additional
objects? With a bit of detective work, we can spot some small objects in
the image, for example, near the bottom left corner and top border.</p>
<figure><img src="../fig/cells-labeled-small-box.jpg" alt="Highlighting small labeled objects in cell image" class="figure mx-auto d-block"></figure><p>For us it is clear that these small spots are artifacts and not
objects we are interested in. But how can we tell the computer? One way
to calibrate the algorithm is to adjust the parameters for blurring
(<code>sigma</code>) and thresholding (<code>t</code>), but you may have
noticed during the above exercise that it is quite hard to find a
combination that produces the right output number. In some cases,
background noise gets picked up as an object. And with other parameters,
some of the foreground objects get broken up or disappear completely.
Therefore, we need other criteria to describe desired properties of the
objects that are found.</p>
</section><section><h2 class="section-heading" id="morphometrics---describe-object-features-with-numbers">Morphometrics - Describe object features with numbers<a class="anchor" aria-label="anchor" href="#morphometrics---describe-object-features-with-numbers"></a>
</h2>
<hr class="half-width">
<p>Morphometrics is concerned with the quantitative analysis of objects
and considers properties such as size and shape. For the example of the
images with the cells, our intuition tells us that the objects should be
of a certain size or area. So we could use a minimum area as a criterion
for when an object should be detected. To apply such a criterion, we
need a way to calculate the area of objects found by connected
components. The scikit-image library provides the function
<code>ski.measure.regionprops</code> to measure the properties of
labeled regions. It returns a list of <code>RegionProperties</code> that
describe each connected region in the images. The properties can be
accessed using the attributes of the <code>RegionProperties</code> data
type. Here we will use the properties <code>"area"</code> and
<code>"label"</code>. You can explore <a href="https://scikit-image.org/docs/stable/api/skimage.measure.html#skimage.measure.regionprops" class="external-link">the
scikit-image documentation on regionprops</a> to learn about other
properties available.</p>
<p>We can get a list of areas of the labeled objects as follows:</p>
<div class="codewrapper sourceCode" id="cb21">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" tabindex="-1"></a><span class="co"># compute object features and extract object areas</span></span>
<span id="cb21-2"><a href="#cb21-2" tabindex="-1"></a>object_features <span class="op">=</span> ski.measure.regionprops(labeled_image)</span>
<span id="cb21-3"><a href="#cb21-3" tabindex="-1"></a>object_areas <span class="op">=</span> [objf[<span class="st">"area"</span>] <span class="cf">for</span> objf <span class="kw">in</span> object_features]</span>
<span id="cb21-4"><a href="#cb21-4" tabindex="-1"></a>object_areas</span></code></pre>
</div>
<p>This will produce the output</p>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>[20.0, 13722.0, 14147.0, 13308.0, 12629.0, 156.0]</code></pre>
</div>
<div id="plot-a-histogram-of-the-object-area-distribution-10-min" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="plot-a-histogram-of-the-object-area-distribution-10-min" class="callout-inner">
<h3 class="callout-title">Plot a histogram of the object area distribution (10 min)</h3>
<div class="callout-content">
<p>Similar to how we determined a “good” threshold in <a href="07-thresholding.html">the <em>Thresholding</em> episode</a>, it is
often helpful to inspect the histogram of an object property. For
example, we want to look at the distribution of the object areas.</p>
<ol style="list-style-type: decimal">
<li>Create and examine a <a href="05-creating-histograms.html">histogram</a> of the object areas
obtained with <code>ski.measure.regionprops</code>.</li>
<li>What does the histogram tell you about the objects?</li>
</ol>
</div>
</div>
</div>
<div id="accordionSolution4" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution4" aria-expanded="false" aria-controls="collapseSolution4">
  <h4 class="accordion-header" id="headingSolution4"> Show me the solution </h4>
</button>
<div id="collapseSolution4" class="accordion-collapse collapse" data-bs-parent="#accordionSolution4" aria-labelledby="headingSolution4">
<div class="accordion-body">
<p>The histogram can be plotted with</p>
<div class="codewrapper sourceCode" id="cb23">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb23-2"><a href="#cb23-2" tabindex="-1"></a>plt.hist(object_areas)</span>
<span id="cb23-3"><a href="#cb23-3" tabindex="-1"></a>plt.xlabel(<span class="st">"Area (pixels)"</span>)</span>
<span id="cb23-4"><a href="#cb23-4" tabindex="-1"></a>plt.ylabel(<span class="st">"Number of objects"</span>)<span class="op">;</span></span></code></pre>
</div>
<figure><img src="../fig/cells-area-histogram.png" alt="Histogram of object areas" class="figure mx-auto d-block"></figure><p>The histogram shows the number of objects (vertical axis) whose area
is within a certain range (horizontal axis). The height of the bars in
the histogram indicates the prevalence of objects with a certain area.
The whole histogram tells us about the distribution of object sizes in
the image. It is often possible to identify gaps between groups of bars
(or peaks if we draw the histogram as a continuous curve) that tell us
about certain groups in the image.</p>
<p>In this example, we can see that there are two small objects that
contain less than 2000 pixels. Then there is a group of four (1+3)
objects in the range between 10000 and 15000. For our object count, we
might want to disregard the small objects as artifacts, i.e, we want to
ignore the leftmost bar of the histogram. We could use a threshold of
8000 as the minimum area to count. In fact, the
<code>object_areas</code> list already tells us that there are fewer
than 200 pixels in these objects. Therefore, it is reasonable to require
a minimum area of at least 200 pixels for a detected object. In
practice, finding the “right” threshold can be tricky and usually
involves an educated guess based on domain knowledge. For example, if
you know the micrometer size of your pixel resolution and expected size
of the cells you are imaging, you could compute the expected number of
pixels per cell area and keep objects of that size.</p>
</div>
</div>
</div>
</div>
<div id="code-cheatsheet-for-filter-objects-by-area" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="code-cheatsheet-for-filter-objects-by-area" class="callout-inner">
<h3 class="callout-title">Code cheatsheet for “Filter objects by area”:</h3>
<div class="callout-content">
<div class="codewrapper sourceCode" id="cb24">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" tabindex="-1"></a><span class="im">import</span> imageio.v3 <span class="im">as</span> iio</span>
<span id="cb24-2"><a href="#cb24-2" tabindex="-1"></a><span class="im">import</span> ipympl</span>
<span id="cb24-3"><a href="#cb24-3" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb24-4"><a href="#cb24-4" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb24-5"><a href="#cb24-5" tabindex="-1"></a><span class="im">import</span> skimage <span class="im">as</span> ski</span>
<span id="cb24-6"><a href="#cb24-6" tabindex="-1"></a><span class="op">%</span>matplotlib widget</span>
<span id="cb24-7"><a href="#cb24-7" tabindex="-1"></a></span>
<span id="cb24-8"><a href="#cb24-8" tabindex="-1"></a><span class="kw">def</span> segment_multichannel(filename, channel<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="fl">1.0</span>, t<span class="op">=</span><span class="fl">0.5</span>, connectivity<span class="op">=</span><span class="dv">2</span>):</span>
<span id="cb24-9"><a href="#cb24-9" tabindex="-1"></a>    <span class="co"># load the image</span></span>
<span id="cb24-10"><a href="#cb24-10" tabindex="-1"></a>    image <span class="op">=</span> iio.imread(filename)</span>
<span id="cb24-11"><a href="#cb24-11" tabindex="-1"></a>    <span class="co"># convert the image to grayscale</span></span>
<span id="cb24-12"><a href="#cb24-12" tabindex="-1"></a>    channel_image <span class="op">=</span> image[:,:,channel]</span>
<span id="cb24-13"><a href="#cb24-13" tabindex="-1"></a>    <span class="co"># denoise the image with a Gaussian filter</span></span>
<span id="cb24-14"><a href="#cb24-14" tabindex="-1"></a>    blurred_image <span class="op">=</span> ski.filters.gaussian(channel_image, sigma<span class="op">=</span>sigma)</span>
<span id="cb24-15"><a href="#cb24-15" tabindex="-1"></a>    <span class="co"># mask the image according to threshold</span></span>
<span id="cb24-16"><a href="#cb24-16" tabindex="-1"></a>    binary_mask <span class="op">=</span> blurred_image <span class="op">&gt;</span> t</span>
<span id="cb24-17"><a href="#cb24-17" tabindex="-1"></a>    <span class="co"># perform connected component analysis</span></span>
<span id="cb24-18"><a href="#cb24-18" tabindex="-1"></a>    labeled_image, count <span class="op">=</span> ski.measure.label(binary_mask,</span>
<span id="cb24-19"><a href="#cb24-19" tabindex="-1"></a>                                                 connectivity<span class="op">=</span>connectivity, return_num<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb24-20"><a href="#cb24-20" tabindex="-1"></a>    <span class="cf">return</span> labeled_image, count</span>
<span id="cb24-21"><a href="#cb24-21" tabindex="-1"></a></span>
<span id="cb24-22"><a href="#cb24-22" tabindex="-1"></a><span class="co"># Call segmentation function on HeLa cells image file, nuclei channel</span></span>
<span id="cb24-23"><a href="#cb24-23" tabindex="-1"></a>labeled_image, count <span class="op">=</span> segment_multichannel(filename<span class="op">=</span><span class="st">"data/hela-cells-8bit.tif"</span>, channel<span class="op">=</span><span class="dv">2</span>, sigma<span class="op">=</span><span class="fl">2.0</span>, t<span class="op">=</span><span class="fl">0.1</span>, connectivity<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb24-24"><a href="#cb24-24" tabindex="-1"></a></span>
<span id="cb24-25"><a href="#cb24-25" tabindex="-1"></a><span class="co"># compute object features and extract object areas</span></span>
<span id="cb24-26"><a href="#cb24-26" tabindex="-1"></a>object_features <span class="op">=</span> ski.measure.regionprops(labeled_image)</span>
<span id="cb24-27"><a href="#cb24-27" tabindex="-1"></a>object_areas <span class="op">=</span> [objf[<span class="st">"area"</span>] <span class="cf">for</span> objf <span class="kw">in</span> object_features]</span></code></pre>
</div>
</div>
</div>
</div>
<div id="filter-objects-by-area-10-min" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="filter-objects-by-area-10-min" class="callout-inner">
<h3 class="callout-title">Filter objects by area (10 min)</h3>
<div class="callout-content">
<p>Now we would like to use a minimum area criterion to obtain a more
accurate count of the objects in the image.</p>
<ol style="list-style-type: decimal">
<li>Find a way to calculate the number of objects by only counting
objects above a certain area.</li>
<li>Keep track of which object labels we want to keep, e.g. in a
list.</li>
</ol>
</div>
</div>
</div>
<div id="accordionSolution5" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution5" aria-expanded="false" aria-controls="collapseSolution5">
  <h4 class="accordion-header" id="headingSolution5"> Show me the solution </h4>
</button>
<div id="collapseSolution5" class="accordion-collapse collapse" data-bs-parent="#accordionSolution5" aria-labelledby="headingSolution5">
<div class="accordion-body">
<p>One way to count only objects above a certain area is to first create
a list of those objects, and then take the length of that list as the
object count. This can be done as follows:</p>
<div class="codewrapper sourceCode" id="cb25">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" tabindex="-1"></a>min_area <span class="op">=</span> <span class="dv">200</span></span>
<span id="cb25-2"><a href="#cb25-2" tabindex="-1"></a>large_objects <span class="op">=</span> []</span>
<span id="cb25-3"><a href="#cb25-3" tabindex="-1"></a><span class="cf">for</span> objf <span class="kw">in</span> object_features:</span>
<span id="cb25-4"><a href="#cb25-4" tabindex="-1"></a>    <span class="cf">if</span> objf[<span class="st">"area"</span>] <span class="op">&gt;</span> min_area:</span>
<span id="cb25-5"><a href="#cb25-5" tabindex="-1"></a>        large_objects.append(objf[<span class="st">"label"</span>])</span>
<span id="cb25-6"><a href="#cb25-6" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Found"</span>, <span class="bu">len</span>(large_objects), <span class="st">"objects!"</span>)</span></code></pre>
</div>
<p>Another option is to use NumPy arrays to create the list of large
objects. We first create an array <code>object_areas</code> containing
the object areas, and an array <code>object_labels</code> containing the
object labels. The labels of the objects are also returned by
<code>ski.measure.regionprops</code>. We have already seen that we can
create boolean arrays using comparison operators. Here we can use
<code>object_areas &gt; min_area</code> to produce an array that has the
same dimension as <code>object_labels</code>. It can then used to select
the labels of objects whose area is greater than <code>min_area</code>
by indexing:</p>
<div class="codewrapper sourceCode" id="cb26">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" tabindex="-1"></a>object_areas <span class="op">=</span> np.array([objf[<span class="st">"area"</span>] <span class="cf">for</span> objf <span class="kw">in</span> object_features])</span>
<span id="cb26-2"><a href="#cb26-2" tabindex="-1"></a>object_labels <span class="op">=</span> np.array([objf[<span class="st">"label"</span>] <span class="cf">for</span> objf <span class="kw">in</span> object_features])</span>
<span id="cb26-3"><a href="#cb26-3" tabindex="-1"></a>large_objects <span class="op">=</span> object_labels[object_areas <span class="op">&gt;</span> min_area]</span>
<span id="cb26-4"><a href="#cb26-4" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Found"</span>, <span class="bu">len</span>(large_objects), <span class="st">"objects!"</span>)</span></code></pre>
</div>
<p>The advantage of using NumPy arrays is that <code>for</code> loops
and <code>if</code> statements in Python can be slow, and in practice
the first approach may not be feasible if the image contains a large
number of objects. In that case, NumPy array functions turn out to be
very useful because they are much faster.</p>
<p>In this example, we can also use the <code>np.count_nonzero</code>
function that we have seen earlier together with the <code>&gt;</code>
operator to count the objects whose area is above
<code>min_area</code>.</p>
<div class="codewrapper sourceCode" id="cb27">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" tabindex="-1"></a>n <span class="op">=</span> np.count_nonzero(object_areas <span class="op">&gt;</span> min_area)</span>
<span id="cb27-2"><a href="#cb27-2" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Found"</span>, n, <span class="st">"objects!"</span>)</span></code></pre>
</div>
<p>For all three alternatives, the output is the same and gives the
expected count of 4 objects.</p>
</div>
</div>
</div>
</div>
<div id="using-functions-from-numpy-and-other-python-packages" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="using-functions-from-numpy-and-other-python-packages" class="callout-inner">
<h3 class="callout-title">Using functions from NumPy and other Python packages</h3>
<div class="callout-content">
<p>Functions from Python packages such as NumPy are often more efficient
and require less code to write. It is a good idea to browse the
reference pages of <code>numpy</code> and <code>skimage</code> to look
for an availabe function that can solve a given task.</p>
</div>
</div>
</div>
<div id="code-cheatsheet-for-removing-small-objects" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="code-cheatsheet-for-removing-small-objects" class="callout-inner">
<h3 class="callout-title">Code cheatsheet for removing small objects</h3>
<div class="callout-content">
<div class="codewrapper sourceCode" id="cb28">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" tabindex="-1"></a><span class="im">import</span> imageio.v3 <span class="im">as</span> iio</span>
<span id="cb28-2"><a href="#cb28-2" tabindex="-1"></a><span class="im">import</span> ipympl</span>
<span id="cb28-3"><a href="#cb28-3" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb28-4"><a href="#cb28-4" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb28-5"><a href="#cb28-5" tabindex="-1"></a><span class="im">import</span> skimage <span class="im">as</span> ski</span>
<span id="cb28-6"><a href="#cb28-6" tabindex="-1"></a><span class="op">%</span>matplotlib widget</span>
<span id="cb28-7"><a href="#cb28-7" tabindex="-1"></a></span>
<span id="cb28-8"><a href="#cb28-8" tabindex="-1"></a><span class="kw">def</span> segment_multichannel(filename, channel<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="fl">1.0</span>, t<span class="op">=</span><span class="fl">0.5</span>, connectivity<span class="op">=</span><span class="dv">2</span>):</span>
<span id="cb28-9"><a href="#cb28-9" tabindex="-1"></a>    <span class="co"># load the image</span></span>
<span id="cb28-10"><a href="#cb28-10" tabindex="-1"></a>    image <span class="op">=</span> iio.imread(filename)</span>
<span id="cb28-11"><a href="#cb28-11" tabindex="-1"></a>    <span class="co"># convert the image to grayscale</span></span>
<span id="cb28-12"><a href="#cb28-12" tabindex="-1"></a>    channel_image <span class="op">=</span> image[:,:,channel]</span>
<span id="cb28-13"><a href="#cb28-13" tabindex="-1"></a>    <span class="co"># denoise the image with a Gaussian filter</span></span>
<span id="cb28-14"><a href="#cb28-14" tabindex="-1"></a>    blurred_image <span class="op">=</span> ski.filters.gaussian(channel_image, sigma<span class="op">=</span>sigma)</span>
<span id="cb28-15"><a href="#cb28-15" tabindex="-1"></a>    <span class="co"># mask the image according to threshold</span></span>
<span id="cb28-16"><a href="#cb28-16" tabindex="-1"></a>    binary_mask <span class="op">=</span> blurred_image <span class="op">&gt;</span> t</span>
<span id="cb28-17"><a href="#cb28-17" tabindex="-1"></a>    <span class="co"># perform connected component analysis</span></span>
<span id="cb28-18"><a href="#cb28-18" tabindex="-1"></a>    labeled_image, count <span class="op">=</span> ski.measure.label(binary_mask,</span>
<span id="cb28-19"><a href="#cb28-19" tabindex="-1"></a>                                                 connectivity<span class="op">=</span>connectivity, return_num<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb28-20"><a href="#cb28-20" tabindex="-1"></a>    <span class="cf">return</span> labeled_image, count</span>
<span id="cb28-21"><a href="#cb28-21" tabindex="-1"></a></span>
<span id="cb28-22"><a href="#cb28-22" tabindex="-1"></a><span class="co"># Call segmentation function on HeLa cells image file, nuclei channel</span></span>
<span id="cb28-23"><a href="#cb28-23" tabindex="-1"></a>labeled_image, count <span class="op">=</span> segment_multichannel(filename<span class="op">=</span><span class="st">"data/hela-cells-8bit.tif"</span>, channel<span class="op">=</span><span class="dv">2</span>, sigma<span class="op">=</span><span class="fl">2.0</span>, t<span class="op">=</span><span class="fl">0.1</span>, connectivity<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb28-24"><a href="#cb28-24" tabindex="-1"></a></span>
<span id="cb28-25"><a href="#cb28-25" tabindex="-1"></a>object_features <span class="op">=</span> ski.measure.regionprops(labeled_image)</span>
<span id="cb28-26"><a href="#cb28-26" tabindex="-1"></a>object_areas <span class="op">=</span> [objf[<span class="st">"area"</span>] <span class="cf">for</span> objf <span class="kw">in</span> object_features]</span>
<span id="cb28-27"><a href="#cb28-27" tabindex="-1"></a>object_areas</span>
<span id="cb28-28"><a href="#cb28-28" tabindex="-1"></a></span>
<span id="cb28-29"><a href="#cb28-29" tabindex="-1"></a><span class="co"># "for loop" way of finding large object labels</span></span>
<span id="cb28-30"><a href="#cb28-30" tabindex="-1"></a>min_area <span class="op">=</span> <span class="dv">200</span></span>
<span id="cb28-31"><a href="#cb28-31" tabindex="-1"></a>large_objects <span class="op">=</span> []</span>
<span id="cb28-32"><a href="#cb28-32" tabindex="-1"></a><span class="cf">for</span> objf <span class="kw">in</span> object_features:</span>
<span id="cb28-33"><a href="#cb28-33" tabindex="-1"></a>    <span class="cf">if</span> objf[<span class="st">"area"</span>] <span class="op">&gt;</span> min_area:</span>
<span id="cb28-34"><a href="#cb28-34" tabindex="-1"></a>        large_objects.append(objf[<span class="st">"label"</span>])</span>
<span id="cb28-35"><a href="#cb28-35" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Found"</span>, <span class="bu">len</span>(large_objects), <span class="st">"objects!"</span>)</span>
<span id="cb28-36"><a href="#cb28-36" tabindex="-1"></a></span>
<span id="cb28-37"><a href="#cb28-37" tabindex="-1"></a><span class="co"># "numpy" way of finding large object labels</span></span>
<span id="cb28-38"><a href="#cb28-38" tabindex="-1"></a>min_area <span class="op">=</span> <span class="dv">200</span></span>
<span id="cb28-39"><a href="#cb28-39" tabindex="-1"></a>object_areas <span class="op">=</span> np.array([objf[<span class="st">"area"</span>] <span class="cf">for</span> objf <span class="kw">in</span> object_features])</span>
<span id="cb28-40"><a href="#cb28-40" tabindex="-1"></a>object_labels <span class="op">=</span> np.array([objf[<span class="st">"label"</span>] <span class="cf">for</span> objf <span class="kw">in</span> object_features])</span>
<span id="cb28-41"><a href="#cb28-41" tabindex="-1"></a>large_objects <span class="op">=</span> object_labels[object_areas <span class="op">&gt;</span> min_area]</span>
<span id="cb28-42"><a href="#cb28-42" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Found"</span>, <span class="bu">len</span>(large_objects), <span class="st">"objects!"</span>)</span></code></pre>
</div>
</div>
</div>
</div>
<div id="remove-small-objects-20-min" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="remove-small-objects-20-min" class="callout-inner">
<h3 class="callout-title">Remove small objects (20 min)</h3>
<div class="callout-content">
<p>We might also want to exclude (mask) the small objects when plotting
the labeled image.</p>
<ol start="2" style="list-style-type: decimal">
<li>Given a labeled image from the <code>segment_multichannel</code>
function, remove objects from the labeled image that are below a certain
area.</li>
</ol>
</div>
</div>
</div>
<div id="accordionSolution6" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution6" aria-expanded="false" aria-controls="collapseSolution6">
  <h4 class="accordion-header" id="headingSolution6"> Show me the solution </h4>
</button>
<div id="collapseSolution6" class="accordion-collapse collapse" data-bs-parent="#accordionSolution6" aria-labelledby="headingSolution6">
<div class="accordion-body">
<p>To remove the small objects from the labeled image, we change the
value of all pixels that belong to the small objects to the background
label 0. One way to do this is to loop over all objects and set the
pixels that match the label of the object to 0.</p>
<div class="codewrapper sourceCode" id="cb29">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" tabindex="-1"></a>min_area <span class="op">=</span> <span class="dv">200</span></span>
<span id="cb29-2"><a href="#cb29-2" tabindex="-1"></a><span class="cf">for</span> object_id, objf <span class="kw">in</span> <span class="bu">enumerate</span>(object_features, start<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb29-3"><a href="#cb29-3" tabindex="-1"></a>    <span class="cf">if</span> objf[<span class="st">"area"</span>] <span class="op">&lt;</span> min_area:</span>
<span id="cb29-4"><a href="#cb29-4" tabindex="-1"></a>        labeled_image[labeled_image <span class="op">==</span> objf[<span class="st">"label"</span>]] <span class="op">=</span> <span class="dv">0</span></span></code></pre>
</div>
<p>Here NumPy functions can also be used to eliminate <code>for</code>
loops and <code>if</code> statements. Like above, we can create an array
of the small object labels with the comparison
<code>object_areas &lt; min_area</code>. We can use another NumPy
function, <code>np.isin</code>, to set the pixels of all small objects
to 0. <code>np.isin</code> takes two arrays and returns a boolean array
with values <code>True</code> if the entry of the first array is found
in the second array, and <code>False</code> otherwise. This array can
then be used to index the <code>labeled_image</code> and set the entries
that belong to small objects to <code>0</code>.</p>
<div class="codewrapper sourceCode" id="cb30">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" tabindex="-1"></a>min_area <span class="op">=</span> <span class="dv">200</span></span>
<span id="cb30-2"><a href="#cb30-2" tabindex="-1"></a>object_areas <span class="op">=</span> np.array([objf[<span class="st">"area"</span>] <span class="cf">for</span> objf <span class="kw">in</span> object_features])</span>
<span id="cb30-3"><a href="#cb30-3" tabindex="-1"></a>object_labels <span class="op">=</span> np.array([objf[<span class="st">"label"</span>] <span class="cf">for</span> objf <span class="kw">in</span> object_features])</span>
<span id="cb30-4"><a href="#cb30-4" tabindex="-1"></a>small_objects <span class="op">=</span> object_labels[object_areas <span class="op">&lt;</span> min_area]</span>
<span id="cb30-5"><a href="#cb30-5" tabindex="-1"></a>labeled_image[np.isin(labeled_image, small_objects)] <span class="op">=</span> <span class="dv">0</span></span></code></pre>
</div>
</div>
</div>
</div>
</div>
<p>An even more elegant way to remove small objects from the image is to
leverage the <code>ski.morphology</code> module. It provides a function
<code>ski.morphology.remove_small_objects</code> that does exactly what
we are looking for. It can be applied to a binary image and returns a
mask in which all objects smaller than <code>min_area</code> are
excluded, i.e, their pixel values are set to <code>False</code>. We can
then apply <code>ski.measure.label</code> to the masked image:</p>
<div class="codewrapper sourceCode" id="cb31">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" tabindex="-1"></a>object_mask <span class="op">=</span> ski.morphology.remove_small_objects(binary_mask, min_size<span class="op">=</span>min_area)</span>
<span id="cb31-2"><a href="#cb31-2" tabindex="-1"></a>labeled_image, n <span class="op">=</span> ski.measure.label(object_mask,</span>
<span id="cb31-3"><a href="#cb31-3" tabindex="-1"></a>                                         connectivity<span class="op">=</span>connectivity, return_num<span class="op">=</span><span class="va">True</span>)</span></code></pre>
</div>
<p>Using the scikit-image features, we can implement the
<code>enhanced_segment_multichannel</code> as follows:</p>
<div class="codewrapper sourceCode" id="cb32">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" tabindex="-1"></a><span class="kw">def</span> enhanced_segment_multichannel(filename, channel<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="fl">1.0</span>, t<span class="op">=</span><span class="fl">0.5</span>, connectivity<span class="op">=</span><span class="dv">2</span>, min_area<span class="op">=</span><span class="dv">0</span>):</span>
<span id="cb32-2"><a href="#cb32-2" tabindex="-1"></a>    <span class="co"># load the image</span></span>
<span id="cb32-3"><a href="#cb32-3" tabindex="-1"></a>    image <span class="op">=</span> iio.imread(filename)</span>
<span id="cb32-4"><a href="#cb32-4" tabindex="-1"></a>    <span class="co"># convert the image to grayscale</span></span>
<span id="cb32-5"><a href="#cb32-5" tabindex="-1"></a>    channel_image <span class="op">=</span> image[:,:,channel]</span>
<span id="cb32-6"><a href="#cb32-6" tabindex="-1"></a>    <span class="co"># denoise the image with a Gaussian filter</span></span>
<span id="cb32-7"><a href="#cb32-7" tabindex="-1"></a>    blurred_image <span class="op">=</span> ski.filters.gaussian(channel_image, sigma<span class="op">=</span>sigma)</span>
<span id="cb32-8"><a href="#cb32-8" tabindex="-1"></a>    <span class="co"># mask the image according to threshold</span></span>
<span id="cb32-9"><a href="#cb32-9" tabindex="-1"></a>    binary_mask <span class="op">=</span> blurred_image <span class="op">&gt;</span> t</span>
<span id="cb32-10"><a href="#cb32-10" tabindex="-1"></a>    <span class="co"># remove objects smaller than specified area before labelling</span></span>
<span id="cb32-11"><a href="#cb32-11" tabindex="-1"></a>    object_mask <span class="op">=</span> ski.morphology.remove_small_objects(binary_mask, min_size<span class="op">=</span>min_area)</span>
<span id="cb32-12"><a href="#cb32-12" tabindex="-1"></a>    <span class="co"># perform connected component analysis</span></span>
<span id="cb32-13"><a href="#cb32-13" tabindex="-1"></a>    labeled_image, count <span class="op">=</span> ski.measure.label(object_mask,</span>
<span id="cb32-14"><a href="#cb32-14" tabindex="-1"></a>                                                 connectivity<span class="op">=</span>connectivity, return_num<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb32-15"><a href="#cb32-15" tabindex="-1"></a>    <span class="cf">return</span> labeled_image, count</span></code></pre>
</div>
<p>We can now call the function with a chosen <code>min_area</code> and
display the resulting labeled image:</p>
<div class="codewrapper sourceCode" id="cb33">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" tabindex="-1"></a>labeled_image, count <span class="op">=</span> enhanced_segment_multichannel(filename<span class="op">=</span><span class="st">"data/hela-cells-8bit.jpg"</span>, channel<span class="op">=</span><span class="dv">2</span>, sigma<span class="op">=</span><span class="fl">1.0</span>, t<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb33-2"><a href="#cb33-2" tabindex="-1"></a>                                                     connectivity<span class="op">=</span><span class="dv">2</span>, min_area<span class="op">=</span><span class="dv">200</span>)</span>
<span id="cb33-3"><a href="#cb33-3" tabindex="-1"></a>colored_label_image <span class="op">=</span> ski.color.label2rgb(labeled_image, bg_label<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb33-4"><a href="#cb33-4" tabindex="-1"></a></span>
<span id="cb33-5"><a href="#cb33-5" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb33-6"><a href="#cb33-6" tabindex="-1"></a>plt.imshow(colored_label_image)</span>
<span id="cb33-7"><a href="#cb33-7" tabindex="-1"></a>plt.axis(<span class="st">"off"</span>)<span class="op">;</span></span>
<span id="cb33-8"><a href="#cb33-8" tabindex="-1"></a></span>
<span id="cb33-9"><a href="#cb33-9" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Found"</span>, count, <span class="st">"objects in the image."</span>)</span></code></pre>
</div>
<figure><img src="../fig/cells-labeled-kept.jpg" alt="Objects filtered by area" class="figure mx-auto d-block"></figure><div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Found 4 objects in the image.</code></pre>
</div>
<p>Note that the small objects are “gone” and we obtain the correct
number of 4 objects in the image.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul>
<li>We can use <code>ski.measure.label</code> to find and label
connected objects in an image.</li>
<li>We can use <code>ski.measure.regionprops</code> to measure
properties of labeled objects.</li>
<li>We can use <code>ski.morphology.remove_small_objects</code> to mask
small objects and remove artifacts from an image.</li>
<li>We can display the labeled image to view the objects coloured by
label.</li>
</ul>
</div>
</div>
</div>
</section></section>
</div>
    </main>
</div>
<!-- END  : inst/pkgdown/templates/content-extra.html -->

      </div>
<!--/div.row-->
      		<footer class="row footer mx-md-3"><hr>
<div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>

        <a href="https://github.com/govekk/image-processing/edit/main/README.md" class="external-link">Edit on GitHub</a>

	
        | <a href="https://github.com/govekk/image-processing/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a>
        | <a href="https://github.com/govekk/image-processing/" class="external-link">Source</a></p>
				<p><a href="https://github.com/govekk/image-processing/blob/main/CITATION" class="external-link">Cite</a> | <a href="mailto:team@carpentries.org">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
			</div>
			<div class="col-md-6">

        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>

        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/carpentries/sandpaper/tree/0.16.10" class="external-link">sandpaper (0.16.10)</a>, <a href="https://github.com/carpentries/pegboard/tree/0.7.7" class="external-link">pegboard (0.7.7)</a>, and <a href="https://github.com/carpentries/varnish/tree/1.0.5" class="external-link">varnish (1.0.5)</a></p>
			</div>
		</footer>
</div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "TrainingMaterial",
  "@id": "https://govekk.github.io/image-processing/instructor/aio.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/TrainingMaterial/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": "software, data, lesson, The Carpentries",
  "name": "All in One View",
  "creativeWorkStatus": "active",
  "url": "https://govekk.github.io/image-processing/instructor/aio.html",
  "identifier": "https://govekk.github.io/image-processing/instructor/aio.html",
  "dateCreated": "2024-03-14",
  "dateModified": "2024-12-31",
  "datePublished": "2024-12-31"
}

  </script><script>
		feather.replace();
	</script><!-- Matomo --><script>
          var _paq = window._paq = window._paq || [];
          /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
          _paq.push(["setDocumentTitle", document.domain + "/" + document.title]);
          _paq.push(["setDomains", ["*.lessons.carpentries.org","*.datacarpentry.github.io","*.datacarpentry.org","*.librarycarpentry.github.io","*.librarycarpentry.org","*.swcarpentry.github.io", "*.carpentries.github.io"]]);
          _paq.push(["setDoNotTrack", true]);
          _paq.push(["disableCookies"]);
          _paq.push(["trackPageView"]);
          _paq.push(["enableLinkTracking"]);
          (function() {
              var u="https://matomo.carpentries.org/";
              _paq.push(["setTrackerUrl", u+"matomo.php"]);
              _paq.push(["setSiteId", "1"]);
              var d=document, g=d.createElement("script"), s=d.getElementsByTagName("script")[0];
              g.async=true; g.src="https://matomo.carpentries.org/matomo.js"; s.parentNode.insertBefore(g,s);
          })();
        </script><!-- End Matomo Code -->
</body>
</html><!-- END:   inst/pkgdown/templates/layout.html-->

